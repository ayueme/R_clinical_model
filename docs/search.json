[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R语言实战临床预测模型",
    "section": "",
    "text": "前言\n谨以此书纪念我不务正业的研究生生涯。",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "index.html#本书缘起",
    "href": "index.html#本书缘起",
    "title": "R语言实战临床预测模型",
    "section": "本书缘起",
    "text": "本书缘起\n我在2019年接触到R语言和临床预测模型，彼时还是“简单的纯生信也能随便发SCI的上古时代”，当时的临床预测模型并不像现在这么火爆，连培训班也只有零星的几个，收费不过1000块左右。\n然而随着大家愈加内卷，各种各样的培训班也越来越多，价格也是水涨船高，竟然都要3000+，甚至8000+了，更让人匪夷所思的是竟然还有付费订阅制软件！离谱！魔幻！但是内容并没有什么新意，无非就是列线图/ROC曲线/C-index/NRI/IDI/校准曲线/决策曲线等等。\n回想自己的学习经历，这些东西无非就是各种R语言操作而已，本人的公众号也一直向大家免费提供这些教程。这部分内容已经积累了近百篇推文，是时候做个总结了，我把这些内容整理在一起，方便有需要的人学习。\n\n本书在线阅读地址：https://ayueme.github.io/R_clinical_model/\n本书github地址：https://github.com/ayueme/R_clinical_model",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "index.html#书籍简介",
    "href": "index.html#书籍简介",
    "title": "R语言实战临床预测模型",
    "section": "书籍简介",
    "text": "书籍简介\n本书主要介绍R语言在临床预测模型中的应用，重实践，少理论，全书多数内容都是R语言实操，但是对于每一种方法和概念都进行了详细的解释。\n临床预测模型和统计学以及机器学习交叉很多，本书虽然是R语言实现临床预测模型的入门书籍，但在阅读本书前，还需要你已经对临床预测模型、统计学、机器学习具有一定的了解。\n\n\n\n\n\n\n提醒\n\n\n\n本书不适合R语言零基础的人。 如果你是刚入门的小白，我首先推荐你了解下R语言的基础知识，比如R语言和R包安装、Rstudio的界面、R语言中数据类型（向量、矩阵、数据框、列表等）、R语言中的数据导入导出、R语言的基础数据操作等。\n\n\n我结合自己学习R语言时的经验，也专门为编程零基础的医学生/医生等群体录制了R语言零基础入门的视频教程，已放在B站，且配套文档、数据都是免费的，无任何套路。各种在初学R时遇到的“坑”，我都替你踩过了，并且也在视频中指出来了。强烈建议没接触过R语言的朋友先去了解下基础知识，切勿直接上手实操！\n本书内容主要涉及模型建立、模型评价、模型比较3部分内容，其中模型建立和模型评价内容占比较多，模型比较部分主要是几个综合性R包的使用，简化多模型比较的流程。变量筛选内容较多，我把它单独放在一个章节中。对于临床预测模型中常见的列线图、C-index、ROC曲线、校准曲线、决策曲线、临床影响曲线、NRI、IDI等内容，皆进行了详细的操作演示（包括训练集、内部验证、外部验证），同时提供多种实现方法。\n本书并未对机器学习方法（如：随机森林、支持向量机、决策树、xgboost、岭回归/lasso回归、knn、GBM等）进行介绍，因为这又是一个全新的领域，虽然目前临床预测模型中经常会用到机器学习方法，但是都比较初级，使用也不规范。对于机器学习，我也专门出了一个合集进行介绍：R语言实战机器学习\n对于一些比较火爆的机器学习方法，如随机生存森林、生存支持向量机、提升法、神经网络等内容，本书也未进行介绍，公众号已更新这部分内容，需要的朋友可关注公众号：医学和生信笔记，并使用关键词搜索历史推文即可。\n\n\n\n\n\n\n注意\n\n\n\n本书是我基于公众号历史推文的重新整理和汇总，书中涉及的所有数据都可以在相关历史推文中免费获取！推文合集链接：临床预测模型。本书自上线以来一直在不断更新中，内容相较于原推文已经发生了较大变化，部分内容在公众号中可能没有。\n我也准备了一个PDF版合集，内容和网页版一致，只是打包了所有的数据，付费获取（10元），介意勿扰！PDF版合集获取链接：R语言实战临床预测模型\n\n\n限于本人水平等问题，难免会有一些错误，欢迎大家以各种方式批评指正，比如公众号留言、粉丝QQ群、github、个人微信等。\n本书会不定期更新，内容和格式都会不断完善。\n更新日志：\n\n20241108：这是一次比较大的更新。（1）修改各个章节内容和顺序，增加大量解释说明的内容和基础知识，合并一些内容，放在同一章节里，并适当精简一些内容；（2）模型评价部分增加新的评价内容，训练集和测试集分别演示；（3）增加tidymodels的使用以及内部验证/外部验证的内容；（4）每个指标和图形都增加解释内容，方便初学者理解；（5）增加样本量计算和缺失值插补相关内容；（6）增加模型比较的内容；（7）增加文献学习内容。\n20231230：优化内容结构和章节，增加变量筛选；增加列线图和决策曲线相关内容等\n20231015：首次上传",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "index.html#作者简介",
    "href": "index.html#作者简介",
    "title": "R语言实战临床预测模型",
    "section": "作者简介",
    "text": "作者简介\n\n阿越，外科医生，R语言爱好者，长期分享R语言和医学统计学、临床预测模型、生信数据挖掘、R语言机器学习等知识。\n哔哩哔哩：阿越就是我\nGithub：ayueme\n公众号：医学和生信笔记，欢迎扫码关注：",
    "crumbs": [
      "前言"
    ]
  },
  {
    "objectID": "临床预测模型概念.html",
    "href": "临床预测模型概念.html",
    "title": "1  什么是临床预测模型？",
    "section": "",
    "text": "1.1 简单理解\n临床预测模型，初听这个名字，或许会觉得很高大上，其实没那么复杂，你可以理解成一种方法，这种方法可以预测一个人到底是有病还是没病，或者预测一个人一段时间后会不会死，或者预测一个人的某种疾病会不会复发，又或者是预测一个样本到底是肿瘤还是正常组织……\n再直白一点，临床预测模型是一个数学公式，根据这个公式，你提供一些基本信息，比如年龄、性别、体重、血红蛋白量等（或者某个基因的表达量等），就可以计算出这个人到底是有病还是没病！\n目前很多疾病都需要做磁共振、做CT、病理才能确诊，假如你发现了一个公式，只要验个血，得到几个生化指标，就能根据你的公式算出来这个人到底是有病还是没病！这不比CT、磁共振、病理简单多了？值得推广。\n所以，临床预测模型的本质是一种分类方法。通过这种方法，你可以对临床中的很多东西进行分类，比如，生和死、有病和没病、肿瘤和非肿瘤、复发和不复发等等。\n既然是一种方法，那肯定就有准确和不准确，看名字也能知道，这只是一种预测，或者叫：猜（有根据的猜）！ 如果你这种方法能和金标准相提并论，那说明你的方法很牛，如果恰好你的方法更加简单方便、经济适用，那你的方法真是太厉害了，非常有希望成为新的金标准！\n那如何评价你的方法好还是不好呢？这就是临床预测模型的评价，通过各种指标（后面会详细介绍）、从各种不同的角度评价。\n说了这么多，我怎么才能得到我的模型（或者叫方法）呢？这就是临床预测模型的另一个主要内容：临床预测模型的建立。\n前面说过，临床预测模型本质上就是一个公式而已！说个最简单的，逻辑回归（logistic），大家应该都知道怎么构建逻辑回归吧？不就是自变量和因变量吗。给你几个自变量，一个二分类的因变量，大家通过SPSS点点点，就可以得到各个自变量的系数，然后就能写出逻辑回归方程了。你的这个逻辑回归方程，这就是一个临床预测模型了！给你几个自变量的值，根据这个方程，你就可以算出因变量的值，然后就可以分类了！\n说到这里，相信你应该明白很多了！但是这还不够，你可能还听过什么机器学习、lasso、随机森林、支持向量机等等，别慌，这就是我们接下来要说的：临床预测模型和机器学习的关系。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>什么是临床预测模型？</span>"
    ]
  },
  {
    "objectID": "临床预测模型概念.html#临床预测模型和机器学习",
    "href": "临床预测模型概念.html#临床预测模型和机器学习",
    "title": "1  什么是临床预测模型？",
    "section": "1.2 临床预测模型和机器学习",
    "text": "1.2 临床预测模型和机器学习\n机器学习，是不是听上去也高大上，但是对于学习临床医学的我们来说，不需要知道的太彻底，大概明白是什么就够了。\n逻辑回归也是机器学习的一种，随机森林、决策树、支持向量机、lasso、岭回归、弹性网络、xgboost等等，这些都是和逻辑回归一样，只是不同的方法而已！\n学过医学统计学的都知道（没学过可能也知道），如果因变量是连续性变量，那么我们就用多元线性回归，如果因变量是二分类变量，就用logistic回归（分类）。回归和分类，刚好就是机器学习的两个主要任务。很多方法，比如随机森林，既可以做回归，又可以做分类，而且准确度还很高，这就是为什么大家喜欢用其他方法的原因，主要是为了提高准确性。\n临床预测模型，只是机器学习在医学领域的应用之一，回归和分类，适用于各行各业，所以在很多领域你都听过机器学习这几个字。此外，还有深度学习、人工智能等等，这些都可以简单的理解为更加牛逼的方法！\n这些不同的方法都有各自适合的场景，在合适的场景下才能得到最好的表现，如何让模型表现的更好，那就需要学习一些机器学习的基本知识了，这些东西在bilibili一搜一大堆，大家可以自行学习，不过千万不要太沉迷哟！\n但是你一搜机器学习教程，出来的都是推荐你吴恩达、西瓜书等内容，我是不太推荐的，这些东西不是给医学生/医生看的，你看这些，可能就是看天书，毕竟很多医学生，连高数都是不学的！我比较推荐statquest，b站也可以搜到，这是一个国外的生物统计教授的课程，他的风格更适合我们。不过在学习这些这些之前，希望你已经学会了书本中常见的医学统计知识。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>什么是临床预测模型？</span>"
    ]
  },
  {
    "objectID": "临床预测模型概念.html#临床预测模型和统计学",
    "href": "临床预测模型概念.html#临床预测模型和统计学",
    "title": "1  什么是临床预测模型？",
    "section": "1.3 临床预测模型和统计学",
    "text": "1.3 临床预测模型和统计学\n我们学过的医学统计学，在某些方面和机器学习是有交集的。比如，逻辑回归、多元线性回归，既是统计学方法，也是机器学习算法，这并不冲突，就像一个人在不同场合有不同身份一样。\n在谈临床预测模型时，我们可能是偏向于机器学习多一点的，毕竟用到的很多方法和理论，都是来自于机器学习领域。但是随着临床预测模型的愈加火爆，它隐隐有成为一个单独细分领域的趋势。\n你可能见到在很多生信文章中，使用一个模型并没有提前检验各种条件，直接就用了。但在医学统计学中，很多方法都是有适用条件的，符合条件才能用。哪种才是正确的呢？\n其实不用纠结，别人能用你也能用，多看文章，你能发现各种用法，但是别人依然发了SCI，你也可以。如果非要说区别，这就涉及到频率学派和贝叶斯学派这些东西了，咱也不是很懂了，如果你有兴趣，可以自己探索。如果就是为了发文章，那就别搞这些没用的了，多看几篇高分SCI，跟着里面的思路模仿吧！\n读到这里，你应该大致解临床预测模型，不致于云里雾里了。但是光说不练是假把式，还是希望你能多读几篇相关的文献。我也会在后面的章节中给大家介绍一些临床预测模型领域的经典文献。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>什么是临床预测模型？</span>"
    ]
  },
  {
    "objectID": "临床预测模型建立的一般步骤.html",
    "href": "临床预测模型建立的一般步骤.html",
    "title": "2  临床预测模型建立的一般步骤",
    "section": "",
    "text": "2.1 明确研究目的\n首先要明确你的研究目的。\n不同的研究目的需要使用不同的模型，对应的模型评价方法、预处理方法、模型比较方法都不一样，不能生搬硬套。\n以上四个问题其实可以分为三类，刚好对应着模型的三种用途：\n如果你的结果变量（或者叫应变量、因变量）是数值型的，比如血糖、血压、血钾这种，那么你需要选择一个可以做回归分析的模型（大部分机器学习方法都是既支持回归也支持分类），此时你选择逻辑回归必然是不行的。\n如果你的结果变量是分类型的，比如生存/死亡，tumor/normal，治愈/有效/无效，患病/不患病，那么你需要选择一个可以做分类分析的模型。\n以上两种类型的模型通常会被大家称为诊断模型。\n如果你的数据涉及到时间问题，那么你需要选择一个可以做生存分析的模型。这种模型通常被大家称为预后模型。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>临床预测模型建立的一般步骤</span>"
    ]
  },
  {
    "objectID": "临床预测模型建立的一般步骤.html#明确研究目的",
    "href": "临床预测模型建立的一般步骤.html#明确研究目的",
    "title": "2  临床预测模型建立的一般步骤",
    "section": "",
    "text": "你是要预测某个患者在10年后的生存状态吗？\n你还是要判断某个病理标本是tumor还是normal？\n你是要计算患者在使用某个药物后的空腹血糖水平吗？\n你还是要预测心梗患者的死亡风险？\n\n\n\n\n分类\n回归\n生存分析",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>临床预测模型建立的一般步骤</span>"
    ]
  },
  {
    "objectID": "临床预测模型建立的一般步骤.html#探索数据",
    "href": "临床预测模型建立的一般步骤.html#探索数据",
    "title": "2  临床预测模型建立的一般步骤",
    "section": "2.2 探索数据",
    "text": "2.2 探索数据\n探索数据的过程非常重要，充分了解你的数据，这个过程有个专业的名词叫**探索性数据分析（exploratory-data-analysis，EDA），主要包括以下几个方面：\n\n共有多少行？多少列？\n哪些是自变量，哪些是因变量？\n每个变量的含义是什么？\n有没有缺失值？离群值？异常值？需不需要处理？\n有没有偏态分布？需不需要处理？\n每个变量是数值型还是分类型？需要转换吗？\n各个变量的单位是否需要转换？需要归一化吗？\n各个变量之间有没有相关性？共线性？零方差？需要处理吗？\n……\n\n每一个问题都很重要，都要搞清楚！不同的模型对数据的要求是不一样的，有的要求不能有缺失值，有的模型要求数据必须归一化等等，这些问题对开发一个准确的、高性能的模型是必须的。\n有些人连自己的数据是啥都不了解，就开始生搬硬套代码，最后得到shit一样的结果，然后到处问：为什么我的模型这么垃圾？滑稽。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>临床预测模型建立的一般步骤</span>"
    ]
  },
  {
    "objectID": "临床预测模型建立的一般步骤.html#数据预处理和变量筛选",
    "href": "临床预测模型建立的一般步骤.html#数据预处理和变量筛选",
    "title": "2  临床预测模型建立的一般步骤",
    "section": "2.3 数据预处理和变量筛选",
    "text": "2.3 数据预处理和变量筛选\n探索完你的数据之后，你就要根据自己选择的模型进行相应的预处理，而且不同的预处理步骤有一定的顺序。\n这一步需要你有一定的专业知识、统计学知识、机器学习知识，其实很难，大家可以遇到了具体问题具体搜索。\n下面是对不同模型推荐的预处理步骤(推荐，不是必需一定要按这个来！！)：\n\n名词解释：\n\ndummy：对分类变量进行哑变量处理，或者进行其他重编码\nzv：去除方差为0（zero-variance）或者近似为0的变量\nimpute：对缺失值进行插补\ndecorrelate：处理有共线性或者高度相关的变量\nnormalize：对数据进行标准化\ntransform：对变量进行转换，比如log、取对数、分箱等\n\n变量选择(又叫特征选择,feature-selection)，是机器学习和统计建模领域非常重要的问题，到底哪些变量是有用的，哪些是不重要的，可以删除的，怎么选才能提高模型表现，理论其实非常复杂。\n比如有个数据共有26个自变量，可能其中只有几个是重要的，其他的有没有都不重要或者对模型影响不大，这时候就要把不重要的变量筛掉。\n在传统的临床预测模型中，比较常见的变量筛选方法有：\n\n先单因素后多因素\n最优子集（全子集回归）\n逐步选择法\nlasso回归筛选变量\n随机森林筛选变量\n…",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>临床预测模型建立的一般步骤</span>"
    ]
  },
  {
    "objectID": "临床预测模型建立的一般步骤.html#建立模型",
    "href": "临床预测模型建立的一般步骤.html#建立模型",
    "title": "2  临床预测模型建立的一般步骤",
    "section": "2.4 建立模型",
    "text": "2.4 建立模型\n这一步其实是大家遇到的最多的一步，可能也是大多数人的第一步。这里的“建立模型”其实是狭义的，就是单指“在训练集拟合模型”这一步，广义的“建立模型”包括本文所说的所有步骤。\n这一步涉及到的主要知识点是各种重抽样方法的选择，比如boostrap（自助法，也有人翻译成拔靴法）、交叉验证、嵌套重抽样等。\n但是写代码时其实就是1行代码而已，没有难度，需要大家理解每一种重抽样方法。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>临床预测模型建立的一般步骤</span>"
    ]
  },
  {
    "objectID": "临床预测模型建立的一般步骤.html#评价模型",
    "href": "临床预测模型建立的一般步骤.html#评价模型",
    "title": "2  临床预测模型建立的一般步骤",
    "section": "2.5 评价模型",
    "text": "2.5 评价模型\n这一步其实是最复杂的，因为从第二步（探索数据）到这一步其实是一个不断重复循环的过程，可能你建立一个模型之后发现这个模型表现很烂，那么你需要重新审视之前的每一个过程，因为每一步都会对模型表现产生影响，你就需要不断对之前的步骤进行调整，也就是不断地重复之前的过程。通常你可能需要重复好多次之后才能得到满意的结果。\n而且模型的评价现在需要在不同的数据集中分别评价，比如：训练集、测试集、外部验证集等。有时候你的训练集模型表现很好但是测试集不一定好，那你是不是得找原因？如果你没有超级强大的知识储备，对你来说最简单的可行方案就是挨个试（对高手来说这一步也必不可少，只是写论文不需要写这个过程）。\n除此之外，对于不同的研究目的和不同的模型需要选择不同的评价指标。对于分类问题你需要选择能够评价分类问题的指标，对于回归问题你需要选能够择评价回归问题的指标，对于生存问题你需要选择能够评价生存问题的指标。不能混用，不然必报错！\n同样是分类问题，研究目的不同使用的指标也不一样，比如：你是想获得更大的敏感度还是更大的特异度？换个说法就是：你想要更高的误诊率还是更大的漏诊率？类别的不平衡对某些指标影响很大，你的研究能忽略这种问题吗？不能的话就要选择适合评价类不平衡数据的指标。诸如此类的问题，都和指标选择有关。\n当你通过一通操作确定了最终的模型之后，你就可以画个列线图展示你的模型了，除此之外还可以根据列线图得分进行分组，做生存分析、亚组分析等。\n如果你还想更加高大上一点，你还可以用shiny做个网页计算器。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>临床预测模型建立的一般步骤</span>"
    ]
  },
  {
    "objectID": "临床预测模型建立的一般步骤.html#结果报告和写作",
    "href": "临床预测模型建立的一般步骤.html#结果报告和写作",
    "title": "2  临床预测模型建立的一般步骤",
    "section": "2.6 结果报告和写作",
    "text": "2.6 结果报告和写作\n全都搞定之后就可以写文章了，不会写的话就pubmed关键词搜一搜，模仿一下即可。除此之外还有一个TRIPOD指南，上面也有建议你需要写哪些东西。\n\n\n\n\n\n\n注释\n\n\n\n本合集并不是按照以上顺序编排的，本合集是模块化的，把这么多步骤分成不同的部分，每个部分都做详细介绍，方便大家学习。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>临床预测模型建立的一般步骤</span>"
    ]
  },
  {
    "objectID": "临床预测模型和机器学习.html",
    "href": "临床预测模型和机器学习.html",
    "title": "3  临床预测模型和机器学习",
    "section": "",
    "text": "3.1 从医学统计到机器学习\n机器学习离医学生/医生很遥远吗？\n并不是，其实大家都学过。\n结合我们的医学背景讲，机器学习是能够帮我们决策的工具。机器学习中的部分内容我们并不陌生。\n医学统计学中都学过多元线性回归、logistic回归、判别分析、聚类分析等，这些都是机器学习的范畴，都属于机器学习的方法。只不过是所处的情境不同，就像一个人可以有多种身份。\n在logistic回归中，我们通过多个自变量建立logistic回归方程，由此来判断因变量的状态，比如患病/不患病，肿瘤/非肿瘤，死亡/生存等；在多元线性回归中，我们可以通过多个自变量预测患者的血糖水平。\n这些问题在医学统计学中，我们的目的是探寻自变量和因变量的关系，在机器学习中也是一样的用法，不过此时的目的更偏向于预测结果。除此之外，机器学习面向的主要是大样本量的数据，而医学统计学在使用这些方法时，通常是样本量不大的。\n除了我们学习过的多元线性回归、logistic回归等，还有一些医学统计学中没有讲到的内容，比如大家经常见到的：随机森林，lasso/ridge/elastic net，支持向量机，knn等，都属于机器学习的内容，都是类似的用法，用多个自变量预测一个因变量。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>临床预测模型和机器学习</span>"
    ]
  },
  {
    "objectID": "临床预测模型和机器学习.html#从医学统计到机器学习",
    "href": "临床预测模型和机器学习.html#从医学统计到机器学习",
    "title": "3  临床预测模型和机器学习",
    "section": "",
    "text": "医学统计学是一门运用统计学的原理和方法，研究医学科研中有关数据的收集、整理和分析的应用科学。–孙振球，徐勇勇《医学统计学》第4版\n\n\n机器学习是一门多学科交叉专业，涵盖概率论知识，统计学知识，近似理论知识和复杂算法知识，使用计算机作为工具并致力于真实实时的模拟人类学习方式，并将现有内容进行知识结构划分来有效提高学习效率。–百度百科",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>临床预测模型和机器学习</span>"
    ]
  },
  {
    "objectID": "临床预测模型和机器学习.html#机器学习在临床中的应用",
    "href": "临床预测模型和机器学习.html#机器学习在临床中的应用",
    "title": "3  临床预测模型和机器学习",
    "section": "3.2 机器学习在临床中的应用",
    "text": "3.2 机器学习在临床中的应用\n机器学习在很多领域应用广泛，在医学领域，大家经常接触的主要是以下几个方面：\n\n影像组学\n生信数据挖掘\n临床预测模型\n……\n\n这里面我认为最简单的就是临床预测模型。\n另外两个需要额外学习的背景知识太多，对于医学生/医生，尤其是临床医学、中医学等，不亚于从0开始学习一门技能。\n今天我们简单介绍下机器学习和临床预测模型的应用。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>临床预测模型和机器学习</span>"
    ]
  },
  {
    "objectID": "临床预测模型和机器学习.html#机器学习和临床预测模型有什么关系",
    "href": "临床预测模型和机器学习.html#机器学习和临床预测模型有什么关系",
    "title": "3  临床预测模型和机器学习",
    "section": "3.3 机器学习和临床预测模型有什么关系？",
    "text": "3.3 机器学习和临床预测模型有什么关系？\n首先大家要明确，临床预测模型是什么？\n\n临床预测模型的本质是一种分类方法。通过这种方法，你可以对很多东西进行分类，比如，生和死、有病和没病、肿瘤和非肿瘤、复发和不复发等等。\n再直白一点，临床预测模型是一个公式，根据这个公式，你提供一些基本信息，比如年龄、性别、体重、血红蛋白量等（或者某个基因的表达量等），就可以计算出这个人到底是有病还是没病！–《简单易懂：什么是临床预测模型》\n\n你看这个过程是不是和我们上面建立多元线性回归、logistic回归的过程一模一样？也是多个自变量和一个因变量的故事。\n所以，临床预测模型的各种实现，都是通过机器学习的方法完成的（你非说是通过统计学的方法也可以，因为二者本来就没有清晰的界限）。这其中比较简单的也是比较常见的是logistic回归、cox回归这些，其他方法，如随机森林、SVM、各种提升算法等，也都逐渐开始使用。\n除此之外，大家常见的各种重抽样方法，比如bootstrap、cross validation、holdout(train/test split)等，都是机器学习中常见的基本内容。\n各种对变量的处理，比如：中心化、标准化、缺失值插补、样条回归、boxcox、向前/向后/逐步选择、最优子集，等，也都是机器学习的基础内容。\n唯一不同且是最重要的一点：临床预测模型更加注重结合临床背景进行解释。\n不同于机器学习中变量重要性(随机森林)这种解释，我们更喜欢OR/HR/RR这种解释，自变量每增加一个单位，因变量的危险增加多少、大于60岁的人相比于小于60岁的人，患某病的风险增加多少。\n临床预测模型必须不能脱离临床，单纯的数字游戏没有任何意义。\n\n很多讲临床预测模型的课程，涉及的机器学习基本方法太少，指南里的东西大家都知道，满足不了大家发文章的需求。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>临床预测模型和机器学习</span>"
    ]
  },
  {
    "objectID": "临床预测模型和机器学习.html#当我们谈论临床预测模型时我们在谈些什么",
    "href": "临床预测模型和机器学习.html#当我们谈论临床预测模型时我们在谈些什么",
    "title": "3  临床预测模型和机器学习",
    "section": "3.4 当我们谈论临床预测模型时，我们在谈些什么？",
    "text": "3.4 当我们谈论临床预测模型时，我们在谈些什么？\n这个答案大家应该都很感兴趣：文章！SCI！\n临床预测模型本质上应该是为医务人员提供新的诊疗工具、决策工具，开发更为快捷、简便、性价比高的量化工具。比较熟悉并且十分成功的案例：肿瘤的TNM分期。\n但是目前来看，主要作用是为大家提供新的发文方式！\n\n\n绝大多数临床预测模型类文章都没有实用价值。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>临床预测模型和机器学习</span>"
    ]
  },
  {
    "objectID": "临床预测模型和机器学习.html#机器学习与临床预测模型需要哪些知识",
    "href": "临床预测模型和机器学习.html#机器学习与临床预测模型需要哪些知识",
    "title": "3  临床预测模型和机器学习",
    "section": "3.5 机器学习与临床预测模型需要哪些知识",
    "text": "3.5 机器学习与临床预测模型需要哪些知识\n\n3.5.1 统计学知识\n这块知识对于大家应该不陌生，很好上手。\n医学统计学，特别是多元线性回归、logistic回归、Cox回归，需要重点掌握。\n除此之外，需要学习一些课本上没有的、但是文献中经常见的统计学方法和指标。\n灵活使用，举一反三，不能还停留在t检验、方差分析的阶段，需重点掌握结果的解释。\n\n\n3.5.2 机器学习基础\n这部分内容需要重新学习，但是不需要掌握复杂的原理，数学公式推导等，需要学会：\n\n常见的数据预处理方法：Garbage In, Garbage Out\n\n对数值型变量的处理\n\n中心化、标准化、零方差/近零方差、共线性、分箱、样条变换、等\n\n对分类变量的处理：哑变量/独热编码等\n对因变量的处理：类不平衡\n缺失值处理：删除、插补\n\n特征工程：特征选择\n超参数调优\n\n存在的问题：处理后不管是单位还是尺度都已变化，怎么解释？\n除此之外，还需学习常见的机器学习算法：\n\n线性回归\nlogistic回归\nlasso/ridge/elastic net\n决策树\n集成算法：随机森林、梯度提升树等\nKNN\nSVM\n和生存分析相关的机器学习算法：正则化Cox、随机生存森林、survival SVM、Coxboost等\n聚类分析、主成分分分析、因子分析\n……\n\n对于以上算法，只需学会使用即可，知道哪些算法可以用于什么样的数据、需要哪些数据预处理，结果如何解读等。\n\n\n3.5.3 统计软件和编程\n\nSPSS，简单方便\nR语言，必学！\n\n我是医学生，R和python我应该学哪一个？\n\npython，影像组学建议学\nLinux，生信数据挖掘建议学\n\n\n\n3.5.4 附:如果你要学习生信数据挖掘\n下游分析需要掌握的基础知识：\n以上所有，外加：\n什么是芯片，常用的芯片平台有哪些？ 什么是GEO？表达矩阵，探针id转换？\n什么是一代测序，二代测序，三代测序？ 什么是counts，tpm, fpkm？ 什么是TCGA？ TCGA包含哪些数据？ 什么是编码基因？mRNA, lncRNA, miRNA, circRNA等？ 生信常见的各种数据库id, hgnc gene symbol, entrez id, ensembl id等？ 中心法则？ 表观遗传涉及哪些内容？ 什么是甲基化？单核苷酸多态性SNP, 拷贝数变异CVN？\n什么是gtf, gff, 参考基因组，基因组注释文件？ 常见的生信数据存放格式?fastp, fastq, bam, sam,\n氨基酸缩写？ 人类染色体命名规则？\n常见的生信下游分析方法？差异分析，生存分析，富集分析，WGCNA，免疫相关分析，治疗相关分析等，在不同数据类型（转录组、甲基化等）中？\n…\n上游分析需要的知识也很多。\n\n我的主要学习阵地：哔哩哔哩！解决你80%的问题",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>临床预测模型和机器学习</span>"
    ]
  },
  {
    "objectID": "临床预测模型和机器学习.html#临床预测模型常见发文类型",
    "href": "临床预测模型和机器学习.html#临床预测模型常见发文类型",
    "title": "3  临床预测模型和机器学习",
    "section": "3.6 临床预测模型常见发文类型",
    "text": "3.6 临床预测模型常见发文类型\n临床预测模型类文章主要内容是3个部分：\n\n模型的建立-各种算法，logistic、决策树等等\n模型的评价-各种指标和图表，ROC、C-index、校准曲线、决策曲线等等\n模型的解释：临床预测模型必须不能脱离临床，单纯的数字游戏没有任何意义。\n\n\n3.6.1 比较简单的\n\n算法不复杂，步骤也不复杂。只需要logistic回归、Cox回归、Lasso即可。\n\n\n诺莫图预测 转移性去势抵抗性前列腺癌经过 Lu177-PSMA 治疗后 的预后\n\n收集一些病人，监测一些指标，建立cox回归，评价模型，解释模型。\n  \n\n\n3.6.2 更加典型的案例\n\n训练集+测试集，各来一遍，各种图、指标都用上：nomogram、ROC曲线、校准曲线、决策曲线、K-M生存曲线、C-index等。\n\n\n临床预测模型评估COVID-19患者的风险\n\n收集一些病人，监测一些指标，建立模型，评价模型，解释模型\n\n\n\n3.6.3 机器学习方法的使用\n\n随机森林、决策树\n\n\n老年人跌倒损伤的预测模型\n\n收集一些病人，监测一些指标，建立随机森林模型，评价模型，解释模型\n\n\nCross Validated Elastic regularized logistic regression method (cv-Enet), boosting linear regression (glmboost), random forest, and an ensemble model\n\n\n胃切除术后90天死亡率的风险预测模型\n\n收集一些病人，监测一些指标，建立多种模型，评价模型，解释模型\n\n\n随机生存森林\n\n\n预测肝癌术后早期复发，的机器学习模型",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>临床预测模型和机器学习</span>"
    ]
  },
  {
    "objectID": "临床预测模型和机器学习.html#临床预测模型和生信数据挖掘结合",
    "href": "临床预测模型和机器学习.html#临床预测模型和生信数据挖掘结合",
    "title": "3  临床预测模型和机器学习",
    "section": "3.7 临床预测模型和生信数据挖掘结合",
    "text": "3.7 临床预测模型和生信数据挖掘结合\n也可以认为是机器学习和生信挖掘领域的结合，基本思路和常规的临床预测模型差不多，比上面介绍的临床预测模型内容更多，主要是两个方面：\n\n变量的选择\n指标的评价\n\n有了生信的加持，可以玩出更多花样！扩展性极大提高！工作量也成倍增加，通常此类文章机器学习只是其中一部分内容。\n\n3.7.1 生信数据挖掘，到底在挖什么？\n\n本质是通过各种方法得到一小撮分子，再通过各种方法证明这些分子很重要！\n\n寻找分子的过程通常也属于变量选择的过程，因为高通量最不缺的就是变量！ 这些分子通常是mRNA/lncRNA/miRNA等。\n一些常见的方法：\n\n差异分析\n生存分析\nWGCNA\n免疫浸润\nhub gene\n多种方法取交集等\n……\n\n然后建立模型，这部分内容和临床预测模型差不多，也是建立各种机器学习算法：\n\nlasso\ncox\nlogistic\n随机森林/随机生存森林\n决策树\nSVM\nKNN\n神经网络\n……\n\n评价模型，和临床预测模型相似的内容：\n\n列线图\n校准曲线\n决策曲线\nROC曲线\n生存曲线\nC-index/AUC\n……\n\n除此之外，还有一些生信数据挖掘特有的部分：必须和治疗/预后扯上关系\n\n和免疫浸润结合\n和富集分析结合\n和免疫治疗结合\n和其他signature/模型/指标比较\n各种分子分型\n……\n\n\n生信数据挖掘文章还有一个特点：紧跟热点\n\n铁死亡、铜死亡、细胞凋亡、内质网应激、肿瘤干性、缺氧、m6A、上皮-间质转化、凝血、血管生成、……\n理论上你去GO或者KEGG的官网，所有的分子集合都可以挖一遍；所有病理生理过程涉及的分子也都可以挖一遍（离子通道）。\n\n生信数据挖掘典型花里胡哨图：\n\n\n\n\n3.7.2 比较简单的\n最早期的临床预测模型和生信数据挖掘结合的思路：\n\ngene signature、基因家族等\n\n通过各种方法找几个基因构建模型（早期，硬筛）\n\n2022年了，这种远古套路依然可以发！因为他加了实验……\n\n铁死亡相关的gene signature（某个病理生理过程相关的分子）\n\n\n思路不新，也没有实验，但是疾病没人挖掘：儿童败血性休克，机器学习只占一小部分内容，主要是寻找分子以及说明重要性：\n\n\n\n3.7.3 复杂的\n\n超级复杂的工作量、泛癌、单细胞、实验验证\n\n\n细胞衰老和肿瘤微环境：机器学习内容是其中一小部分，但是不可或缺。\n\n\n恐怖的工作量：单是机器学习部分就有10种机器学习算法的101种组合(非常火爆的101种组合算法就是来自这篇文章！)！以及和其他已发表的模型进行比较！",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>临床预测模型和机器学习</span>"
    ]
  },
  {
    "objectID": "临床预测模型和机器学习.html#总结",
    "href": "临床预测模型和机器学习.html#总结",
    "title": "3  临床预测模型和机器学习",
    "section": "3.8 总结",
    "text": "3.8 总结\n\n常用的方法就那么几个，只要认真学习，都能学会！\n对一些细节的处理、结果的解释、好的思路和想法更加重要！用工具解决一个问题是最简单的层面\n医学中的机器学习更加强调结合医学背景的解释，并不单单是得到更好的模型表现即可，得到模型后结合背景知识进行更加深入的谈论是必不可少的内容，也是和传统机器学习领域最大的不同之处。\n\n感谢大家，祝大家百发百中！",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>临床预测模型和机器学习</span>"
    ]
  },
  {
    "objectID": "文献学习.html",
    "href": "文献学习.html",
    "title": "4  文献学习",
    "section": "",
    "text": "4.1 文献学习\n相关文献解读，点击直达：",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>文献学习</span>"
    ]
  },
  {
    "objectID": "文献学习.html#文献学习",
    "href": "文献学习.html#文献学习",
    "title": "4  文献学习",
    "section": "",
    "text": "机器学习算法识别结直肠癌中的免疫相关lncRNA signature\n文献学习：机器学习帮助临床决策\n文献学习：机器学习方法帮助缩短就诊时间\nSEER数据库+临床预测模型，一篇中规中矩的高分文献学习（IF：16）\n新鲜出炉的lancet-oncology(IF:51)预测模型文章：列线图预测黑色素瘤患者的预后（含全部代码）\n文献学习：MIMIC-IV+eICU+临床预测模型\nmeta分析+临床预测模型，简单可学习的IF=4.7文章学习",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>文献学习</span>"
    ]
  },
  {
    "objectID": "文献学习.html#经典文献",
    "href": "文献学习.html#经典文献",
    "title": "4  文献学习",
    "section": "4.2 经典文献",
    "text": "4.2 经典文献\n除此之外，对于临床预测模型还有一些经典的指导性文献，部分内容已在本书介绍，还有很多建议大家自己学习，这些文献都是经典，这里给大家找了十几篇超级无敌经典的相关文献，每一篇都是经典，涉及：\n\n模型建立的步骤、\n模型评价、\n缺失值处理、\n样本量计算、\n数据划分（内外部验证、bootstrap等）\n论文写作等多个方面。\n\n17篇文献的详细信息如下所示，为了方便大家学习，我已经把这17篇文献整理好了，公众号后台回复20240608即可获取全部文献。\n\nCollins G S, Moons K G M, Dhiman P, et al. TRIPOD+AI statement: updated guidance for reporting clinical prediction models that use regression or machine learning methods[J]. BMJ (Clinical research ed.), 2024, 385: e078378. DOI:10.1136/bmj-2023-078378.\nCollins G S, Reitsma J B, Altman D G, et al. Transparent reporting of a multivariable prediction model for individual prognosis or diagnosis (TRIPOD): the TRIPOD statement[J]. British Medical Journal, 2015, 350(jan07 4): g7594–g7594. DOI:10.1136/bmj.g7594.\nSteyerberg E W, Vergouwe Y. Towards better clinical prediction models: seven steps for development and an ABCD for validation[J]. European Heart Journal, 2014, 35(29): 1925–1931. DOI:10.1093/eurheartj/ehu207.\nVan Calster B, Wynants L, Verbeek J F M, et al. Reporting and Interpreting Decision Curve Analysis: A Guide for Investigators[J]. European Urology, 2018, 74(6): 796–804. DOI:10.1016/j.eururo.2018.08.038.\nBalachandran V P, Gonen M, Smith J J, et al. Nomograms in Oncology – More than Meets the Eye[J]. The Lancet. Oncology, 2015, 16(4): e173–e180. DOI:10.1016/S1470-2045(14)71116-7.\nSterne J A C, White I R, Carlin J B, et al. Multiple imputation for missing data in epidemiological and clinical research: potential and pitfalls[J]. BMJ (Clinical research ed.), 2009, 338: b2393. DOI:10.1136/bmj.b2393.\nArcher L, Snell K I E, Ensor J, et al. Minimum sample size for external validation of a clinical prediction model with a continuous outcome[J]. Statistics in Medicine, 2021, 40(1): 133–146. DOI:10.1002/sim.8766.\nRiley R D, Debray T P A, Collins G S, et al. Minimum sample size for external validation of a clinical prediction model with a binary outcome[J]. Statistics in Medicine, 2021, 40(19): 4230–4251. DOI:10.1002/sim.9025.\nRiley R D, Collins G S, Ensor J, et al. Minimum sample size calculations for external validation of a clinical prediction model with a time-to-event outcome[J]. Statistics in Medicine, 2022, 41(7): 1280–1295. DOI:10.1002/sim.9275.\nRiley R D, Snell K I E, Archer L, et al. Evaluation of clinical prediction models (part 3): calculating the sample size required for an external validation study[J]. British Medical Journal, 2024, 384: e074821. DOI:10.1136/bmj-2023-074821.\nRiley R D, Archer L, Snell K I E, et al. Evaluation of clinical prediction models (part 2): how to undertake an external validation study[J]. British Medical Journal, 2024, 384: e074820. DOI:10.1136/bmj-2023-074820.\nCollins G S, Dhiman P, Ma J, et al. Evaluation of clinical prediction models (part 1): from development to external validation[J]. British Medical Journal, 2024, 384: e074819. DOI:10.1136/bmj-2023-074819.\nAlba A C, Agoritsas T, Walsh M, et al. Discrimination and Calibration of Clinical Prediction Models: Users’ Guides to the Medical Literature[J]. JAMA, 2017, 318(14): 1377–1384. DOI:10.1001/jama.2017.12126.\nStrandberg R, Jepsen P, Hagström H. Developing and validating clinical prediction models in hepatology—An overview for clinicians[J]. Journal of Hepatology, 2024: S0168-8278(24)00213–7. DOI:10.1016/j.jhep.2024.03.030.\nFitzgerald M, Saville B R, Lewis R J. Decision curve analysis[J]. JAMA, 2015, 313(4): 409–410. DOI:10.1001/jama.2015.37.\nRd R, J E, Kie S, et al. Calculating the sample size required for developing a clinical prediction model[J]. British Medical Journal, BMJ, 2020, 368. DOI:10.1136/bmj.m441.\nEfthimiou O, Seo M, Chalkou K, Debray T, Egger M, Salanti G. Developing clinical prediction models: a step-by-step guide. BMJ. 2024 Sep 3;386:e078276. doi: 10.1136/bmj-2023-078276. PMID: 39227063; PMCID: PMC11369751.",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>文献学习</span>"
    ]
  },
  {
    "objectID": "data-split.html",
    "href": "data-split.html",
    "title": "5  常见的数据划分方法",
    "section": "",
    "text": "5.1 留出法(holdout)\n大家最常使用的，把数据集随机划分为训练集(train)/测试集(test)的做法就是holdout，其中训练集用于建模，测试集用于评估模型表现。测试集有时也被称为验证集(validation)。\n如果你的数据样本量足够大，大到几乎不可能产生错误的结果，那你可以大胆放心用这种方法，否则一般都不推荐只使用这种方法。\n通常的做法是把数据集划分为训练集/测试集后，在训练集中建立模型，当确定最终的模型后，我们会让模型对测试集进行预测，以评估模型最终的表现。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>常见的数据划分方法</span>"
    ]
  },
  {
    "objectID": "data-split.html#交叉验证cross-validation",
    "href": "data-split.html#交叉验证cross-validation",
    "title": "5  常见的数据划分方法",
    "section": "5.2 交叉验证(cross validation)",
    "text": "5.2 交叉验证(cross validation)\n交叉验证，意思就是一份数据既用作训练，也用作验证，互相交叉，主要有以下几种：\nK折交叉验证(K fold cross validation)，就是把数据集随机分为K个样本量基本相同的子数据集。比如5折交叉验证，就是把数据集分为5个子集（比如分成A,B,C,D,E,5份），在建模时，首先会使用其中A,B,C,D,4份数据进行建模，然后用剩下的E数据评估模型表现，接下来使用A,B,C,E，4份数据建模，用剩下的D评估模型表现。这样依次进行5个循环，每份数据都会用来评估模型表现。这样就会得到5个模型，就会有5个结果，最后将得到的5个模型表现结果进行汇总作为最终的结果。\n下面是一个5折交叉验证的示意图，我们把所有数据分为训练集和测试集，然后在训练集建立模型，建立模型时，对训练集使用了5折交叉验证的方法：\n\n留一交叉验证(LOOCV, leave one out cross validation)，是K折交叉验证的特例。每次都只留1个样本用于评估模型表现，所以这里的K其实就等于样本量，每一个样本都会被用来评估模型表现。\n重复交叉验证(repeated cross validation)，也是K折交叉验证的扩展版本，比如，重复10次的5折交叉验证，就是把5折交叉验证这个过程重复10遍。\n蒙特卡洛交叉验证(Monte Carlo cross validation)，也是交叉验证的一个变种。留出法是将数据集划分1次，而蒙特卡洛交叉验证就是将留出法进行多次。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>常见的数据划分方法</span>"
    ]
  },
  {
    "objectID": "data-split.html#bootstrap",
    "href": "data-split.html#bootstrap",
    "title": "5  常见的数据划分方法",
    "section": "5.3 bootstrap",
    "text": "5.3 bootstrap\n自助法，即有放回的随机抽样法。具体做法如下：\n比如，一个数据集有100个样本，每次随机抽取1个，然后放回去，再随机抽取1个，再放回去，这样的过程重复100次，就得到了一个和原数据集样本量相等的抽样数据集，这个抽样数据集就叫做自助集或自助样本。\n由于每次都是有放回然后再随机抽取，所以一个自助集中可能有多个同一样本！所以就有可能在100次随机抽取中，有一些没被抽中过的样本，这些样本就被称为袋外样本(out-of-bag，OOB)，其中被抽中的样本(也就是自助集)用于训练模型，袋外样本用来评估模型表现。\n如果设置bootstrap的次数是10，就是抽取10个自助集，10个袋外样本，在每个自助集中训练一个模型，并在相应的袋外样本中评估模型，这样就会得到10个模型表现，对它们取平均值，就是最终的模型表现。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>常见的数据划分方法</span>"
    ]
  },
  {
    "objectID": "data-split.html#其他方法",
    "href": "data-split.html#其他方法",
    "title": "5  常见的数据划分方法",
    "section": "5.4 其他方法",
    "text": "5.4 其他方法\n除了以上方法，其实还有非常多没有介绍，比如在mlr3中经常使用的嵌套重抽样，这些大家感兴趣可以自行了解。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>常见的数据划分方法</span>"
    ]
  },
  {
    "objectID": "data-split.html#内部验证外部验证",
    "href": "data-split.html#内部验证外部验证",
    "title": "5  常见的数据划分方法",
    "section": "5.5 内部验证/外部验证",
    "text": "5.5 内部验证/外部验证\n临床预测模型中会有内部验证/外部验证的说法，内部验证又叫内部重抽样，其实没有任何特殊的地方，只是换个说法而已。\n一个数据集被随机划分为训练集和测试集，在训练集建立模型时，我们可能会对训练集使用K折交叉验证或者bootstrap等方法，这样可以使我们的模型更加稳健，避免出现极坏或者极好的结果。在训练集中使用K折交叉验证或者bootstrap等方法，就被叫做内部验证或者内部重抽样。在测试集（指建模时未使用过的数据）测试模型的表现，就叫做外部验证。\n下图是《R语言整洁建模》中的典型数据划分方法示意图，非常贴合临床预测模型的数据划分方法。\n\n\n\n典型的数据划分方法\n\n\n首先我们会把所有数据划分为训练集和测试集，然后在训练集中建立模型，这个过程会对训练集使用另一种重抽样方法（比如交叉验证或者bootstrap等），每一次重抽样我们都会使用其中一部分数据用于拟合模型，另一部分数据用于评估模型，用于拟合模型的这部分数据被称为分析集，用于评估模型的数据被称为评估集。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>常见的数据划分方法</span>"
    ]
  },
  {
    "objectID": "data-split.html#重抽样的目的",
    "href": "data-split.html#重抽样的目的",
    "title": "5  常见的数据划分方法",
    "section": "5.6 重抽样的目的",
    "text": "5.6 重抽样的目的\n经常有粉丝问我：为什么我用了各种方法，10折交叉验证、10折重复交叉验证、自助法，都用过了，为什么最后模型的表现还是很差？\n看到类似的问题，我想这部分朋友可能把重抽样的目的搞错了，重抽样的目的不是为了提高模型表现，重抽样也确实不能提高模型表现！开头我已说过，重抽样技术是为了让模型更好的认识数据而已，这样能够得到更加稳健、无偏的结果，但是对于提高模型表现没有直接的影响哦~\n你可以这么理解，如果你不重抽样，可能某一次结果的AUC是0.9，再做一次可能就变成0.5了，而你重抽样10次，得到的结果是10次的平均，这样的结果很明显是更加稳健的、误差小的。\n模型表现好不好首先是数据原因，一个牛逼的数据不需要复杂的模型也能有很好的结果，数据预处理对数据影响很大，大家可以参考下一章内容。另外还和模型本身的性质有关，比如模型的超参数、模型本身的上限等，这些都会影响模型的表现。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>常见的数据划分方法</span>"
    ]
  },
  {
    "objectID": "data-split.html#为什么要单独划分",
    "href": "data-split.html#为什么要单独划分",
    "title": "5  常见的数据划分方法",
    "section": "5.7 为什么要单独划分",
    "text": "5.7 为什么要单独划分\n通常我们建立模型时，会把数据集A划分为A1和A2两份，A1用来训练模型，A2用来测试模型，在训练模型的过程中，完全不用使用到A2这部分数据。有些人不理解，把这种方法和嵌套重抽样混为一谈。其实这两个有着本质的区别。\n嵌套重抽样是在训练模型时使用的，把两份数据集全都用到了，而且两份数据集都会再叠加其他重抽样方法。\n但我们划分数据的目的是什么呢？我们是为了测试最终的模型表现。临床问题数据很珍贵，通常都只有1份，这种情况下我把这份数据全都用于训练模型，那我用什么测试训练出来的模型好坏呢？有的人喜欢把训练好的模型作用于用来训练模型的数据上，发现结果竟然很好，这样是不对的，这叫数据泄露，你的数据模型已经学习过了，这不是作弊吗？这样的模型结果能说明什么问题呢？\n所以一开始把数据就划分为2份是一个很好的解决方法。如果你有很多个数据集，你完全可以在其中1个数据集中使用各种方法建模。比如，你的临床试验有多个分中心，你完全可以使用其中1个或几个中心的数据建立模型，然后在其余中心的数据中评估最终的模型。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>常见的数据划分方法</span>"
    ]
  },
  {
    "objectID": "data-split.html#方法选择建议",
    "href": "data-split.html#方法选择建议",
    "title": "5  常见的数据划分方法",
    "section": "5.8 方法选择建议",
    "text": "5.8 方法选择建议\n以上就是一些常见的重抽样方法，可以看到每种方法都强调一个问题，那就是随机！，只有随机，才能保证模型学习到这个数据集中的更多信息，才能获得稳健的模型表现！\n以下是一些方法选择建议：\n\n没有哪一种方法好，哪一种方法不好！！只有合不合适，没有好不好！\n如果样本量较小，建议选择重复10折交叉验证；\n如果样本量足够大，比如几万，几十万这种，随便选，都可以；\n如果目的不是得到最好的模型表现，而是为了在不同模型间进行选择，建议使用bootstrap；\n如果还不知道怎么选，建议都试一试，喜欢哪个选哪个",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>常见的数据划分方法</span>"
    ]
  },
  {
    "objectID": "data-preprocess.html",
    "href": "data-preprocess.html",
    "title": "6  常见的数据预处理方法",
    "section": "",
    "text": "6.1 加载R包和数据\nlibrary(AppliedPredictiveModeling)\nlibrary(caret)\n\ndata(\"segmentationOriginal\")\n\nsegData &lt;- subset(segmentationOriginal, Case == \"Train\")\ncellID &lt;- segData$Cell\ncalss &lt;- segData$Class\ncase &lt;- segData$Case\nsegData &lt;- segData[ ,  -(1:3)]\nstatusColNum &lt;- grep(\"Status\", names(segData))\nstatusColNum\n##  [1]   2   4   9  10  11  12  14  16  20  21  22  26  27  28  30  32  34  36  38\n## [20]  40  43  44  46  48  51  52  55  56  59  60  63  64  68  69  70  72  73  74\n## [39]  76  78  80  82  84  86  88  92  93  94  97  98 103 104 105 106 110 111 112\n## [58] 114\n\nsegData &lt;- segData[ , -statusColNum]\n\nstr(segData)\n## 'data.frame':    1009 obs. of  58 variables:\n##  $ AngleCh1               : num  133.8 106.6 69.2 109.4 104.3 ...\n##  $ AreaCh1                : int  819 431 298 256 258 358 158 315 246 223 ...\n##  $ AvgIntenCh1            : num  31.9 28 19.5 18.8 17.6 ...\n##  $ AvgIntenCh2            : num  206 115 101 126 124 ...\n##  $ AvgIntenCh3            : num  69.9 63.9 28.2 13.6 22.5 ...\n##  $ AvgIntenCh4            : num  164.2 106.7 31 46.8 71.2 ...\n##  $ ConvexHullAreaRatioCh1 : num  1.26 1.05 1.2 1.08 1.08 ...\n##  $ ConvexHullPerimRatioCh1: num  0.797 0.935 0.866 0.92 0.931 ...\n##  $ DiffIntenDensityCh1    : num  31.9 32.5 26.7 28 27.9 ...\n##  $ DiffIntenDensityCh3    : num  43.1 36 22.9 14.9 16.1 ...\n##  $ DiffIntenDensityCh4    : num  79.3 51.4 26.4 32.7 36.2 ...\n##  $ EntropyIntenCh1        : num  6.09 5.88 5.42 5.38 5.18 ...\n##  $ EntropyIntenCh3        : num  6.64 6.68 5.44 4.15 5.49 ...\n##  $ EntropyIntenCh4        : num  7.88 7.14 5.78 6.19 6.62 ...\n##  $ EqCircDiamCh1          : num  32.3 23.4 19.5 18.1 18.2 ...\n##  $ EqEllipseLWRCh1        : num  1.56 1.38 3.39 1.38 1.62 ...\n##  $ EqEllipseOblateVolCh1  : num  2233 802 725 368 404 ...\n##  $ EqEllipseProlateVolCh1 : num  1433 583 214 267 250 ...\n##  $ EqSphereAreaCh1        : num  3279 1727 1195 1027 1036 ...\n##  $ EqSphereVolCh1         : num  17654 6751 3884 3096 3134 ...\n##  $ FiberAlign2Ch3         : num  0.488 0.301 0.22 0.364 0.359 ...\n##  $ FiberAlign2Ch4         : num  0.352 0.522 0.733 0.481 0.244 ...\n##  $ FiberLengthCh1         : num  64.3 21.1 43.1 22.3 26.5 ...\n##  $ FiberWidthCh1          : num  13.2 21.1 7.4 12.1 10.2 ...\n##  $ IntenCoocASMCh3        : num  0.02805 0.00686 0.03096 0.10816 0.01303 ...\n##  $ IntenCoocASMCh4        : num  0.01259 0.00614 0.01103 0.00995 0.00896 ...\n##  $ IntenCoocContrastCh3   : num  8.23 14.45 7.3 6.16 9.4 ...\n##  $ IntenCoocContrastCh4   : num  6.98 16.7 13.39 10.59 10.3 ...\n##  $ IntenCoocEntropyCh3    : num  6.82 7.58 6.31 5.04 6.96 ...\n##  $ IntenCoocEntropyCh4    : num  7.1 7.67 7.2 7.13 7.14 ...\n##  $ IntenCoocMaxCh3        : num  0.1532 0.0284 0.1628 0.3153 0.0739 ...\n##  $ IntenCoocMaxCh4        : num  0.0739 0.0232 0.0775 0.0586 0.0348 ...\n##  $ KurtIntenCh1           : num  -0.249 -0.293 0.626 -0.365 -0.556 ...\n##  $ KurtIntenCh3           : num  -0.331 1.051 0.128 1.083 -0.512 ...\n##  $ KurtIntenCh4           : num  -0.265 0.151 -0.347 -0.626 -0.647 ...\n##  $ LengthCh1              : num  47.2 28.1 37.9 23.1 26.3 ...\n##  $ NeighborAvgDistCh1     : num  174 158 206 264 231 ...\n##  $ NeighborMinDistCh1     : num  30.1 34.9 33.1 38.4 29.8 ...\n##  $ NeighborVarDistCh1     : num  81.4 90.4 116.9 88.5 103.5 ...\n##  $ PerimCh1               : num  154.9 84.6 101.1 68.7 73.4 ...\n##  $ ShapeBFRCh1            : num  0.54 0.724 0.589 0.635 0.557 ...\n##  $ ShapeLWRCh1            : num  1.47 1.33 2.83 1.31 1.49 ...\n##  $ ShapeP2ACh1            : num  2.26 1.27 2.55 1.4 1.59 ...\n##  $ SkewIntenCh1           : num  0.399 0.472 0.882 0.547 0.443 ...\n##  $ SkewIntenCh3           : num  0.62 0.971 1 1.432 0.556 ...\n##  $ SkewIntenCh4           : num  0.527 0.325 0.604 0.704 0.137 ...\n##  $ SpotFiberCountCh3      : int  4 2 4 0 1 1 4 2 2 2 ...\n##  $ SpotFiberCountCh4      : int  11 6 7 5 4 5 4 2 5 1 ...\n##  $ TotalIntenCh1          : int  24964 11552 5545 4613 4340 14461 4743 88725 136957 79885 ...\n##  $ TotalIntenCh2          : int  160997 47510 28869 30855 30719 74259 15434 148012 57421 62235 ...\n##  $ TotalIntenCh3          : int  54675 26344 8042 3332 5548 14474 6265 58224 20304 23878 ...\n##  $ TotalIntenCh4          : int  128368 43959 8843 11466 17588 23099 17534 120536 15482 98948 ...\n##  $ VarIntenCh1            : num  18.8 17.3 13.8 13.9 12.3 ...\n##  $ VarIntenCh3            : num  56.7 37.7 30 18.6 17.7 ...\n##  $ VarIntenCh4            : num  118.4 49.5 24.7 40.3 41.9 ...\n##  $ WidthCh1               : num  32.2 21.2 13.4 17.5 17.7 ...\n##  $ XCentroid              : int  215 371 487 211 172 276 239 95 438 386 ...\n##  $ YCentroid              : int  347 252 295 495 207 385 404 95 16 14 ...",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>常见的数据预处理方法</span>"
    ]
  },
  {
    "objectID": "data-preprocess.html#中心化和标准化",
    "href": "data-preprocess.html#中心化和标准化",
    "title": "6  常见的数据预处理方法",
    "section": "6.2 中心化和标准化",
    "text": "6.2 中心化和标准化\n某些算法对预测变量是有要求的，比如需要预测变量具有相同的尺度，如果有的预测变量范围是0.10.2，但是有的却是1000020000，这种变量间的绝大差距会影像某些模型的稳定性，所以需要想办法把它们变成差不多的范围（有个专有名词：无量纲化）。\n中心化和标准化可以解决这样的问题。\n中心化是将所有变量减去其均值，其结果是变换后的变量均值为0；标准化是将每个变量除以其自身的标准差，标准化迫使变量的标准差为1。\nR语言中scale()函数可实现中心化和标准化，就不多做介绍了。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>常见的数据预处理方法</span>"
    ]
  },
  {
    "objectID": "data-preprocess.html#偏度问题",
    "href": "data-preprocess.html#偏度问题",
    "title": "6  常见的数据预处理方法",
    "section": "6.3 偏度问题",
    "text": "6.3 偏度问题\n无偏分布类似我们常说的正态分布，有偏分布又分为右偏和左偏，分别类似正偏态分布和负偏态分布。\n一个判断数据有偏的黄金标准：如果最大值与最小值的比例超过20，那么我们认为数据有偏。\n可以通过计算偏度统计量来衡量偏度。如果预测变量分布是大致对称的，那么偏度将接近于0，右偏分布偏度大于0，越大说明偏的越厉害；左偏分布偏度小于0，越小说明偏的越厉害。\n计算偏度的包很多。\n使用e1071包查看变量的偏度：\n\nlibrary(e1071)\n# 查看偏度\nskewness(segData$AngleCh1)\n## [1] -0.02426252\n## [1] -0.02426252\n\n# 查看每一列的偏度\nskewValues &lt;- apply(segData, 2, skewness)\nhead(skewValues)\n##    AngleCh1     AreaCh1 AvgIntenCh1 AvgIntenCh2 AvgIntenCh3 AvgIntenCh4 \n## -0.02426252  3.52510745  2.95918524  0.84816033  2.20234214  1.90047128\n\n也可以通过psych包查看：\n\npsych::skew(segData$AngleCh1) # 偏度\n## [1] -0.02426252\n\npsych::kurtosi(segData$AngleCh1) # 峰度\n## [1] -0.8594789\n\n通过对数据进行变换可以一定程度解决偏度的问题，常用的方法有：取对数(log)，平方根，倒数，Box&Cox法等。\nlog、平方根、倒数这些很简单，就不演示了，下面演示下BoxCox变换。\n\n# 准备对数据进行BoxCox变换\nCh1AreaTrans &lt;- BoxCoxTrans(segData$AreaCh1)\nCh1AreaTrans\n## Box-Cox Transformation\n## \n## 1009 data points used to estimate Lambda\n## \n## Input data summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   150.0   194.0   256.0   325.1   376.0  2186.0 \n## \n## Largest/Smallest: 14.6 \n## Sample Skewness: 3.53 \n## \n## Estimated Lambda: -0.9\n\n# 进行变换\nAreaCh1_transed &lt;- predict(Ch1AreaTrans, segData$AreaCh1)\n\n# 查看变换前、后的数据\nhead(segData$AreaCh1)\n## [1] 819 431 298 256 258 358\nhead(AreaCh1_transed)\n## [1] 1.108458 1.106383 1.104520 1.103554 1.103607 1.105523\n\n这里可以看到caret对数据预处理的方式，首先是选择方法，然后使用predict()函数把变换应用到具体的变量上。这是caret的基本操作，大家一定要记住！\n对于变换前后的数据变化，只看数字没有直观的感受，下面给大家画图演示。\n\n# 画图看变换前后\nopar &lt;- par(mfrow=c(1,2))\nhist(segData$AreaCh1)\nhist(AreaCh1_transed)\n\n\n\n\n\n\n\npar(opar)\n\n可以明显看到变换前是右偏分布，变换后基本接近无偏，可以再次计算偏度看看：\n\npsych::skew(AreaCh1_transed)\n## [1] 0.0976087\n\n下面是BoxCox变换的一点点扩展，不看也影响不大。\nBoxCox变换需要一个参数lambda，这个参数需要我们计算并指定，如上使用caret进行变换时，它会自动帮我们处理好，其中一句代码显示Estimated Lambda: -0.9，也就是lambda=0.9。\n还有很多R包可以实现BoxCox变换，其中比较简单的是forecast，简单演示如下：\n\nlibrary(forecast)\n\nbest.lambda &lt;- BoxCox.lambda(segData$AreaCh1) # 计算lambda\nbest.lambda\n## [1] -0.9999264\n\nAreaCh1.transformed &lt;- BoxCox(segData$AreaCh1, lambda = best.lambda) # 变换\nhead(AreaCh1.transformed)\n## [1] 0.9988519 0.9977522 0.9967163 0.9961655 0.9961958 0.9972789\n\ny0 &lt;- InvBoxCox(AreaCh1.transformed,lambda=best.lambda) # 还原",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>常见的数据预处理方法</span>"
    ]
  },
  {
    "objectID": "data-preprocess.html#解决离群值",
    "href": "data-preprocess.html#解决离群值",
    "title": "6  常见的数据预处理方法",
    "section": "6.4 解决离群值",
    "text": "6.4 解决离群值\n离群值其实是有明确定义的，通常我们会选择直接删除离群值，但是还是要根据实际情况来看，有的离群值是非常有意义的，这样的离群值不能直接删除。\n\n有的离群值可能是数据录入时不小心输错了，比如错把收缩压132mmHg录成了 -132mmHg，只需要改正即可；\n在样本量较小时，不宜直接删除离群值，有的离群值可能是因为数据来自一个明显有偏的分布，只是因为我们的样本量太小无法观测到这个偏度；\n有些离群值可能来自一个特殊的子集，只是这个子集才刚开始被收集到。\n\n有些模型对离群值很敏感，比如线性模型，这样是需要处理的，一个常见的方法是空间表示变换，该变换将预测变量取值映射到高纬的球上，它会把所有样本变换到离球心相等的球面上。在caret中可以实现。关于它的具体数学运算过程，感兴趣的自己了解即可，我不太感兴趣。\n在进行空间表示变换前，最好先进行中心化和标准化，这也和它的数学计算有关，我也不太感兴趣。\n查看变换前的图形：\n\n# 变换前的图形\ndata(mdrr)\ntransparentTheme(trans = .4)\n\nplotSubset &lt;- data.frame(scale(mdrrDescr[, c(\"nC\", \"X4v\")])) \nxyplot(nC ~ X4v,\n       data = plotSubset,\n       groups = mdrrClass, \n       auto.key = list(columns = 2))\n\n\n\n\n\n\n\n\n查看变换后的图形：\n\n# 变换后的图形\ntransformed &lt;- spatialSign(plotSubset)\ntransformed &lt;- as.data.frame(transformed)\nxyplot(nC ~ X4v, \n       data = transformed, \n       groups = mdrrClass, \n       auto.key = list(columns = 2)) \n\n\n\n\n\n\n\n\n是不是很神奇？",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>常见的数据预处理方法</span>"
    ]
  },
  {
    "objectID": "data-preprocess.html#降维和特征提取",
    "href": "data-preprocess.html#降维和特征提取",
    "title": "6  常见的数据预处理方法",
    "section": "6.5 降维和特征提取",
    "text": "6.5 降维和特征提取\n有很多方法，比如PCA，ICA，PLS，UMAP等，最流行的还是PCA，主要是它给出的主成分是彼此不相关的，这恰好符合一些模型的需求。\n对数据进行PCA变换之前，最好先解决偏度问题，然后进行中心化和标准化，和它的数学计算过程有关，感兴趣的自己了解。\n可视化前后不同：\n\n# 主成分分析，可参考我之前的推文\npr &lt;- prcomp(~ AvgIntenCh1 + EntropyIntenCh1, \n             data = segData, \n             scale. = TRUE)\n\n# 可视化前后图形\nlibrary(ggplot2)\n\np1 &lt;- ggplot(segData, aes(AvgIntenCh1,EntropyIntenCh1))+\n  geom_point()+\n  labs(x=\"Channel 1 Fiber Width\",y=\"Intensity Entropy Channel 1\")+\n  theme_bw()\np2 &lt;- ggplot(as.data.frame(pr$x), aes(PC1,PC2))+\n  geom_point()+\n  theme_bw()\ncowplot::plot_grid(p1,p2)",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>常见的数据预处理方法</span>"
    ]
  },
  {
    "objectID": "data-preprocess.html#处理缺失值",
    "href": "data-preprocess.html#处理缺失值",
    "title": "6  常见的数据预处理方法",
    "section": "6.6 处理缺失值",
    "text": "6.6 处理缺失值\n缺失值处理是一个宏大的话题，首先要了解缺失值的类型：\n\n完全随机缺失：若某变量的缺失数据与其他任何观测或未观测变量都不相关，则数据 为完全随机缺失（MCAR）。注意，如果每个有缺失值的变量都是MCAR，那么可以将数据完整的实例看作对更大数据集的一个简单随机抽样。\n随机缺失：若某变量上的缺失数据与其他观测变量相关，与它自己的未观测值不相关， 则数据为随机缺失（MAR）。\n非随机缺失：若缺失数据不属于MCAR和MAR，则数据为非随机缺失（NMAR）。\n\n大部分处理缺失数据的方法都假定数据是MCAR或MAR。缺失值的处理方法非常多，理论也非常复杂，下面是一些常见的缺失值处理方法：\n\n缺失值探索\n缺失值插补之simputation包\n我常用的缺失值插补方法\nmice多重插补",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>常见的数据预处理方法</span>"
    ]
  },
  {
    "objectID": "data-preprocess.html#过滤",
    "href": "data-preprocess.html#过滤",
    "title": "6  常见的数据预处理方法",
    "section": "6.7 过滤",
    "text": "6.7 过滤\n这里的过滤和解决共线性，其实部分属于特征选择的范围，就是大家常见的自变量选择问题，这个问题在以后的推文中还会详细介绍。\n\n冗余的变量通常增加了模型的复杂度而非信息量\n\n主要是过滤两种变量：(近)零方差变量和高度相关变量。\n如果一个变量只有1个值，那么这个变量的方差为0；如果一个变量只有少量不重复的取值，这种变量称为近零方差变量；这2种变量包含的信息太少了，应当过滤；\n检测近零方差变量的准则是：\n\n不重复取值的数目与样本量的比值低（比如10%）；\n最高频数和次高频数的比值高（比如20%）\n\n如果两个变量相关性太高，那么它们携带的信息可能很多是重叠的，会对某些模型产生较大的影响，应当解决。\n移除共线变量的方法如下：\n\n计算预测变量的相关系数矩阵\n找出相关系数绝对值最大的那对预测变量（记为变量A和B）\n分别计算A和B和其他预测变量的相关系数\n如果A的平均相关系数更大，移除A，否则移除B\n重复步骤2-4，直至所有相关系数的绝对值都低于设定的阈值\n\ncaret可以轻松实现以上过程。\n使用mdrr数据集演示。其中一列nR11大部分都是501，这种变量方差是很小的！\n\ndata(mdrr)\ntable(mdrrDescr$nR11) # 大部分值都是0\n## \n##   0   1   2 \n## 501   4  23\n\nsd(mdrrDescr$nR11)^2 # 方差很小！\n## [1] 0.1731787\n\n使用nearZeroVar()找出零方差和近零方差变量，结果中会给出zeroVar和nzv两列，用逻辑值表示是不是近零方差变量或者零方差变量。\n\nnzv &lt;- nearZeroVar(mdrrDescr, saveMetrics= TRUE)\nnzv[nzv$nzv,][1:10,]\n##        freqRatio percentUnique zeroVar  nzv\n## nTB     23.00000     0.3787879   FALSE TRUE\n## nBR    131.00000     0.3787879   FALSE TRUE\n## nI     527.00000     0.3787879   FALSE TRUE\n## nR03   527.00000     0.3787879   FALSE TRUE\n## nR08   527.00000     0.3787879   FALSE TRUE\n## nR11    21.78261     0.5681818   FALSE TRUE\n## nR12    57.66667     0.3787879   FALSE TRUE\n## D.Dr03 527.00000     0.3787879   FALSE TRUE\n## D.Dr07 123.50000     5.8712121   FALSE TRUE\n## D.Dr08 527.00000     0.3787879   FALSE TRUE\n\n去掉近零方差变量：\n\ndim(mdrrDescr)\n## [1] 528 342\n\nnzv &lt;- nearZeroVar(mdrrDescr)\nfilteredDescr &lt;- mdrrDescr[, -nzv]\ndim(filteredDescr)\n## [1] 528 297\n\n下面是处理高度相关的变量。\n\n# 相关系数矩阵\ncorrelations &lt;- cor(segData)\ndim(correlations)\n## [1] 58 58\n\n# 可视化相关系数矩阵，中间几个颜色深的就是高度相关的变量\nlibrary(corrplot)\ncorrplot(correlations, order = \"hclust\",tl.col = \"black\")\n\n\n\n\n\n\n\n\n去掉高度相关的变量：\n\n# 阈值设为0.75\nhighCorr &lt;- findCorrelation(correlations, cutoff = 0.75)\nlength(highCorr)\n## [1] 32\nhead(highCorr)\n## [1] 23 40 43 36  7 15\n\n# 去掉高度相关的变量\nfilteredSegData &lt;- segData[, -highCorr]",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>常见的数据预处理方法</span>"
    ]
  },
  {
    "objectID": "data-preprocess.html#共线性",
    "href": "data-preprocess.html#共线性",
    "title": "6  常见的数据预处理方法",
    "section": "6.8 共线性",
    "text": "6.8 共线性\n假设一个下面这种的数据，其中第2列和第3列的值加起来和第1列一样，第4,5,6列的值起来也和第1列一样。这种数据的某些变量间是有高度共线性的。\n\nltfrDesign &lt;- matrix(0, nrow=6, ncol=6)\nltfrDesign[,1] &lt;- c(1, 1, 1, 1, 1, 1)\nltfrDesign[,2] &lt;- c(1, 1, 1, 0, 0, 0)\nltfrDesign[,3] &lt;- c(0, 0, 0, 1, 1, 1)\nltfrDesign[,4] &lt;- c(1, 0, 0, 1, 0, 0)\nltfrDesign[,5] &lt;- c(0, 1, 0, 0, 1, 0)\nltfrDesign[,6] &lt;- c(0, 0, 1, 0, 0, 1)\n\nltfrDesign\n##      [,1] [,2] [,3] [,4] [,5] [,6]\n## [1,]    1    1    0    1    0    0\n## [2,]    1    1    0    0    1    0\n## [3,]    1    1    0    0    0    1\n## [4,]    1    0    1    1    0    0\n## [5,]    1    0    1    0    1    0\n## [6,]    1    0    1    0    0    1\n\nfindLinearCombos()可以通过算法给出需要去除的变量，关于具体的方法可以官网查看。\n\ncomboInfo &lt;- findLinearCombos(ltfrDesign)\ncomboInfo\n## $linearCombos\n## $linearCombos[[1]]\n## [1] 3 1 2\n## \n## $linearCombos[[2]]\n## [1] 6 1 4 5\n## \n## \n## $remove\n## [1] 3 6\n\n结果给出了需要去除的变量是第3列和第6列。\n\n# 去除第3列和第6列\nltfrDesign[, -comboInfo$remove]\n##      [,1] [,2] [,3] [,4]\n## [1,]    1    1    1    0\n## [2,]    1    1    0    1\n## [3,]    1    1    0    0\n## [4,]    1    0    1    0\n## [5,]    1    0    0    1\n## [6,]    1    0    0    0",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>常见的数据预处理方法</span>"
    ]
  },
  {
    "objectID": "data-preprocess.html#构建虚拟变量",
    "href": "data-preprocess.html#构建虚拟变量",
    "title": "6  常见的数据预处理方法",
    "section": "6.9 构建虚拟变量",
    "text": "6.9 构建虚拟变量\n最常见的回归分析中的哑变量设置，可以参考之前的推文，详细介绍了常见的分类变量的编码方式：分类变量进行回归分析时的编码方案\n这里介绍下独热编码（one-hot encoding），和哑变量编码稍有不同，哑变量是变成k-1个变量，独热编码是变成k个变量。\n使用以下数据进行演示：\n\ndata(\"cars\", package = \"caret\")\nhead(cars)\n##      Price Mileage Cylinder Doors Cruise Sound Leather Buick Cadillac Chevy\n## 1 22661.05   20105        6     4      1     0       0     1        0     0\n## 2 21725.01   13457        6     2      1     1       0     0        0     1\n## 3 29142.71   31655        4     2      1     1       1     0        0     0\n## 4 30731.94   22479        4     2      1     0       0     0        0     0\n## 5 33358.77   17590        4     2      1     1       1     0        0     0\n## 6 30315.17   23635        4     2      1     0       0     0        0     0\n##   Pontiac Saab Saturn convertible coupe hatchback sedan wagon\n## 1       0    0      0           0     0         0     1     0\n## 2       0    0      0           0     1         0     0     0\n## 3       0    1      0           1     0         0     0     0\n## 4       0    1      0           1     0         0     0     0\n## 5       0    1      0           1     0         0     0     0\n## 6       0    1      0           1     0         0     0     0\n\ntype &lt;- c(\"convertible\", \"coupe\", \"hatchback\", \"sedan\", \"wagon\")\ncars$Type &lt;- factor(apply(cars[, 14:18], 1, function(x) type[which(x == 1)]))\n\ncarSubset &lt;- cars[sample(1:nrow(cars), 20), c(1, 2, 19)]\n\n# 上面是数据生成过程，不重要，记住下面这个数据的样子即可！！\nhead(carSubset)\n##        Price Mileage  Type\n## 627 36332.89   25153 sedan\n## 692 15233.16   32535 sedan\n## 548 27714.05    5379 sedan\n## 49  29844.20   23143 sedan\n## 295 13688.95   21611 sedan\n## 523 19116.13   26252 sedan\nlevels(carSubset$Type) # Type是一个因子型变量\n## [1] \"convertible\" \"coupe\"       \"hatchback\"   \"sedan\"       \"wagon\"\n\n现在把Type这个变量进行独热编码。\n使用dummyVars构建虚拟变量：\n\nsimpleMod &lt;- dummyVars(~Mileage + Type, # 用mileage和Type对价格进行预测\n                       data = carSubset,\n                       levelsOnly = TRUE) # 从列名中移除因子变量的名称\nsimpleMod\n## Dummy Variable Object\n## \n## Formula: ~Mileage + Type\n## 2 variables, 1 factors\n## Factor variable names will be removed\n## A less than full rank encoding is used\n\n接下来就可以使用predict和simpleMod对训练集进行生成虚拟变量的操作了：\n\npredict(simpleMod, head(carSubset))\n##     Mileage convertible coupe hatchback sedan wagon\n## 627   25153           0     0         0     1     0\n## 692   32535           0     0         0     1     0\n## 548    5379           0     0         0     1     0\n## 49    23143           0     0         0     1     0\n## 295   21611           0     0         0     1     0\n## 523   26252           0     0         0     1     0\n\n可以看到Type变量没有了，完成了虚拟变量的转换。\n假如你认为车型和里程有交互影响，则可以使用:表示：\n\nwithInteraction &lt;- dummyVars(~Mileage + Type + Mileage:Type,\n                             data = carSubset,\n                             levelsOnly = TRUE)\nwithInteraction\n## Dummy Variable Object\n## \n## Formula: ~Mileage + Type + Mileage:Type\n## 2 variables, 1 factors\n## Factor variable names will be removed\n## A less than full rank encoding is used\n\n应用于新的数据集：\n\npredict(withInteraction, head(carSubset))\n##     Mileage convertible coupe hatchback sedan wagon Mileage:Typeconvertible\n## 627   25153           0     0         0     1     0                       0\n## 692   32535           0     0         0     1     0                       0\n## 548    5379           0     0         0     1     0                       0\n## 49    23143           0     0         0     1     0                       0\n## 295   21611           0     0         0     1     0                       0\n## 523   26252           0     0         0     1     0                       0\n##     Mileage:Typecoupe Mileage:Typehatchback Mileage:Typesedan Mileage:Typewagon\n## 627                 0                     0             25153                 0\n## 692                 0                     0             32535                 0\n## 548                 0                     0              5379                 0\n## 49                  0                     0             23143                 0\n## 295                 0                     0             21611                 0\n## 523                 0                     0             26252                 0",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>常见的数据预处理方法</span>"
    ]
  },
  {
    "objectID": "data-preprocess.html#区间化预测变量",
    "href": "data-preprocess.html#区间化预测变量",
    "title": "6  常见的数据预处理方法",
    "section": "6.10 区间化预测变量",
    "text": "6.10 区间化预测变量\n主要是为了好解释结果，比如把血压分为高血压1级、2级、3级，把贫血分为轻中重极重等，这样比如你做logistic回归，可以说血压每增高一个等级，因变量的风险增加多少，但是你如果说血压值每增加1mmHg，因变量增加多少倍，这就有点扯了。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>常见的数据预处理方法</span>"
    ]
  },
  {
    "objectID": "data-preprocess.html#多个预处理步骤放一起",
    "href": "data-preprocess.html#多个预处理步骤放一起",
    "title": "6  常见的数据预处理方法",
    "section": "6.11 多个预处理步骤放一起",
    "text": "6.11 多个预处理步骤放一起\n在caret中是通过preProcess()函数里面的method参数实现的，把不同的预处理步骤按照顺序写好即可。\n\nlibrary(AppliedPredictiveModeling)\ndata(schedulingData)\nstr(schedulingData)\n## 'data.frame':    4331 obs. of  8 variables:\n##  $ Protocol   : Factor w/ 14 levels \"A\",\"C\",\"D\",\"E\",..: 4 4 4 4 4 4 4 4 4 4 ...\n##  $ Compounds  : num  997 97 101 93 100 100 105 98 101 95 ...\n##  $ InputFields: num  137 103 75 76 82 82 88 95 91 92 ...\n##  $ Iterations : num  20 20 10 20 20 20 20 20 20 20 ...\n##  $ NumPending : num  0 0 0 0 0 0 0 0 0 0 ...\n##  $ Hour       : num  14 13.8 13.8 10.1 10.4 ...\n##  $ Day        : Factor w/ 7 levels \"Mon\",\"Tue\",\"Wed\",..: 2 2 4 5 5 3 5 5 5 3 ...\n##  $ Class      : Factor w/ 4 levels \"VF\",\"F\",\"M\",\"L\": 2 1 1 1 1 1 1 1 1 1 ...\n\n# 中心化、标准化、YeoJohnson变换\npp_hpc &lt;- preProcess(schedulingData[, -8], \n                     method = c(\"center\", \"scale\", \"YeoJohnson\"))\npp_hpc\n## Created from 4331 samples and 7 variables\n## \n## Pre-processing:\n##   - centered (5)\n##   - ignored (2)\n##   - scaled (5)\n##   - Yeo-Johnson transformation (5)\n## \n## Lambda estimates for Yeo-Johnson transformation:\n## -0.08, -0.03, -1.05, -1.1, 1.44\n\n# 应用于数据\ntransformed &lt;- predict(pp_hpc, newdata = schedulingData[, -8])\nhead(transformed)\n##   Protocol  Compounds InputFields Iterations NumPending         Hour Day\n## 1        E  1.2289592  -0.6324580 -0.0615593  -0.554123  0.004586516 Tue\n## 2        E -0.6065826  -0.8120473 -0.0615593  -0.554123 -0.043733201 Tue\n## 3        E -0.5719534  -1.0131504 -2.7894869  -0.554123 -0.034967177 Thu\n## 4        E -0.6427737  -1.0047277 -0.0615593  -0.554123 -0.964170752 Fri\n## 5        E -0.5804713  -0.9564504 -0.0615593  -0.554123 -0.902085020 Fri\n## 6        E -0.5804713  -0.9564504 -0.0615593  -0.554123  0.698108782 Wed\n\nmean(schedulingData$NumPending == 0)\n## [1] 0.7561764\n\n# 进行中心化、标准化、YeoJohnson、nzv\npp_no_nzv &lt;- preProcess(schedulingData[, -8], \n                        method = c(\"center\", \"scale\", \"YeoJohnson\", \"nzv\"))\npp_no_nzv\n## Created from 4331 samples and 7 variables\n## \n## Pre-processing:\n##   - centered (4)\n##   - ignored (2)\n##   - removed (1)\n##   - scaled (4)\n##   - Yeo-Johnson transformation (4)\n## \n## Lambda estimates for Yeo-Johnson transformation:\n## -0.08, -0.03, -1.05, 1.44\n\npredict(pp_no_nzv, newdata = schedulingData[1:6, -8])\n##   Protocol  Compounds InputFields Iterations         Hour Day\n## 1        E  1.2289592  -0.6324580 -0.0615593  0.004586516 Tue\n## 2        E -0.6065826  -0.8120473 -0.0615593 -0.043733201 Tue\n## 3        E -0.5719534  -1.0131504 -2.7894869 -0.034967177 Thu\n## 4        E -0.6427737  -1.0047277 -0.0615593 -0.964170752 Fri\n## 5        E -0.5804713  -0.9564504 -0.0615593 -0.902085020 Fri\n## 6        E -0.5804713  -0.9564504 -0.0615593  0.698108782 Wed\n\n如果你用过tidymodels，那你应该知道里面的数据预处理步骤是通过recipes包完成的，每一步都是step_xx，说实话我觉得caret的这种方式更加简洁易懂！\n以上就是数据预处理的一般过程，一个caret包可以解决上面所有的问题，有兴趣的小伙伴可以自行学习。\n数据预处理是一个非常系统且专业的过程，如同开头说的那样：最有效的编码数据的方法来自于建模者对数据的理解，而不是通过任何数学方法，在对数据进行预处理之前，一定要仔细理解自己的数据哦，结果导向的思维是不对的哦！\n本文简单介绍了常见的数据预处理方法和简单的实现方法，并且大量使用了caret包，但是目前在R中实现数据预处理有更好的方法了，那就是tidymodels和mlr3，这部分内容可参考：\n\nmlr3数据预处理\ntidymodels菜谱：数据预处理\nR语言机器学习caret-02：数据预处理",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>常见的数据预处理方法</span>"
    ]
  },
  {
    "objectID": "nomogram-logistic.html",
    "href": "nomogram-logistic.html",
    "title": "7  逻辑回归列线图绘制",
    "section": "",
    "text": "7.1 准备数据\n使用lowbirth数据集，这个数据集是关于低出生体重儿是否会死亡的数据集，共有565行，10列。其中dead这一列是结果变量，0代表存活，1代表死亡，其余列都是预测变量。\n获取lowbirth数据请在公众号：医学和生信笔记，后台回复20220520。或者到粉丝QQ群文件自取。\nrm(list = ls())\nlowbirth &lt;- read.csv(\"./datasets/lowbirth.csv\")\n查看一下数据：\ndim(lowbirth) # 565行，10列\n## [1] 565  10\nstr(lowbirth) \n## 'data.frame':    565 obs. of  10 variables:\n##  $ birth   : num  81.5 81.6 81.6 81.6 81.6 ...\n##  $ lowph   : num  7.25 7.06 7.25 6.97 7.32 ...\n##  $ pltct   : int  244 114 182 54 282 153 229 182 361 378 ...\n##  $ race    : chr  \"white\" \"black\" \"black\" \"black\" ...\n##  $ bwt     : int  1370 620 1480 925 1255 1350 1310 1110 1180 970 ...\n##  $ delivery: chr  \"abdominal\" \"vaginal\" \"vaginal\" \"abdominal\" ...\n##  $ apg1    : int  7 1 8 5 9 4 6 6 6 2 ...\n##  $ vent    : int  0 1 0 1 0 0 1 0 0 1 ...\n##  $ sex     : chr  \"female\" \"female\" \"male\" \"female\" ...\n##  $ dead    : int  0 1 0 1 0 0 0 0 0 1 ...\n数据中有很多分类变量，比如race、delivery、sex、vent，但是类型是chr或者int，通常在R语言中需要把分类变量变成factor，也就是因子型。\n除此之外，race这个变量一共有4个类别：其中oriental和native American这两个类别太少了，这样在建立模型的时候会导致不可靠的结果，所以我们需要对这个变量进行一些转换。\ntable(lowbirth$race)\n## \n##           black native American        oriental           white \n##             325              14               4             222\n还有就是，有些模型（比如逻辑回归）要求分类变量先进行哑变量（或者其他方法）转换，但是你如果把分类变量变成了因子型，R语言内部会自动帮你转换，不需要手动进行，相关知识我详细介绍过，可以参考分类变量进行回归分析时的编码方案\n对于分类型的因变量，通常需要也变成factor类型，虽然很多R包支持不同类型，但是我建议你转换。\n下面就是用代码实现两步预处理：\nlibrary(dplyr)\n\ntmp &lt;- lowbirth %&gt;% \n  mutate(across(where(is.character),as.factor),\n         vent = factor(vent),\n         dead = factor(dead),\n         race = case_when(race %in% \n                            c(\"native American\",\"oriental\") ~ \"other\",\n                          .default = race),\n         race = factor(race))\n\nstr(tmp)\n## 'data.frame':    565 obs. of  10 variables:\n##  $ birth   : num  81.5 81.6 81.6 81.6 81.6 ...\n##  $ lowph   : num  7.25 7.06 7.25 6.97 7.32 ...\n##  $ pltct   : int  244 114 182 54 282 153 229 182 361 378 ...\n##  $ race    : Factor w/ 3 levels \"black\",\"other\",..: 3 1 1 1 1 1 3 1 3 3 ...\n##  $ bwt     : int  1370 620 1480 925 1255 1350 1310 1110 1180 970 ...\n##  $ delivery: Factor w/ 2 levels \"abdominal\",\"vaginal\": 1 2 2 1 2 1 2 2 1 2 ...\n##  $ apg1    : int  7 1 8 5 9 4 6 6 6 2 ...\n##  $ vent    : Factor w/ 2 levels \"0\",\"1\": 1 2 1 2 1 1 2 1 1 2 ...\n##  $ sex     : Factor w/ 2 levels \"female\",\"male\": 1 1 2 1 1 1 2 2 2 1 ...\n##  $ dead    : Factor w/ 2 levels \"0\",\"1\": 1 2 1 2 1 1 1 1 1 2 ...",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>逻辑回归列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-logistic.html#准备数据",
    "href": "nomogram-logistic.html#准备数据",
    "title": "7  逻辑回归列线图绘制",
    "section": "",
    "text": "分类变量（包括因变量）因子化\n把oriental和native American这两个类别合并成一个类别，就叫other",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>逻辑回归列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-logistic.html#方法1rms",
    "href": "nomogram-logistic.html#方法1rms",
    "title": "7  逻辑回归列线图绘制",
    "section": "7.2 方法1：rms",
    "text": "7.2 方法1：rms\n这个R包非常强大，以后在很多场景中都会用到，是目前唯一能胜任临床预测模型所有步骤的R包。\n\nlibrary(rms)\n\n首先是打包数据，这一步对于rms包来说是必须的：\n\ndd &lt;- datadist(tmp)\noptions(datadist=\"dd\")\n\n构建逻辑回归模型，我们只使用其中的部分变量进行演示：\n\nfit1 &lt;- lrm(dead==1 ~ birth + lowph + pltct + bwt + vent + race,\n            data = tmp)\n#fit1\n\n上面使用了dead==1表示要计算死亡的概率，这里指定一下不容易出错。\n\nlrm()做逻辑回归应该是默认计算排序靠后的类别的概率。\n\n接下来就是构建列线图，然后画图。\n\nnom1 &lt;- nomogram(fit1, fun=plogis,\n                 fun.at=c(0.001,0.1,0.25,0.5,0.75,0.9,0.99),\n                 lp=T, # 是否显示线性预测值\n                 maxscale = 100, # 最大得分数\n                 conf.int = F, # 添加置信区间，很难看，可以不要\n                 funlabel=\"Risk of Death\")  \nplot(nom1) \n\n\n\n\n\n\n\n\n还可以进行一些美化，这个函数的参数非常多，大家可以通过帮助文档自己学习：\n\nplot(nom1,\n     col.grid=c(\"tomato\",\"grey\")\n     #conf.space = c(0.3,0.5) # 置信区间位置\n     ) \n\n\n\n\n\n\n\n\n这个图形展示的是不同变量的取值对应的得分情况，最上面一行是每个变量对应的得分。\n假如有一个患者：\n\n他的birth是87.5，那么对应得分就是0分（看下面的示意图）；\n他的lowph是6.5，那么对应的得分是100；\n他的pltct是50，那么对应的得分是20分；\n他的bwt是920（大约），那么对应的得分是40；\n他的vent是1，那么对应的得分是60；\n他的race是black，那么对应的得分是27（大约）\n\n\n这样一来你就可以得到这个患者的总得分是：100+20+40+60+27=247，这样你就可以在Total Points这一行找到247，然后对应线性预测值（Linear Predictor）就是2，对应的死亡风险是0.85（大约）。\n列线图就是这么看的，不管有多么的花里胡哨都是这么看的，没有任何区别。\n实际在计算每个患者得分时有专门的R包实现，不用自己算，后面的章节会介绍。\n\n\n\n\n\n\n注释\n\n\n\n下面给大家展示下“先做哑变量处理再画列线图”是什么样的效果。就以race这个变量为例。\n\ntmp0 &lt;- lowbirth %&gt;% \n  mutate(across(where(is.character),as.factor),\n         vent = factor(vent),\n         dead = factor(dead),\n         # 下面是对race做哑变量处理\n         black = ifelse(race == \"black\",1,0),\n         white = ifelse(race == \"white\",1,0),\n         other = ifelse(race %in% c(\"native American\",\"oriental\"),1,0)\n         ) %&gt;% \n  select(- race)\n\n# race一列变3列了，这个哑变量怎么看，请参考\n# [分类变量进行回归分析时的编码方案]\nstr(tmp0)\n## 'data.frame':    565 obs. of  12 variables:\n##  $ birth   : num  81.5 81.6 81.6 81.6 81.6 ...\n##  $ lowph   : num  7.25 7.06 7.25 6.97 7.32 ...\n##  $ pltct   : int  244 114 182 54 282 153 229 182 361 378 ...\n##  $ bwt     : int  1370 620 1480 925 1255 1350 1310 1110 1180 970 ...\n##  $ delivery: Factor w/ 2 levels \"abdominal\",\"vaginal\": 1 2 2 1 2 1 2 2 1 2 ...\n##  $ apg1    : int  7 1 8 5 9 4 6 6 6 2 ...\n##  $ vent    : Factor w/ 2 levels \"0\",\"1\": 1 2 1 2 1 1 2 1 1 2 ...\n##  $ sex     : Factor w/ 2 levels \"female\",\"male\": 1 1 2 1 1 1 2 2 2 1 ...\n##  $ dead    : Factor w/ 2 levels \"0\",\"1\": 1 2 1 2 1 1 1 1 1 2 ...\n##  $ black   : num  0 1 1 1 1 1 0 1 0 0 ...\n##  $ white   : num  1 0 0 0 0 0 1 0 1 1 ...\n##  $ other   : num  0 0 0 0 0 0 0 0 0 0 ...\n\ndd &lt;- datadist(tmp0)\noptions(datadist=\"dd\")\n# 以other这个类别为参考\nfit0 &lt;- lrm(dead==1 ~ birth+lowph+pltct+bwt+vent+black+white,data = tmp0)\nnom0 &lt;- nomogram(fit0, fun=plogis,\n                 fun.at=c(0.001,0.1,0.25,0.5,0.75,0.9,0.99),\n                 funlabel=\"Risk of Death\")  \nplot(nom0,col.grid=c(\"tomato\",\"grey\")) \n\n\n\n\n\n\n\n\n看到不同了吗？black和white是两列，other是参考，所以不用写在公式里，当black和white都是0的时候就表示other，当black是1的时候就表示black，white和other此时必为0（不信你可以查看tmp0这个数据），white为1的时候就表示white，此时black和other比为0。\n但是你再仔细观察，你会发现这个图里的black和white对应的分数和上面的列线图是一样的，神奇吗？所以你不需要先自己进行哑变量处理（R会自动处理），虽然画出来的图不一样，但是得分、概率啥的都是一样的，就只是图不一样而已。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>逻辑回归列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-logistic.html#方法2regplot",
    "href": "nomogram-logistic.html#方法2regplot",
    "title": "7  逻辑回归列线图绘制",
    "section": "7.3 方法2：regplot",
    "text": "7.3 方法2：regplot\n这个R包也非常强大，也是做临床预测模型必须要学习的包。\n\nlibrary(regplot)\n\n# 建立模型，这里使用glm也可以\nfit2 &lt;- lrm(dead==1 ~ birth + lowph + pltct + bwt + vent + race,\n            data = tmp)\n\n# 绘图\naa &lt;- regplot(fit2,\n        #连续性变量形状，\"no plot\"\"density\"\"boxes\"\"ecdf\"\n        #\"bars\"\"boxplot\"\"violin\"\"bean\" \"spikes\"；\n        #分类变量的形状，可选\"no plot\" \"boxes\" \"bars\" \"spikes\"\n        plots = c(\"violin\", \"boxes\"),   \n        observation = tmp[1,], #用哪行观测，或者T F\n        center = T, # 对齐变量\n        subticks = T,\n        droplines = T,#是否画竖线\n        title = \"nomogram\",\n        points = T, # 截距项显示为0-100\n        odds = T, # 是否显示OR值\n        showP = T, # 是否显示变量的显著性标记\n        rank = \"sd\", # 根据sd给变量排序\n        interval=\"confidence\", # 展示可信区间\n        clickable = F # 是否可以交互\n        )\n\n这个图看起来更加的花里胡哨，但是图的解读还是和上面一样的，而且我们还有代码专门展示了第一个患者的得分情况。\n唯一不同就是在图中添加了各种图形用来展示各个变量的数据分布情况。\n仔细看你会发现，同样的数据同样的模型和变量，但是画出来的列线图细节确有很多地方不一样！都是正确的哈，写文章时把R包的参考文献加进去即可，别纠结。\n除了以上两种方法外，之前还有另外两个R包可以使用：VRPM和DynNom，但是这两个包太老了，很久没更新了，所以目前只能通过下载安装包本地安装。目前不推荐使用了，如果你一定要用，可参考：Logistic回归列线图的4种绘制方法",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>逻辑回归列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-cox.html",
    "href": "nomogram-cox.html",
    "title": "8  Cox回归列线图绘制",
    "section": "",
    "text": "8.1 准备数据\nCox回归模型在医学统计中是一个很重要的统计方法，关于Cox比例风险模型的构建和结果解读，我写过一些实现方法以及细节解读的推文，大家可以参考：\n# 加载需要的R包和数据\nlibrary(survival)\n\nrm(list = ls())\n\ndim(lung)\n## [1] 228  10\nstr(lung)\n## 'data.frame':    228 obs. of  10 variables:\n##  $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n##  $ time     : num  306 455 1010 210 883 ...\n##  $ status   : num  2 2 1 2 2 1 2 2 2 2 ...\n##  $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n##  $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n##  $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n##  $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n##  $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n##  $ meal.cal : num  1175 1225 NA 1150 NA ...\n##  $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ...\n这个是关于肺癌的生存数据，一共有228行，10列，其中time是生存时间，单位是天，status是生存状态，1是删失，2是死亡。其余变量是自变量，意义如下：",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cox回归列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-cox.html#准备数据",
    "href": "nomogram-cox.html#准备数据",
    "title": "8  Cox回归列线图绘制",
    "section": "",
    "text": "R语言生存分析：Cox回归\nR语言时依系数和时依协变量Cox回归\n\n\n\n\ninst：机构代码，对于我们这次建模没啥用\nage：年龄\nsex：1是男性，2是女性\nph.ecog：ECOG评分。0=无症状，1=有症状但完全可以走动，2=每天&lt;50%的时间在床上，3=在床上&gt;50%的时间但没有卧床，4=卧床不起\nph.karno：医生评的KPS评分，范围是0-100，得分越高，健康状况越好，越能忍受治疗给身体带来的副作用。\npat.karno：患者自己评的KPS评分\nmeal.cal：用餐时消耗的卡路里\nwt.loss：过去6个月的体重减少量，单位是磅",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cox回归列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-cox.html#方法1rms",
    "href": "nomogram-cox.html#方法1rms",
    "title": "8  Cox回归列线图绘制",
    "section": "8.2 方法1：rms",
    "text": "8.2 方法1：rms\n大多数情况下都是使用1代表死亡，0代表删失，下面这个演示数据集用2代表死亡。在这里没有影响，但有的R包会报错，需要注意！\n\nlibrary(rms)\n# 使用rms包需要对数据进行“打包”操作\ndd &lt;- datadist(lung)\noptions(datadist = \"dd\")\n\n构建cox比例风险模型：\n\n# 选择部分变量演示\ncoxfit &lt;- cph(Surv(time, status) ~ age+sex+ph.ecog+ph.karno+pat.karno,\n              data = lung, x=T,y=T,surv = T\n              )\n\n指定你要计算哪一年的生存率：\n\n# 构建生存函数，注意你的最大生存时间\nsurv &lt;- Survival(coxfit) \nsurv1 &lt;- function(x) surv(365,x) # 1年OS\nsurv2 &lt;- function(x) surv(365*2,x) # 2年OS\n\n构建列线图数据:\n\n# 构建列线图数据\nnom &lt;- nomogram(coxfit,\n                fun = list(surv1,surv2),\n                funlabel = c('1-year survival Probability',\n                         '2-year survival Probability'),\n                fun.at = c(0.95,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1))\n\n然后就是画图：\n\nplot(nom, \n     lplabel=\"Linear Predictor\",\n     xfrac = 0.2, # 左侧标签距离坐标轴的距离\n     #varname.label = TRUE, \n     tcl = -0.2, # 刻度长短和方向 \n     lmgp = 0.1, # 坐标轴标签距离坐标轴远近\n     points.label ='Points', \n     total.points.label = 'Total Points',\n     cap.labels = FALSE,\n     cex.var = 1, # 左侧标签字体大小\n     cex.axis = 1, # 坐标轴字体大小\n     col.grid = gray(c(0.8, 0.95))) # 竖线颜色\n\n\n\n\n\n\n\n\n这个图的解读方式和逻辑回归的列线图一模一样，这里就不再重复了，大家看逻辑回归的那篇。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cox回归列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-cox.html#方法2regplot",
    "href": "nomogram-cox.html#方法2regplot",
    "title": "8  Cox回归列线图绘制",
    "section": "8.3 方法2：regplot",
    "text": "8.3 方法2：regplot\n使用regplot包实现。\n\nlibrary(regplot)\n\n# 建立cox回归模型\ncoxfit &lt;- cph(Surv(time, status) ~ age+sex+ph.ecog+ph.karno+pat.karno,\n              data = lung, x=T,y=T,surv = T\n              )\n\n# 画图即可\naa &lt;- regplot(coxfit,\n        #连续性变量形状，\"no plot\"\"density\"\"boxes\"\"ecdf\"\n        #\"bars\"\"boxplot\"\"violin\"\"bean\" \"spikes\"；\n        #分类变量的形状，可选\"no plot\" \"boxes\" \"bars\" \"spikes\"\n        plots = c(\"violin\", \"boxes\"), \n        observation = lung[1,], #用哪行观测，或者T F\n        center = T, # 对齐变量\n        subticks = T,\n        droplines = T,#是否画竖线\n        title = \"nomogram\",\n        points = T, # 截距项显示为0-100\n        odds = T, # 是否显示OR值\n        showP = T, # 是否显示变量的显著性标记\n        rank = \"sd\", # 根据sd给变量排序\n        interval=\"confidence\", # 展示可信区间\n        clickable = F # 是否可以交互\n        )\n\n除了以上两种方法外，之前还有另外两个R包可以使用：VRPM和DynNom，但是这两个包太老了，很久没更新了，所以目前只能通过下载安装包本地安装。目前不推荐使用了，如果你一定要用，可参考：Cox回归列线图（nomogram）的4种绘制方法",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Cox回归列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-原理.html",
    "href": "nomogram-原理.html",
    "title": "9  列线图的本质",
    "section": "",
    "text": "9.1 列线图与模型的关系\n前面我们展示了绘制逻辑回归和cox回归列线图的多种方法，不知道大家有没有考虑过，其他模型可以绘制列线图吗？例如lasso回归、随机森林等（不行哈，理论可行，实际不行）。这就涉及到列线图到底是怎么绘制出来的。\n对于一个含有多个自变量和1个因变量的逻辑回归来说，回归方程可以写成类似 y=a + b1x1 + b2x2 + b3x3 这种形式，其中b是回归系数。列线图就是把回归方程用图形的方式展现出来，线段的长短（分数）根据回归系数计算。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>列线图的本质</span>"
    ]
  },
  {
    "objectID": "nomogram-原理.html#列线图分数的计算方法",
    "href": "nomogram-原理.html#列线图分数的计算方法",
    "title": "9  列线图的本质",
    "section": "9.2 列线图分数的计算方法",
    "text": "9.2 列线图分数的计算方法\n以下面这个列线图为例：\n\n上面这个列线图是一个逻辑回归的，它的逻辑回归的结果是这样的：\n\nlrm(formula = dead ~ birth + lowph + pltct + bwt + vent + black + \n     white, data = tmp, x = T, y = T)                    \n \n           Coef    S.E.    Wald Z Pr(&gt;|Z|)\n Intercept 38.3815 11.0303  3.48  0.0005  \n birth     -0.1201  0.0914 -1.31  0.1890  \n lowph     -4.1451  1.1881 -3.49  0.0005  \n pltct     -0.0017  0.0019 -0.91  0.3644  \n bwt       -0.0031  0.0006 -5.14  &lt;0.0001 \n vent=1     2.7526  0.7436  3.70  0.0002  \n black      1.1974  0.8448  1.42  0.1564  \n white      0.8597  0.8655  0.99  0.3206\n \n## 新的\nlrm(formula = dead == 1 ~ birth + lowph + pltct + bwt + vent + race, data = tmp)\n\n           Coef    S.E.    Wald Z Pr(&gt;|Z|)\nIntercept  39.5788 11.0070  3.60  0.0003  \nbirth      -0.1201  0.0914 -1.31  0.1890  \nlowph      -4.1451  1.1881 -3.49  0.0005  \npltct      -0.0017  0.0019 -0.91  0.3644  \nbwt        -0.0031  0.0006 -5.14  &lt;0.0001 \nvent=1      2.7526  0.7436  3.70  0.0002  \nrace=other -1.1974  0.8448 -1.42  0.1564  \nrace=white -0.3377  0.2953 -1.14  0.2529  \n\n在最下面列出了每个自变量的回归系数，我们首先把回归系数绝对值最大的设置为100分，在这个例子中是lowph，它的回归系数绝对值是4.1451,也就是对应的是100分，然后其他自变量都是根据lowph进行转换，即可算出其他自变量对应的得分！\n然后根据这个表达式得到的列线图的结果是这样的：\n\nnom1\nPoints per unit of linear predictor: 21.93145 \nLinear predictor units per point   : 0.04559661 \n\n birth Points\n 81.5  16    \n 82.0  14    \n 82.5  13    \n 83.0  12    \n 83.5  11    \n 84.0   9    \n 84.5   8    \n 85.0   7    \n 85.5   5    \n 86.0   4    \n 86.5   3    \n 87.0   1    \n 87.5   0    \n\n lowph Points\n 6.5   100   \n 6.6    91   \n 6.7    82   \n 6.8    73   \n 6.9    64   \n 7.0    55   \n 7.1    45   \n 7.2    36   \n 7.3    27   \n 7.4    18   \n 7.5     9   \n 7.6     0   \n\n pltct Points\n   0   22    \n  50   20    \n 100   18    \n 150   17    \n 200   15    \n 250   13    \n 300   11    \n 350    9    \n 400    7    \n 450    6    \n 500    4    \n 550    2    \n 600    0    \n\n bwt  Points\n  400 76    \n  500 69    \n  600 62    \n  700 55    \n  800 48    \n  900 41    \n 1000 34    \n 1100 27    \n 1200 21    \n 1300 14    \n 1400  7    \n 1500  0    \n\n vent Points\n 0     0    \n 1    60    \n\n race  Points\n black 26    \n other  0    \n white 19    \n\n Total Points  Dead\n           53 0.001\n          104 0.010\n          157 0.100\n          181 0.250\n          205 0.500\n          229 0.750\n          253 0.900\n\n上面的 Linear predictor units per point: 0.04559661  意思是每一个小刻度代表的分数是0.04559661分，这实际上是最大回归系数的1/100(这里应该是4.1451/100=0.041451，实际上会有偏差！)。\n\n9.2.1 分类变量分数的计算\n以vent为例，vent=1的时候，它的回归系数是2.7526，那么它对应的分数应该是 2.7526/0.04559661 * 100 ≈ 60，上面得到的结果是60分，一样的！black应该是 1.1974/0.04559661 * 100 ≈ 26，也和我们算的差不多！\n这就是分类变量分数的计算。\n\n\n9.2.2 连续性变量分数的计算\n连续性自变量需要考虑取值范围，它的解释应该是每增加一个单位，因变量变化多少，对于pltct来说，系数是-0.0017，就是每增加1各单位，因变量减少0.0017。\npltct是600，对应的分数是0分，那么如果是100，对应的分数就是 （600-100）* (0.0017/0.04559661) ≈ 18。\n这就是连续性变量分数的计算。\n了解了列线图的分数计算方法，即使没有R语言，你也可以通过手动计算算出来，这样你可以自己画图！（理论上可行，但实际上很难，至少我还没见到过…）",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>列线图的本质</span>"
    ]
  },
  {
    "objectID": "nomogram-rcs.html",
    "href": "nomogram-rcs.html",
    "title": "10  样条回归列线图绘制",
    "section": "",
    "text": "10.1 逻辑回归的RCS列线图\n建立逻辑回归模型：\n# 加载数据\nload(file = \"./datasets/titanic3.rdata\")\n# 使用rms前先把数据打包\ndd &lt;- datadist(titanic3); options(datadist='dd')\n\n# 逻辑回归的立方样条，对age这个变量做样条变换\nf &lt;- lrm(survived ~ rcs(sqrt(age),5) + sex, data=titanic3)\n#f\n下面直接画图即可，没有任何难度，因为rms这个包把一切都给你做好了，不用自己操心，如果你做临床预测模型，是不可能绕开这个包的。\nnom &lt;- nomogram(f, fun=plogis, funlabel=\"Risk of Death\")  \nplot(nom)\n这样RCS的列线图就画好了，关于一些参数的意义和细节的美化，可以参考前面的文章，这里就不多说了。在图中Age这个变量的线条有一些拥挤，这就是样条变换的原因，它需要给你计算分数，所以就挤到一起了，这是rms自动帮你搞的，很方便。\n既然逻辑回归没问题，那COX回归自然也是没问题的！",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>样条回归列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-rcs.html#cox回归rcs的列线图",
    "href": "nomogram-rcs.html#cox回归rcs的列线图",
    "title": "10  样条回归列线图绘制",
    "section": "10.2 COX回归RCS的列线图",
    "text": "10.2 COX回归RCS的列线图\n准备一个生存数据，就用survival自带的肺癌数据：lung\n\nrm(list = ls())\nlibrary(survival)\n\n# 打包数据\ndd &lt;- datadist(lung)\noptions(datadist = \"dd\")\n\n构建cox比例风险模型：\n\ncoxfit &lt;- cph(Surv(time, status) ~ rcs(sqrt(age),5) + sex,\n              data = lung, x=T,y=T,surv = T\n              )\n\n# 构建生存函数，计算生存率，注意你的最大生存时间\nsurv &lt;- Survival(coxfit) \nsurv1 &lt;- function(x) surv(365,x) # 1年OS\nsurv2 &lt;- function(x) surv(365*2,x) # 2年OS\n\n# 画图\nnom &lt;- nomogram(coxfit, fun = list(surv1,surv2),\n                funlabel = c('1-year survival Probability',\n                             '2-year survival Probability')\n                )\n\nplot(nom)\n\n\n\n\n\n\n\n\n这就是COX回归RCS的列线图，是不是很简单？\n因为是演示数据，所以画出来的图不是很美观，但是实现方法就是这么简单！只要是rms包支持的方法，都可以绘制列线图。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>样条回归列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-compete-risk.html",
    "href": "nomogram-compete-risk.html",
    "title": "11  竞争风险模型列线图绘制",
    "section": "",
    "text": "11.1 加载数据和R包\n探讨骨髓移植和血液移植治疗白血病的疗效，结局事件定义为复发，某些患者因为移植不良反应死亡，定义为竞争风险事件。\nrm(list = ls())\ndata(\"bmtcrr\",package = \"casebase\")\nstr(bmtcrr)\n## 'data.frame':    177 obs. of  7 variables:\n##  $ Sex   : Factor w/ 2 levels \"F\",\"M\": 2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : Factor w/ 2 levels \"ALL\",\"AML\": 1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : Factor w/ 4 levels \"CR1\",\"CR2\",\"CR3\",..: 4 2 3 2 2 4 1 1 1 4 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Status: int  2 1 0 2 2 2 0 2 0 1 ...\n##  $ Source: Factor w/ 2 levels \"BM+PB\",\"PB\": 1 1 1 1 1 1 1 1 1 1 ...\n##  $ ftime : num  0.67 9.5 131.77 24.03 1.47 ...\n这个数据一共7个变量，177行。\n# 竞争风险分析需要用的R包\nlibrary(cmprsk)",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>竞争风险模型列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-compete-risk.html#加载数据和r包",
    "href": "nomogram-compete-risk.html#加载数据和r包",
    "title": "11  竞争风险模型列线图绘制",
    "section": "",
    "text": "Sex: 性别，F是女，M是男\nD: 疾病类型，ALL是急性淋巴细胞白血病，AML是急性髓系细胞白血病。\nPhase: 不同阶段，4个水平，CR1，CR2，CR3，Relapse。\nAge: 年龄。\nStatus: 结局变量，0=删失，1=复发，2=竞争风险事件。\nSource: 因子变量，2个水平：BM+PB(骨髓移植+血液移植)，PB(血液移植)。\nftime: 生存时间。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>竞争风险模型列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-compete-risk.html#竞争风险模型多因素分析",
    "href": "nomogram-compete-risk.html#竞争风险模型多因素分析",
    "title": "11  竞争风险模型列线图绘制",
    "section": "11.2 竞争风险模型（多因素分析）",
    "text": "11.2 竞争风险模型（多因素分析）\n做完了单因素分析，再看看竞争风险模型的多因素分析。\n首先要把自变量单独放在一个数据框里，使用中发现一个问题，这里如果把分类变量变为因子型不会自动进行哑变量编码，所以需要手动进行哑变量编码！\n但是我这里偷懒了，并没有进行哑变量设置！实际中是需要的哦！！\n\ncovs &lt;- subset(bmtcrr, select = - c(ftime,Status))\ncovs[,c(1:3,5)] &lt;- lapply(covs[,c(1:3,5)],as.integer)\n\nstr(covs)\n## 'data.frame':    177 obs. of  5 variables:\n##  $ Sex   : int  2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : int  1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : int  4 2 3 2 2 4 1 1 1 4 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Source: int  1 1 1 1 1 1 1 1 1 1 ...\n\n指定failcode=1, cencode=0, 分别代表结局事件1与截尾0，其他默认为竞争风险事件2。\n\n# 构建竞争风险模型\nf2 &lt;- crr(bmtcrr$ftime, bmtcrr$Status, covs, failcode=1, cencode=0)\nsummary(f2)\n## Competing Risks Regression\n## \n## Call:\n## crr(ftime = bmtcrr$ftime, fstatus = bmtcrr$Status, cov1 = covs, \n##     failcode = 1, cencode = 0)\n## \n##           coef exp(coef) se(coef)      z p-value\n## Sex     0.0494     1.051   0.2867  0.172 0.86000\n## D      -0.4860     0.615   0.3040 -1.599 0.11000\n## Phase   0.4144     1.514   0.1194  3.470 0.00052\n## Age    -0.0174     0.983   0.0118 -1.465 0.14000\n## Source  0.9526     2.592   0.5469  1.742 0.08200\n## \n##        exp(coef) exp(-coef)  2.5% 97.5%\n## Sex        1.051      0.952 0.599  1.84\n## D          0.615      1.626 0.339  1.12\n## Phase      1.514      0.661 1.198  1.91\n## Age        0.983      1.018 0.960  1.01\n## Source     2.592      0.386 0.888  7.57\n## \n## Num. cases = 177\n## Pseudo Log-likelihood = -267 \n## Pseudo likelihood ratio test = 23.6  on 5 df,\n\n结果解读：在控制了竞争分险事件后，phase变量，即疾病所处阶段是患者复发的独立影响因素(p =0.00052)。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>竞争风险模型列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-compete-risk.html#列线图",
    "href": "nomogram-compete-risk.html#列线图",
    "title": "11  竞争风险模型列线图绘制",
    "section": "11.3 列线图",
    "text": "11.3 列线图\nregplot包绘制列线图。但是它目前只适用coxph()、lm()和glm()返回的对象。\n因此我们需要对原数据集加权创建一个新数据集用于为竞争风险模型分析，使用mstate包中的crprep()创建加权数据集,然后使用coxph()对加权数据集进行竞争风险模型拟合，这样就可以画列线图了。\n首先是加载数据和R包：\n\nrm(list = ls())\ndata(\"bmtcrr\",package = \"casebase\") # 还是这个数据\n\nlibrary(mstate) # 加权用到的R包\n\nbmtcrr$id &lt;- 1:nrow(bmtcrr) # 创建id\n\n# phase变为2分类，不然列线图不好解释\nbmtcrr$Phase &lt;- factor(ifelse(bmtcrr$Phase==\"Relapse\",1,0)) \nstr(bmtcrr)\n## 'data.frame':    177 obs. of  8 variables:\n##  $ Sex   : Factor w/ 2 levels \"F\",\"M\": 2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : Factor w/ 2 levels \"ALL\",\"AML\": 1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : Factor w/ 2 levels \"0\",\"1\": 2 1 1 1 1 2 1 1 1 2 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Status: int  2 1 0 2 2 2 0 2 0 1 ...\n##  $ Source: Factor w/ 2 levels \"BM+PB\",\"PB\": 1 1 1 1 1 1 1 1 1 1 ...\n##  $ ftime : num  0.67 9.5 131.77 24.03 1.47 ...\n##  $ id    : int  1 2 3 4 5 6 7 8 9 10 ...\n\n然后是对原数据进行加权：\n\ndf.w &lt;- crprep(\"ftime\", \"Status\",\n               data=bmtcrr, \n               trans=c(1,2),# 要加权的变量，1表示结局事件，2表示竞争风险事件\n               cens=0, # 删失\n               id=\"id\",\n               \n               # 要保留的协变量\n               keep=c(\"Age\",\"Sex\",\"D\",\"Source\",\"Phase\"))\n\nhead(df.w)\n##   id Tstart Tstop status weight.cens Age Sex   D Source Phase count failcode\n## 1  1   0.00  0.67      2   1.0000000  48   M ALL  BM+PB     1     1        1\n## 2  1   0.67  9.50      2   1.0000000  48   M ALL  BM+PB     1     2        1\n## 3  1   9.50 13.07      2   0.9679938  48   M ALL  BM+PB     1     3        1\n## 4  1  13.07 17.23      2   0.8730924  48   M ALL  BM+PB     1     4        1\n## 5  1  17.23 20.83      2   0.8536904  48   M ALL  BM+PB     1     5        1\n## 6  1  20.83 28.53      2   0.8120469  48   M ALL  BM+PB     1     6        1\ndf.w$T&lt;- df.w$Tstop - df.w$Tstart\n\n上述代码已经创建一个加权数据集df.w，此时还需要选择failcode==1的行，然后我们才可以在此数据集上使用coxph()函数进行竞争风险分析，不然最后画列线图会报错。\n\n# 参考资料\n# https://blog.csdn.net/zhongkeyuanchongqing/article/details/124086113\ndf.w2 &lt;- df.w[df.w$failcode == 1,]\n\n构建cox模型：\n\nm.crr&lt;- coxph(Surv(T,status==1)~Age+Sex+D+Source+Phase,\n             data=df.w2,\n             weight=weight.cens,\n             subset=failcode==1)\nsummary(m.crr)\n## Call:\n## coxph(formula = Surv(T, status == 1) ~ Age + Sex + D + Source + \n##     Phase, data = df.w2, weights = weight.cens, subset = failcode == \n##     1)\n## \n##   n= 686, number of events= 56 \n## \n##              coef exp(coef) se(coef) robust se      z Pr(&gt;|z|)    \n## Age      -0.02174   0.97850  0.01172   0.01208 -1.800 0.071914 .  \n## SexM      0.10551   1.11128  0.27981   0.29571  0.357 0.721247    \n## DAML     -0.53163   0.58764  0.29917   0.30613 -1.737 0.082450 .  \n## SourcePB  1.06564   2.90269  0.53453   0.56000  1.903 0.057051 .  \n## Phase1    1.06140   2.89040  0.27870   0.28129  3.773 0.000161 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##          exp(coef) exp(-coef) lower .95 upper .95\n## Age         0.9785     1.0220    0.9556     1.002\n## SexM        1.1113     0.8999    0.6225     1.984\n## DAML        0.5876     1.7017    0.3225     1.071\n## SourcePB    2.9027     0.3445    0.9686     8.699\n## Phase1      2.8904     0.3460    1.6654     5.016\n## \n## Concordance= 0.737  (se = 0.037 )\n## Likelihood ratio test= 28.33  on 5 df,   p=3e-05\n## Wald test            = 27.27  on 5 df,   p=5e-05\n## Score (logrank) test = 30.49  on 5 df,   p=1e-05,   Robust = 20.2  p=0.001\n## \n##   (Note: the likelihood ratio and score tests assume independence of\n##      observations within a cluster, the Wald and robust score tests do not).\n\n接下来，我们可以使用regplot()函数绘制nomogram。其实你可以绘制多种不同的列线图，可以参考之前的推文：生存资料列线图的4种绘制方法\n\nlibrary(regplot)\naa &lt;- regplot(m.crr,\n        observation=df.w2[df.w2$id==25&df.w2$failcode==1,],\n        failtime = c(36, 60), \n        prfail = T, \n        droplines=T)\n\n\n在这个列线图中，将数据集中id=25的患者各协变量的取值映射到相应的得分，并计算总得分,并分别计算其在36个月和60个月的累计复发概率，此概率即为控制了竞争风险的累计复发概率，分别为：0.134和0.146。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>竞争风险模型列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-lasso.html",
    "href": "nomogram-lasso.html",
    "title": "12  lasso回归列线图绘制",
    "section": "",
    "text": "lasso回归的列线图绘制请参考Chapter 33：lasso回归列线图、校准曲线、内外部验证。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>lasso回归列线图绘制</span>"
    ]
  },
  {
    "objectID": "nomogram-colorfulbar.html",
    "href": "nomogram-colorfulbar.html",
    "title": "13  列线图添加彩色风险分层",
    "section": "",
    "text": "13.1 加载数据和R包\nlibrary(survival)\nlibrary(rms)\ndim(lung)\n## [1] 228  10\nstr(lung)\n## 'data.frame':    228 obs. of  10 variables:\n##  $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n##  $ time     : num  306 455 1010 210 883 ...\n##  $ status   : num  2 2 1 2 2 1 2 2 2 2 ...\n##  $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n##  $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n##  $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n##  $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n##  $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n##  $ meal.cal : num  1175 1225 NA 1150 NA ...\n##  $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ...",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>列线图添加彩色风险分层</span>"
    ]
  },
  {
    "objectID": "nomogram-colorfulbar.html#传统列线图",
    "href": "nomogram-colorfulbar.html#传统列线图",
    "title": "13  列线图添加彩色风险分层",
    "section": "13.2 传统列线图",
    "text": "13.2 传统列线图\n大多数情况下都是使用1代表死亡，0代表删失，这个数据集用2代表死亡。在这里没有影响，但有的R包会报错，需要注意！\n\ndd &lt;- datadist(lung)\noptions(datadist = \"dd\")\n\n构建cox比例风险模型：\n\ncoxfit &lt;- cph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno,\n              data = lung, surv = T)\n\n# 构建生存函数，注意你的最大生存时间\nsurv &lt;- Survival(coxfit) \nsurv1 &lt;- function(x) surv(365,x) # 1年OS\nsurv2 &lt;- function(x) surv(365*2,x) # 2年OS\n\nnom &lt;- nomogram(coxfit,\n                fun = list(surv1,surv2),\n                lp = T,\n                funlabel = c('1-year survival Probability',\n                         '2-year survival Probability'),\n                maxscale = 100,\n                fun.at = c(0.95,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1))\n\n然后就是默认的画图，没有任何难度：\n\nplot(nom, \n     lplabel=\"Linear Predictor\",\n     xfrac = 0.2, # 左侧标签距离坐标轴的距离\n     #varname.label = TRUE, \n     tcl = -0.2, # 刻度长短和方向 \n     lmgp = 0.1, # 坐标轴标签距离坐标轴远近\n     points.label ='Points', \n     total.points.label = 'Total Points',\n     cap.labels = FALSE,\n     cex.var = 1, # 左侧标签字体大小\n     cex.axis = 1, # 坐标轴字体大小\n     col.grid = gray(c(0.8, 0.95))) # 竖线颜色",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>列线图添加彩色风险分层</span>"
    ]
  },
  {
    "objectID": "nomogram-colorfulbar.html#新型列线图",
    "href": "nomogram-colorfulbar.html#新型列线图",
    "title": "13  列线图添加彩色风险分层",
    "section": "13.3 新型列线图",
    "text": "13.3 新型列线图\n如何给列线图添加风险分层条带呢？其实思路是很简单的，只要在合适的位置插入颜色条即可。\n为了达到这个目的，需要你对base r的绘图语法足够熟悉。\n直接用rect即可在原图形继续添加矩形区域，然后给它一个颜色即可，除此之外，我们还可以用text函数在底部添加文字提示，让这个图形看上去更加美观实用。\n\n#pdf(\"nomogram.pdf\")\nplot(nom, \n     lplabel=\"Risk Stratification\",\n     xfrac = 0.2, # 左侧标签距离坐标轴的距离\n     #varname.label = TRUE, \n     tcl = -0.2, # 刻度长短和方向 \n     lmgp = 0.1, # 坐标轴标签距离坐标轴远近\n     points.label ='Points', \n     total.points.label = 'Total Points',\n     cap.labels = FALSE,\n     cex.var = 1, # 左侧标签字体大小\n     cex.axis = 1, # 坐标轴字体大小\n     col.grid = gray(c(0.8, 0.95))) # 竖线颜色\nrect(0.29,0.20,0.5,0.26,col = \"#01847F\") # 添加彩色条带\nrect(0.5,0.20,0.7,0.26,col = \"#FBD26A\")\nrect(0.7,0.20,0.935,0.26,col = \"#F40002\")\ntext(0.4,0.18,\"Low\")\ntext(0.6,0.18,\"Medium\")\ntext(0.83,0.18,\"High\")\n#dev.off()\n\n\n这样一个新型的带颜色条的列线图就绘制好了。是不是很简单呢？\n我说说我的具体思路，首先用rect函数添加3个彩色条带，其用法是rect(min(x),min(y),max(x),max(y))，前四个参数确定位置。然后使用text函数在合适的位置添加文字即可。\n这个彩色条带刚好覆盖在原来的Linear Predictor的位置，当然这个位置需要你不断的尝试才能确定，而且我这里的风险分层为了演示是随便选的，你需要根据自己的实际情况确定到底什么分数段属于什么分层，然后不断调整位置直到你满意为止。\n但是这个图现在还是有点问题的，主要是左侧遗留了一个-1，没办法去掉。\n当然了，你也可以直接把传统列线图保存为PDF，然后用AI等软件编辑，更加自由！",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>列线图添加彩色风险分层</span>"
    ]
  },
  {
    "objectID": "nomogram-colorfulbar.html#继续改进",
    "href": "nomogram-colorfulbar.html#继续改进",
    "title": "13  列线图添加彩色风险分层",
    "section": "13.4 继续改进",
    "text": "13.4 继续改进\n我又去pubmed以及google使用关键词nomogram继续搜索，果然又搜到一篇带有彩色条带的列线图，而且我感觉这个图更加好看！\n\n文献DOI：10.1093/eurheartj/ehab294\n上面这个图不仅有彩色条带展示分层，而且还增加了彩色箭头标识，并在最底部也增加了彩色线条标识。\n下面我们继续学习这个列线图怎么画，思路和上面基本是一样的。\n首先是再添加一个颜色条：\n\n#pdf(\"nomogram.pdf\")\nplot(nom, \n     lplabel=\"Risk Stratification\",#名字就不改了\n     xfrac = 0.2, # 左侧标签距离坐标轴的距离\n     #varname.label = TRUE, \n     tcl = -0.2, # 刻度长短和方向 \n     lmgp = 0.1, # 坐标轴标签距离坐标轴远近\n     points.label ='Points', \n     total.points.label = 'Total Points',\n     cap.labels = FALSE,\n     cex.var = 1, # 左侧标签字体大小\n     cex.axis = 1, # 坐标轴字体大小\n     col.grid = gray(c(0.8, 0.95))) # 竖线颜色\nrect(0.29,0.245,0.5,0.26,col = \"#01847F\") # 添加彩色条带\nrect(0.5,0.245,0.7,0.26,col = \"#FBD26A\")\nrect(0.7,0.245,0.935,0.26,col = \"#F40002\")\ntext(0.4,0.28,\"Low\")\ntext(0.6,0.28,\"Medium\")\ntext(0.83,0.28,\"High\")\n\n#在底部再增加3个彩色条带，高度错开，显得有层次感\nrect(0.37,0.14,0.5,0.144,col = \"#01847F\")\nrect(0.5,0.144,0.7,0.148,col = \"#FBD26A\")\nrect(0.7,0.148,0.835,0.152,col = \"#F40002\")\n#如果你还要继续添加文字说明也可以，我这里就不加了\n#dev.off()\n\n\n彩色箭头如何添加？一模一样的思路，选择一个你想展示的病人，然后计算它每一项的分数，然后使用arrows函数在合适的位置绘制箭头即可。\n下面随便展示下，我这里并没有认真计算这个人的各项分数。如果你需要展示，可以用nomogramformula包计算，或者看下一篇文章演示。\n\n#pdf(\"nomogram.pdf\")\nplot(nom, \n     lplabel=\"Risk Stratification\",#名字就不改了\n     xfrac = 0.2, # 左侧标签距离坐标轴的距离\n     #varname.label = TRUE, \n     tcl = -0.2, # 刻度长短和方向 \n     lmgp = 0.1, # 坐标轴标签距离坐标轴远近\n     points.label ='Points', \n     total.points.label = 'Total Points',\n     cap.labels = FALSE,\n     cex.var = 1, # 左侧标签字体大小\n     cex.axis = 1, # 坐标轴字体大小\n     col.grid = gray(c(0.8, 0.95))) # 竖线颜色\nrect(0.29,0.245,0.5,0.26,col = \"#01847F\") # 添加彩色条带\nrect(0.5,0.245,0.7,0.26,col = \"#FBD26A\")\nrect(0.7,0.245,0.935,0.26,col = \"#F40002\")\ntext(0.4,0.28,\"Low\")\ntext(0.6,0.28,\"Medium\")\ntext(0.83,0.28,\"High\")\n\n#在底部再增加3个彩色条带，高度错开，显得有层次感\nrect(0.37,0.14,0.5,0.144,col = \"#01847F\")\nrect(0.5,0.144,0.7,0.148,col = \"#FBD26A\")\nrect(0.7,0.148,0.835,0.152,col = \"#F40002\")\n#如果你还要继续添加文字说明也可以，我这里就不加了\n\n# 添加箭头\narrows(0.205,0.86,0.205,0.96,col = \"steelblue\",lwd = 4,length = 0.1)\narrows(0.4,0.76,0.4,0.96,col = \"steelblue\",lwd = 4,length = 0.1)\narrows(0.68,0.655,0.68,0.96,col = \"steelblue\",lwd = 4,length = 0.1)\narrows(0.28,0.55,0.28,0.96,col = \"steelblue\",lwd = 4,length = 0.1)\narrows(0.47,0.45,0.47,0.96,col = \"steelblue\",lwd = 4,length = 0.1)\n\n# 总分箭头，加起来可能不对，单纯演示下\narrows(0.84,0.40,0.84,0.35,col = \"#F40002\",lwd = 4,length = 0.1)\n#dev.off()\n\n\n这样一个非常漂亮的列线图就画好了，层次分明，细节满满，让人耳目一新，大家赶紧用起来吧！",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>列线图添加彩色风险分层</span>"
    ]
  },
  {
    "objectID": "nomogram-points.html",
    "href": "nomogram-points.html",
    "title": "14  计算列线图得分及危险分层",
    "section": "",
    "text": "14.1 准备数据\n使用R包自带数据。\nlibrary(survival)\nlibrary(rms)\n\nrm(list = ls())\n\ndim(lung)\n## [1] 228  10\nstr(lung)\n## 'data.frame':    228 obs. of  10 variables:\n##  $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n##  $ time     : num  306 455 1010 210 883 ...\n##  $ status   : num  2 2 1 2 2 1 2 2 2 2 ...\n##  $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n##  $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n##  $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n##  $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n##  $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n##  $ meal.cal : num  1175 1225 NA 1150 NA ...\n##  $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ...",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>计算列线图得分及危险分层</span>"
    ]
  },
  {
    "objectID": "nomogram-points.html#建立模型和列线图",
    "href": "nomogram-points.html#建立模型和列线图",
    "title": "14  计算列线图得分及危险分层",
    "section": "14.2 建立模型和列线图",
    "text": "14.2 建立模型和列线图\n使用rms包构建模型和列线图。\n大多数情况下都是使用1代表死亡，0代表删失，这个数据集用2代表死亡。在这里没有影响，但有的R包会报错，需要注意！\n\ndd &lt;- datadist(lung)\noptions(datadist = \"dd\")\n\n构建cox比例风险模型：\n\ncoxfit &lt;- cph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno,\n              data = lung ,surv = T)\n\n# 构建生存函数，注意你的最大生存时间\nsurv &lt;- Survival(coxfit) \nsurv1 &lt;- function(x) surv(365,x) # 1年OS\nsurv2 &lt;- function(x) surv(365*2,x) # 2年OS\n\nnom &lt;- nomogram(coxfit,\n                fun = list(surv1,surv2),\n                lp = T,\n                funlabel = c('1-year survival Probability',\n                         '2-year survival Probability'),\n                maxscale = 100,\n                fun.at = c(0.95,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1))\n\n然后就是画图：\n\nplot(nom, \n     lplabel=\"Linear Predictor\",\n     xfrac = 0.2, # 左侧标签距离坐标轴的距离\n     #varname.label = TRUE, \n     tcl = -0.2, # 刻度长短和方向 \n     lmgp = 0.1, # 坐标轴标签距离坐标轴远近\n     points.label ='Points', \n     total.points.label = 'Total Points',\n     cap.labels = FALSE,\n     cex.var = 1, # 左侧标签字体大小\n     cex.axis = 1, # 坐标轴字体大小\n     col.grid = gray(c(0.8, 0.95))) # 竖线颜色\n\n\n\n\n\n\n\n\n到这里都很简单。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>计算列线图得分及危险分层</span>"
    ]
  },
  {
    "objectID": "nomogram-points.html#计算分数",
    "href": "nomogram-points.html#计算分数",
    "title": "14  计算列线图得分及危险分层",
    "section": "14.3 计算分数",
    "text": "14.3 计算分数\n使用nomogramFormula计算每个患者的列线图得分。\n两种方法，一种是使用formula_lp根据线性预测值计算，另一种是使用formula_rd根据原始数据（raw_data）计算，两种方法结果差不多，任选一种即可。\n\nlibrary(nomogramFormula)\nresults &lt;- formula_lp(nomogram = nom)\npoints1 &lt;- points_cal(formula = results$formula, lp = coxfit$linear.predictors)\n\n#或者\n#results &lt;- formula_rd(nomogram = nom)\n#points1 &lt;- points_cal(formula = results$formula, rd = lung)\n\nlength(points1)\n## [1] 223\nhead(points1)\n##         1         2         3         4         5         6 \n## 129.96853  98.56938  90.51815 142.40181 102.54570 104.51291\n\n这样每个人都根据列线图得到一个分数，根据这个分数就可以把所有患者分成高风险组/低风险组了。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>计算列线图得分及危险分层</span>"
    ]
  },
  {
    "objectID": "nomogram-points.html#分层",
    "href": "nomogram-points.html#分层",
    "title": "14  计算列线图得分及危险分层",
    "section": "14.4 分层",
    "text": "14.4 分层\n假如我们想根据列线图得分进行分层，使得分层后两组的K-M生存分析的p值最小，方法很多，任选一种即可，我这里就用surv_cutpoint演示。\n但是计算出来的分数有223个，原始数据是228个，因为数据有缺失值，在建立模型时有5个样本被删了，这时候你回过去找不一定找得到缺失值在哪（我能找到），所以建议一开始就把缺失值处理掉。\n\nlibrary(tidyr)\nlibrary(survminer)\n\n# 去掉缺失值\ntmp &lt;- lung %&gt;% \n  drop_na(ph.ecog,ph.karno,pat.karno)\ndim(tmp)\n## [1] 223  10\n\ntmp$points &lt;- points1\n\n# 确定最佳截点，然后根据最佳截点分层\nres.cut &lt;- surv_cutpoint(tmp, time = \"time\", event = \"status\",\n                         variables = \"points\"\n                         )\n\n# 查看最佳分割点\nres.cut[[\"cutpoint\"]][[\"cutpoint\"]]\n## [1] 109.2188\n\n# 根据最佳截点分层\nres.cat &lt;- surv_categorize(res.cut)\n\n绘制生存曲线：\n\nlibrary(\"survival\")\nfit &lt;- survfit(Surv(time, status) ~ points, data = res.cat)\nggsurvplot(fit, data = res.cat, pval = T)\n\n\n\n\n\n\n\n\n中间的数据展示省略了很多，还不熟悉这一套流程的可以一步一步的看，结合之前的文章。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>计算列线图得分及危险分层</span>"
    ]
  },
  {
    "objectID": "nomogram-points.html#外部验证集",
    "href": "nomogram-points.html#外部验证集",
    "title": "14  计算列线图得分及危险分层",
    "section": "14.5 外部验证集",
    "text": "14.5 外部验证集\n大家一定要学会变通啊，学会R语言的基础知识，才好举一反三。\n外部验证集的分数计算直接使用formula_rd()函数就可以了（不管训练集还是外部验证集我都推荐使用这个，前面为了演示没用这个函数），rd参数提供外部验证集即可：\n\n# 假设这是外部验证集\nvaldf &lt;- na.omit(lung[1:100,])\n\n# 计算分数\nresults &lt;- formula_rd(nomogram = nom)\npoints_val &lt;- points_cal(formula = results$formula, \n                         rd = valdf) # 外部验证集\n\nlength(points_val)\n## [1] 74\nhead(points_val)\n## [1]  98.56934 142.40178 104.51289 131.33431 112.08372 109.11084\n\n前面我们计算的最佳截点是109.2188，现在就根据这个截点对外部验证集分组，高于这个值就是高风险，低于这个值就是低风险：\n\nvaldf$points &lt;- points_val\nvaldf$groups &lt;- ifelse(valdf$points&gt;109.2188,\"high\",\"low\")\nhead(valdf[,11:12])\n##      points groups\n## 2  98.56934    low\n## 4 142.40178   high\n## 6 104.51289    low\n## 7 131.33431   high\n## 8 112.08372   high\n## 9 109.11084    low\n\n绘制外部验证集的生存曲线：\n\nlibrary(\"survival\")\nfit &lt;- survfit(Surv(time, status) ~ groups, data = valdf)\nggsurvplot(fit, data = valdf, pval = T)\n\n\n\n\n\n\n\n\n是不是一样的简单？",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>计算列线图得分及危险分层</span>"
    ]
  },
  {
    "objectID": "nomogram-points.html#扩展",
    "href": "nomogram-points.html#扩展",
    "title": "14  计算列线图得分及危险分层",
    "section": "14.6 扩展",
    "text": "14.6 扩展\n这里是根据列线图的得分进行分层的，其实也可以直接根据模型得到的线性预测值进行分层，就是直接使用predict即可：\n\npredict(coxfit,head(lung))\n##          1          2          3          4          5          6 \n##  0.3113300 -0.2213878 -0.3579849  0.5222729 -0.1539256 -0.1205499\n\n这个东西就是大家常见的risk-score，当然这只是其中一种计算方式，不同的模型计算方法略有不同。\n而且cox回归得到的这个线性预测值又叫做预后指数（prognosis index, PI），这个值在统计学中是有明确含义的，根据这个值进行危险分层也是完全没问题的。\n\n预后指数越大，患者风险越大，预后越差。–孙振球《医学统计学》第4版P293\n\n最早的建模类文章都是这么干的，现在也不少见。优点就是少了计算分数那一步，缺点嘛暂时没发现，毕竟都是模仿，你发文章只要把你的故事说清楚即可。",
    "crumbs": [
      "模型建立和可视化",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>计算列线图得分及危险分层</span>"
    ]
  },
  {
    "objectID": "feature-selection_unimulti.html",
    "href": "feature-selection_unimulti.html",
    "title": "15  变量选择之先单后多",
    "section": "",
    "text": "15.1 准备数据\n我们使用TCGA-BLCA的lncRNA数据，其中包括408个样本，time_months是生存时间，event是生存状态，1代表死亡，0代表生存，其余变量都是自变量。\n先简单处理一下数据（数据已放在粉丝QQ群文件）：\nrm(list = ls())\nload(file = \"datasets/lnc_expr_clin.RData\")\n#去掉没有生存信息的样本\nlnc_expr_clin1 &lt;- lnc_expr_clin[!is.na(lnc_expr_clin$time_months),]\nlnc_expr_clin1 &lt;- lnc_expr_clin1[lnc_expr_clin1$time_months&gt;0,]\n\n#选择其中一部分数据\ndat.cox &lt;- lnc_expr_clin1[,c(72:73,1:59)]\ndim(dat.cox)\n## [1] 297  61\ndat.cox[1:4,1:6]\n##   event time_months   PGM5-AS1 LINC01082 AC005180.2 AC005180.1\n## 1     0       36.33 0.15064007 0.2642238  0.0000000  0.1547768\n## 2     0       13.87 0.06309362 0.1666554  0.3105983  0.2436603\n## 3     1       21.83 2.16399508 3.5662920  2.2454129  2.0073496\n## 4     0       18.20 2.73075081 1.7314314  0.8609916  0.7323014\n现在这个数据一共59个自变量，我们先对每一个自变量都做一遍单因素COX回归，但是要注意，这里的59个自变量都是连续型的，通常基因表达量增加1，死亡风险增加xx倍这种情况是不可能发生的，这样的结果解释也是不合理的，所以我们需要先把这样的变量重新分箱，比如根据中位数分成两组，再进行单因素COX回归。\ndat_cox &lt;- dat.cox\ndat_cox[,c(3:ncol(dat_cox))] &lt;- sapply(dat_cox[,c(3:ncol(dat_cox))],function(x){\n  ifelse(x&gt;median(x),\"high\",\"low\")\n})\ndat_cox[,c(3:ncol(dat_cox))] &lt;- lapply(dat_cox[,c(3:ncol(dat_cox))],factor)\ndat_cox[1:4,1:6]\n##   event time_months PGM5-AS1 LINC01082 AC005180.2 AC005180.1\n## 1     0       36.33     high       low        low        low\n## 2     0       13.87      low       low       high       high\n## 3     1       21.83     high      high       high       high\n## 4     0       18.20     high      high       high       high",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>变量选择之先单后多</span>"
    ]
  },
  {
    "objectID": "feature-selection_unimulti.html#批量单因素cox",
    "href": "feature-selection_unimulti.html#批量单因素cox",
    "title": "15  变量选择之先单后多",
    "section": "15.2 批量单因素cox",
    "text": "15.2 批量单因素cox\n然后就可以对每个变量进行单因素COX分析了：\n\nlibrary(survival)\n\ngene &lt;- colnames(dat_cox)[-c(1:2)]\ncox.result &lt;- list()\nfor (i in 1:length(gene)) {\n      #print(i)\n      group &lt;- dat_cox[, i + 2]\n      if (length(table(group)) == 1) next\n      #if (length(grep(\"high\", group)) &lt; min_sample_size) next\n      #if (length(grep(\"low\", group)) &lt; min_sample_size) next\n      x &lt;- survival::coxph(survival::Surv(time_months, event) ~ group, \n                           data = dat_cox)\n      tmp1 &lt;- broom::tidy(x, exponentiate = T, conf.int = T)\n      cox.result[[i]] &lt;- c(gene[i], tmp1)\n    }\n\nres.cox &lt;- data.frame(do.call(rbind, cox.result))\n\n筛选出P值小于0.1的变量：\n\nlibrary(dplyr)\n\nunifea &lt;- res.cox %&gt;% \n  filter(p.value&lt;0.1) %&gt;% \n  pull(V1) %&gt;% \n  unlist()\nunifea\n##  [1] \"AC005180.2\"   \"AC005180.1\"   \"AC053503.3\"   \"MIR100HG\"     \"AP001107.5\"  \n##  [6] \"C5orf66-AS1\"  \"AL162424.1\"   \"ADAMTS9-AS1\"  \"MIR200CHG\"    \"AC093010.3\"  \n## [11] \"AC079313.2\"   \"SNHG25\"       \"AL049555.1\"   \"MIR1-1HG-AS1\" \"SPINT1-AS1\"  \n## [16] \"KRT7-AS\"      \"HAND2-AS1\"    \"AC025575.2\"   \"MAFG-DT\"      \"AL390719.2\"  \n## [21] \"AC002398.2\"   \"AL161431.1\"   \"U62317.1\"     \"AL023284.4\"   \"AATBC\"",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>变量选择之先单后多</span>"
    ]
  },
  {
    "objectID": "feature-selection_unimulti.html#多因素cox",
    "href": "feature-selection_unimulti.html#多因素cox",
    "title": "15  变量选择之先单后多",
    "section": "15.3 多因素cox",
    "text": "15.3 多因素cox\n把这些变量进行多因素COX回归\n\nsub_dat &lt;- dat_cox[,c(\"time_months\",\"event\",unifea)]\ndim(sub_dat)\n## [1] 297  27\nsub_dat[1:4,1:6]\n##   time_months event AC005180.2 AC005180.1 AC053503.3 MIR100HG\n## 1       36.33     0        low        low        low      low\n## 2       13.87     0       high       high       high      low\n## 3       21.83     1       high       high       high     high\n## 4       18.20     0       high       high       high     high\n\n拟合多因素cox回归模型并查看结果：\n\nfinal.fit &lt;- coxph(Surv(time_months,event)~., data = sub_dat)\nres &lt;- broom::tidy(final.fit)\nres\n## # A tibble: 25 × 5\n##    term             estimate std.error statistic p.value\n##    &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n##  1 AC005180.2low      0.146      0.413     0.354 0.723  \n##  2 AC005180.1low     -0.343      0.399    -0.859 0.390  \n##  3 AC053503.3low     -0.139      0.391    -0.355 0.723  \n##  4 MIR100HGlow       -0.365      0.366    -0.997 0.319  \n##  5 AP001107.5low      0.284      0.344     0.825 0.409  \n##  6 `C5orf66-AS1`low  -0.538      0.284    -1.89  0.0587 \n##  7 AL162424.1low      0.0418     0.335     0.125 0.901  \n##  8 `ADAMTS9-AS1`low  -0.947      0.360    -2.63  0.00853\n##  9 MIR200CHGlow       0.0336     0.329     0.102 0.919  \n## 10 AC093010.3low      0.905      0.323     2.80  0.00505\n## # ℹ 15 more rows\n\n查看P值小于0.05的变量：结果只有5个\n\nres %&gt;% filter(p.value&lt;0.05)\n## # A tibble: 5 × 5\n##   term             estimate std.error statistic p.value\n##   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n## 1 `ADAMTS9-AS1`low   -0.947     0.360     -2.63 0.00853\n## 2 AC093010.3low       0.905     0.323      2.80 0.00505\n## 3 SNHG25low           0.592     0.280      2.11 0.0346 \n## 4 AC025575.2low       0.618     0.287      2.16 0.0311 \n## 5 AL161431.1low      -0.704     0.309     -2.28 0.0226\n\n这5个变量可以用于最终的模型中，但是考虑到不同变量之间的交互作用等情况，此时再拟合多因素cox模型，可能还会出现某个变量的P值大于0.05的情况，属于正常现象~\n\nfit5 &lt;- coxph(Surv(time_months,event)~`ADAMTS9-AS1`+AC093010.3+SNHG25+\n                AC025575.2+AL161431.1,data = sub_dat)\nlibrary(survminer)\nsurvminer::ggforest(fit5)\n\n\n\n\n\n\n\n\n上面这个森林图是多因素回归的森林图，和亚组分析的森林图完全不是一回事，不知道大家有没有注意过呢？\n关于森林图和亚组分析的相关问题和详细解释以及各种代码可以在公众号后台回复森林图获取合集。",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>变量选择之先单后多</span>"
    ]
  },
  {
    "objectID": "feature-selection_unimulti.html#行代码实现",
    "href": "feature-selection_unimulti.html#行代码实现",
    "title": "15  变量选择之先单后多",
    "section": "15.4 1行代码实现",
    "text": "15.4 1行代码实现\n手动实现的过程就是为了告诉大家思路是怎样的，这样大家有一定的基础就可以自己做，不管是什么数据，都是一样的思路，用什么方法和工具不重要，思路才是最重要的。\n下面再给大家介绍一个R包，可以实现1行代码完成先单后多cox分析，得到的结果和我们的手动实现的结果是一样的。\n首先安装R包：\n\n#install.packages(\"devtools\")\ndevtools::install_github(\"cardiomoon/autoReg\")\n\n\nlibrary(autoReg)\n\n使用autoReg函数可以实现先单后多cox分析，首先先建立cox模型，此时是多因素cox的形式，但是这个函数会自动帮我们提取数据，然后先批量对每个变量做cox。\n但是！乱七八糟的变量名字是不行的，比如我们演示用的这个lncRNA数据集，变量名字中有-，导致函数报错：\nfit &lt;- coxph(Surv(time_months,event)~., data = dat_cox)\n\nautoReg(fit,\n        threshold = 0.1,\n        uni = T,\n        multi = F\n        )\n\n# 报错\nError in parse(text = eq) : &lt;text&gt;:1:23: unexpected symbol\n1: df[['MIR1-1HG-AS1']]+1HG\n^\n我们给这个数据集的变量名字修改一下即可，我这里直接把-去掉了：\n\ncolnames(dat_cox)&lt;- gsub(\"-\",\"\",colnames(dat_cox))\ndat_cox[1:4,1:6]\n##   event time_months PGM5AS1 LINC01082 AC005180.2 AC005180.1\n## 1     0       36.33    high       low        low        low\n## 2     0       13.87     low       low       high       high\n## 3     1       21.83    high      high       high       high\n## 4     0       18.20    high      high       high       high\n\n这样变量名字中就没有乱七八糟的符号了，此时再进行分析就不会报错了。\n而且结果直接给出了三线表的格式，看起来非常整洁：\n\nfit &lt;- coxph(Surv(time_months,event)~., data = dat_cox)\n\nft &lt;- autoReg(fit,\n        threshold = 0.1,\n        uni = T, # 单因素分析\n        multi = T, # 多因素分析\n        final = F # 逐步法，向后\n        )\nft\n\n表格太长了，只展示部分：\n\n这个结果是可以导出为Word或者Excel格式的：\n\nlibrary(rrtable)\n\ntable2docx(ft)\n\n除此之外，这个包还是一个非常强大的三线表绘制R包，可以1行代码实现多种精美的三线表、回归分析（线性回归、逻辑回归、生存分析）结果表格，大家感兴趣的可以去官网学习：https://cardiomoon.github.io/autoReg/index.html",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>变量选择之先单后多</span>"
    ]
  },
  {
    "objectID": "feature-selection_stepwise.html",
    "href": "feature-selection_stepwise.html",
    "title": "16  变量选择之逐步回归",
    "section": "",
    "text": "16.1 加载数据\n我们使用TCGA-BLCA的lncRNA数据（数据已放在粉丝qq群文件），其中包括408个样本，time_months是生存时间，event是生存状态，1代表死亡，0代表生存，其余变量都是自变量。\nrm(list = ls())\nload(file = \"datasets/lnc_expr_clin.RData\")\n#去掉没有生存信息的样本\nlnc_expr_clin1 &lt;- lnc_expr_clin[!is.na(lnc_expr_clin$time_months),]\nlnc_expr_clin1 &lt;- lnc_expr_clin1[lnc_expr_clin1$time_months&gt;0,]\n\n#选择其中一部分数据\ndat.cox &lt;- lnc_expr_clin1[,c(72:73,1:59)]\ndim(dat.cox)\n## [1] 297  61\ndat.cox[1:4,1:6]\n##   event time_months   PGM5-AS1 LINC01082 AC005180.2 AC005180.1\n## 1     0       36.33 0.15064007 0.2642238  0.0000000  0.1547768\n## 2     0       13.87 0.06309362 0.1666554  0.3105983  0.2436603\n## 3     1       21.83 2.16399508 3.5662920  2.2454129  2.0073496\n## 4     0       18.20 2.73075081 1.7314314  0.8609916  0.7323014\n现在这个数据一共59个自变量，我们先使用所有自变量建立cox回归模型。",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>变量选择之逐步回归</span>"
    ]
  },
  {
    "objectID": "feature-selection_stepwise.html#建立模型",
    "href": "feature-selection_stepwise.html#建立模型",
    "title": "16  变量选择之逐步回归",
    "section": "16.2 建立模型",
    "text": "16.2 建立模型\n我们这个是生存数据，使用cox回归。如果你的数据是其他类型，使用逻辑回归或者线性回归都是可以的。\n\nlibrary(survival)\n\nfit.cox &lt;- coxph(Surv(time_months,event)~.,data = dat.cox)\nfit.cox\n## Call:\n## coxph(formula = Surv(time_months, event) ~ ., data = dat.cox)\n## \n##                     coef exp(coef)  se(coef)      z       p\n## `PGM5-AS1`     -0.008183  0.991850  0.222738 -0.037 0.97069\n## LINC01082       0.345614  1.412858  0.403674  0.856 0.39190\n## AC005180.2      0.977584  2.658027  0.906672  1.078 0.28094\n## AC005180.1      0.846348  2.331118  1.193460  0.709 0.47823\n## FENDRR         -0.653451  0.520247  0.548215 -1.192 0.23328\n## AC053503.3     -0.589548  0.554578  0.553104 -1.066 0.28647\n## MIR100HG        0.902471  2.465687  0.386229  2.337 0.01946\n## AP001107.5     -0.812922  0.443560  0.677700 -1.200 0.23032\n## `C5orf66-AS1`   0.094286  1.098873  0.295767  0.319 0.74989\n## NR4A1AS         0.874631  2.397990  0.336703  2.598 0.00939\n## AL162424.1      0.049223  1.050455  0.324490  0.152 0.87943\n## AF001548.1      0.949594  2.584659  0.788709  1.204 0.22860\n## AC099850.4      0.205430  1.228053  0.252745  0.813 0.41634\n## `MBNL1-AS1`    -0.798659  0.449932  0.675864 -1.182 0.23733\n## `ADAMTS9-AS1`  -0.065160  0.936917  1.776167 -0.037 0.97074\n## MIR22HG         0.108393  1.114486  0.228433  0.475 0.63514\n## MIR200CHG      -0.070914  0.931542  0.215534 -0.329 0.74214\n## AC093010.3     -0.658117  0.517825  0.347044 -1.896 0.05791\n## LINC00865      -0.282616  0.753809  0.284716 -0.993 0.32089\n## AP003071.4     -0.506228  0.602765  0.675734 -0.749 0.45377\n## PCAT6           0.347869  1.416047  0.199663  1.742 0.08146\n## LINC02657      -0.175082  0.839388  0.122482 -1.429 0.15287\n## `PPP1R14B-AS1`  0.144657  1.155643  0.238269  0.607 0.54377\n## AC012085.2     -2.267686  0.103552  1.671128 -1.357 0.17479\n## `ACTA2-AS1`    -0.084816  0.918681  0.760755 -0.111 0.91123\n## AC036108.3      1.405644  4.078154  1.413552  0.994 0.32003\n## AC079313.2      0.167743  1.182633  1.020173  0.164 0.86940\n## AC020916.1      0.037921  1.038649  0.201470  0.188 0.85070\n## SNHG25         -0.151295  0.859594  0.330536 -0.458 0.64715\n## AL049555.1      0.398962  1.490277  0.207738  1.921 0.05479\n## `MIR1-1HG-AS1` -1.851131  0.157059  1.991975 -0.929 0.35274\n## AC018904.1      0.026484  1.026838  0.233038  0.114 0.90952\n## SNHG12          0.144329  1.155264  0.344430  0.419 0.67519\n## `SPINT1-AS1`    0.676775  1.967522  0.374980  1.805 0.07110\n## `KRT7-AS`      -0.137828  0.871248  0.129775 -1.062 0.28821\n## MIR205HG       -0.076826  0.926051  0.161261 -0.476 0.63378\n## `HAND2-AS1`     1.853233  6.380415  1.742430  1.064 0.28751\n## AL445524.1     -0.255737  0.774345  0.220099 -1.162 0.24527\n## LINC01980      -0.171282  0.842584  0.128515 -1.333 0.18260\n## `ZNF710-AS1`   -0.959290  0.383165  0.459985 -2.085 0.03703\n## AC092718.4      0.010577  1.010633  0.272577  0.039 0.96905\n## AC008735.2     -0.002696  0.997308  0.291545 -0.009 0.99262\n## LINC01133       0.122659  1.130499  0.120170  1.021 0.30739\n## AC025575.2      0.158544  1.171804  0.135523  1.170 0.24205\n## `MAFG-DT`       0.343519  1.409901  0.242305  1.418 0.15627\n## CASC9          -0.118071  0.888633  0.154923 -0.762 0.44598\n## AL390719.2      0.177187  1.193854  0.225404  0.786 0.43182\n## AC002398.2     -1.089318  0.336446  1.662224 -0.655 0.51225\n## AC008736.1     -0.117863  0.888818  0.163847 -0.719 0.47193\n## AL161431.1      0.158805  1.172110  0.112004  1.418 0.15623\n## `PCCA-DT`      -0.456381  0.633572  0.254320 -1.795 0.07273\n## AC245041.2      0.243686  1.275944  0.200371  1.216 0.22392\n## U62317.1       -0.162513  0.850005  0.205601 -0.790 0.42928\n## U62317.2       -0.131903  0.876426  0.315579 -0.418 0.67597\n## `VPS9D1-AS1`   -0.044547  0.956431  0.174172 -0.256 0.79813\n## AL023284.4     -0.335339  0.715095  0.245641 -1.365 0.17220\n## AATBC           0.136654  1.146432  0.180919  0.755 0.45005\n## LINC00641       0.383262  1.467062  0.474750  0.807 0.41950\n## AC015912.3     -0.562875  0.569569  0.296322 -1.900 0.05749\n## \n## Likelihood ratio test=78.86  on 59 df, p=0.04311\n## n= 297, number of events= 71\n\n下面就是用逐步法选择变量。",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>变量选择之逐步回归</span>"
    ]
  },
  {
    "objectID": "feature-selection_stepwise.html#逐步选择",
    "href": "feature-selection_stepwise.html#逐步选择",
    "title": "16  变量选择之逐步回归",
    "section": "16.3 逐步选择",
    "text": "16.3 逐步选择\n我们使用逐步选择法进行变量筛选：\n\nfit.step &lt;- step(fit.cox,direction = \"both\")\n#save(fit.step,file = \"./datasets/fit.step.edata\")\n\nStart:  AIC=794.12\nSurv(time_months, event) ~ `PGM5-AS1` + LINC01082 + AC005180.2 + \n    AC005180.1 + FENDRR + AC053503.3 + MIR100HG + AP001107.5 + \n    `C5orf66-AS1` + NR4A1AS + AL162424.1 + AF001548.1 + AC099850.4 + \n    `MBNL1-AS1` + `ADAMTS9-AS1` + MIR22HG + MIR200CHG + AC093010.3 + \n    LINC00865 + AP003071.4 + PCAT6 + LINC02657 + `PPP1R14B-AS1` + \n    AC012085.2 + `ACTA2-AS1` + AC036108.3 + AC079313.2 + AC020916.1 + \n    SNHG25 + AL049555.1 + `MIR1-1HG-AS1` + AC018904.1 + SNHG12 + \n    `SPINT1-AS1` + `KRT7-AS` + MIR205HG + `HAND2-AS1` + AL445524.1 + \n    LINC01980 + `ZNF710-AS1` + AC092718.4 + AC008735.2 + LINC01133 + \n    AC025575.2 + `MAFG-DT` + CASC9 + AL390719.2 + AC002398.2 + \n    AC008736.1 + AL161431.1 + `PCCA-DT` + AC245041.2 + U62317.1 + \n    U62317.2 + `VPS9D1-AS1` + AL023284.4 + AATBC + LINC00641 + \n    AC015912.3\n\n                 Df    AIC\n- AC008735.2      1 792.12\n- `ADAMTS9-AS1`   1 792.12\n- `PGM5-AS1`      1 792.12\n- AC092718.4      1 792.12\n- `ACTA2-AS1`     1 792.13\n- AC018904.1      1 792.13\n- AL162424.1      1 792.14\n- AC079313.2      1 792.15\n- AC020916.1      1 792.15\n- `VPS9D1-AS1`    1 792.18\n- `C5orf66-AS1`   1 792.22\n- MIR200CHG       1 792.23\n- U62317.2        1 792.29\n- SNHG12          1 792.29\n- SNHG25          1 792.33\n- MIR22HG         1 792.34\n- MIR205HG        1 792.35\n- `PPP1R14B-AS1`  1 792.49\n- AC002398.2      1 792.56\n- AC005180.1      1 792.63\n- AC008736.1      1 792.65\n- AATBC           1 792.69\n- AP003071.4      1 792.69\n- CASC9           1 792.70\n- AL390719.2      1 792.74\n- U62317.1        1 792.75\n- LINC00641       1 792.76\n- AC099850.4      1 792.79\n- LINC01082       1 792.86\n- `MIR1-1HG-AS1`  1 793.03\n- AC036108.3      1 793.10\n- LINC00865       1 793.13\n- LINC01133       1 793.13\n- `HAND2-AS1`     1 793.23\n- `KRT7-AS`       1 793.25\n- AC005180.2      1 793.25\n- AC053503.3      1 793.29\n- AL445524.1      1 793.49\n- AC025575.2      1 793.50\n- AF001548.1      1 793.55\n- FENDRR          1 793.61\n- AC245041.2      1 793.61\n- `MBNL1-AS1`     1 793.62\n- AP001107.5      1 793.84\n- LINC01980       1 793.87\n- AL023284.4      1 794.01\n- AL161431.1      1 794.11\n&lt;none&gt;              794.12\n- `MAFG-DT`       1 794.13\n- AC012085.2      1 794.14\n- LINC02657       1 794.20\n- PCAT6           1 795.17\n- `PCCA-DT`       1 795.43\n- `SPINT1-AS1`    1 795.45\n- AC093010.3      1 795.84\n- AL049555.1      1 795.88\n- AC015912.3      1 795.94\n- `ZNF710-AS1`    1 796.86\n- MIR100HG        1 797.13\n- NR4A1AS         1 798.62\n\nStep:  AIC=792.12\n## 省略巨多中间过程\nStep:  AIC=790.12\n## 省略巨多中间过程\nStep:  AIC=734.72\nSurv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n    NR4A1AS + AC093010.3 + PCAT6 + AC036108.3 + AL049555.1 + \n    `MIR1-1HG-AS1` + `SPINT1-AS1` + LINC01980 + `ZNF710-AS1` + \n    AL161431.1 + `PCCA-DT` + U62317.1 + AL023284.4 + AC015912.3\n\n                 Df    AIC\n&lt;none&gt;              734.72\n+ LINC00641       1 734.91\n+ AC012085.2      1 735.01\n- AL049555.1      1 735.02\n+ AC002398.2      1 735.06\n- AC036108.3      1 735.12\n+ `MAFG-DT`       1 735.17\n- `ZNF710-AS1`    1 735.28\n+ AF001548.1      1 735.44\n+ AL445524.1      1 735.44\n- `MIR1-1HG-AS1`  1 735.54\n- U62317.1        1 735.76\n+ `C5orf66-AS1`   1 735.89\n+ `MBNL1-AS1`     1 735.91\n+ MIR205HG        1 735.92\n+ AP003071.4      1 735.99\n- `PCCA-DT`       1 736.08\n+ AATBC           1 736.14\n+ LINC01133       1 736.25\n+ AC099850.4      1 736.27\n- AL161431.1      1 736.29\n+ AC245041.2      1 736.30\n+ AC008735.2      1 736.34\n+ AC025575.2      1 736.36\n+ SNHG12          1 736.36\n+ MIR200CHG       1 736.42\n+ LINC02657       1 736.46\n- AL023284.4      1 736.47\n+ `KRT7-AS`       1 736.49\n+ SNHG25          1 736.50\n+ `PPP1R14B-AS1`  1 736.52\n+ `ADAMTS9-AS1`   1 736.53\n+ U62317.2        1 736.53\n+ FENDRR          1 736.56\n+ `ACTA2-AS1`     1 736.60\n+ AC008736.1      1 736.60\n+ `HAND2-AS1`     1 736.60\n+ `PGM5-AS1`      1 736.61\n+ MIR22HG         1 736.61\n+ AL390719.2      1 736.66\n+ `VPS9D1-AS1`    1 736.67\n+ CASC9           1 736.67\n+ AC053503.3      1 736.67\n+ AC005180.1      1 736.68\n+ AL162424.1      1 736.68\n+ LINC01082       1 736.71\n+ AC079313.2      1 736.71\n+ LINC00865       1 736.71\n+ AC092718.4      1 736.71\n+ AC020916.1      1 736.72\n+ AC018904.1      1 736.72\n- NR4A1AS         1 736.74\n- MIR100HG        1 736.79\n- LINC01980       1 736.86\n- `SPINT1-AS1`    1 736.89\n- AP001107.5      1 737.71\n- PCAT6           1 738.00\n- AC015912.3      1 738.51\n- AC093010.3      1 739.96\n- AC005180.2      1 739.97\n\n查看下结果：\n\nsummary(fit.step)\n\nCall:\ncoxph(formula = Surv(time_months, event) ~ AC005180.2 + MIR100HG + \n    AP001107.5 + NR4A1AS + AC093010.3 + PCAT6 + AC036108.3 + \n    AL049555.1 + `MIR1-1HG-AS1` + `SPINT1-AS1` + LINC01980 + \n    `ZNF710-AS1` + AL161431.1 + `PCCA-DT` + U62317.1 + AL023284.4 + \n    AC015912.3, data = dat.cox)\n\n  n= 297, number of events= 71 \n\n                   coef exp(coef) se(coef)      z Pr(&gt;|z|)   \nAC005180.2      0.83728   2.31007  0.30399  2.754  0.00588 **\nMIR100HG        0.59783   1.81818  0.28762  2.079  0.03766 * \nAP001107.5     -1.63414   0.19512  0.80039 -2.042  0.04118 * \nNR4A1AS         0.48095   1.61761  0.22753  2.114  0.03453 * \nAC093010.3     -0.65126   0.52139  0.24377 -2.672  0.00755 **\nPCAT6           0.34371   1.41017  0.14756  2.329  0.01985 * \nAC036108.3      1.48666   4.42231  0.96894  1.534  0.12495   \nAL049555.1      0.23994   1.27117  0.15931  1.506  0.13203   \n`MIR1-1HG-AS1` -1.95396   0.14171  1.21419 -1.609  0.10756   \n`SPINT1-AS1`    0.48314   1.62116  0.23919  2.020  0.04340 * \nLINC01980      -0.17331   0.84087  0.08564 -2.024  0.04300 * \n`ZNF710-AS1`   -0.55489   0.57414  0.35644 -1.557  0.11953   \nAL161431.1      0.17192   1.18758  0.08854  1.942  0.05217 . \n`PCCA-DT`      -0.35372   0.70207  0.19499 -1.814  0.06966 . \nU62317.1       -0.20670   0.81326  0.12168 -1.699  0.08937 . \nAL023284.4     -0.30170   0.73956  0.15674 -1.925  0.05425 . \nAC015912.3     -0.43266   0.64878  0.18428 -2.348  0.01888 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\nAC005180.2        2.3101     0.4329   1.27311    4.1916\nMIR100HG          1.8182     0.5500   1.03470    3.1949\nAP001107.5        0.1951     5.1251   0.04065    0.9367\nNR4A1AS           1.6176     0.6182   1.03563    2.5266\nAC093010.3        0.5214     1.9180   0.32334    0.8407\nPCAT6             1.4102     0.7091   1.05601    1.8831\nAC036108.3        4.4223     0.2261   0.66204   29.5404\nAL049555.1        1.2712     0.7867   0.93025    1.7370\n`MIR1-1HG-AS1`    0.1417     7.0566   0.01312    1.5308\n`SPINT1-AS1`      1.6212     0.6168   1.01443    2.5908\nLINC01980         0.8409     1.1892   0.71094    0.9946\n`ZNF710-AS1`      0.5741     1.7417   0.28551    1.1546\nAL161431.1        1.1876     0.8420   0.99839    1.4126\n`PCCA-DT`         0.7021     1.4244   0.47908    1.0288\nU62317.1          0.8133     1.2296   0.64070    1.0323\nAL023284.4        0.7396     1.3522   0.54395    1.0055\nAC015912.3        0.6488     1.5413   0.45211    0.9310\n\nConcordance= 0.735  (se = 0.029 )\nLikelihood ratio test= 54.26  on 17 df,   p=9e-06\nWald test            = 47.59  on 17 df,   p=1e-04\nScore (logrank) test = 51.16  on 17 df,   p=3e-05\n\n最终59个变量剩下17个，筛选效果还不错。\n这个筛选过程是根据AIC进行的，一般会选择AIC最小的结果。AIC全称赤池信息量准则(Akaike information criterion，AIC)，是评估统计模型的复杂度和衡量统计模型”拟合优度”（Goodness of Fit）的一种标准，是由日本统计学家赤池弘次创立和发展的。赤池信息量准则的方法是寻找可以最好地解释数据但包含最少自由参数的模型。\n查看最终的AIC和BIC：\n\n# 初始模型的AIC\nAIC(fit.cox)\n## [1] 794.1182\n\n# 筛选后的AIC和BIC\nAIC(fit.step)\n## [1] 734.7167\nBIC(fit.step)\n## [1] 773.1823\n\n查看回归系数：\n\nstep.coef &lt;- coef(fit.step)\nstep.coef\n##     AC005180.2       MIR100HG     AP001107.5        NR4A1AS     AC093010.3 \n##      0.8372759      0.5978335     -1.6341403      0.4809485     -0.6512620 \n##          PCAT6     AC036108.3     AL049555.1 `MIR1-1HG-AS1`   `SPINT1-AS1` \n##      0.3437133      1.4866631      0.2399385     -1.9539623      0.4831391 \n##      LINC01980   `ZNF710-AS1`     AL161431.1      `PCCA-DT`       U62317.1 \n##     -0.1733137     -0.5548853      0.1719177     -0.3537250     -0.2067033 \n##     AL023284.4     AC015912.3 \n##     -0.3017031     -0.4326573\n\n提取这17个变量的名字：\n\nstep.lnc &lt;- names(coef(fit.step))\nstep.lnc\n##  [1] \"AC005180.2\"     \"MIR100HG\"       \"AP001107.5\"     \"NR4A1AS\"       \n##  [5] \"AC093010.3\"     \"PCAT6\"          \"AC036108.3\"     \"AL049555.1\"    \n##  [9] \"`MIR1-1HG-AS1`\" \"`SPINT1-AS1`\"   \"LINC01980\"      \"`ZNF710-AS1`\"  \n## [13] \"AL161431.1\"     \"`PCCA-DT`\"      \"U62317.1\"       \"AL023284.4\"    \n## [17] \"AC015912.3\"\n\n简单。\n当然使用broom也是可以提取这个结果的：\n\nbroom::tidy(fit.step)\n## # A tibble: 17 × 5\n##    term           estimate std.error statistic p.value\n##    &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n##  1 AC005180.2        0.837    0.304       2.75 0.00588\n##  2 MIR100HG          0.598    0.288       2.08 0.0377 \n##  3 AP001107.5       -1.63     0.800      -2.04 0.0412 \n##  4 NR4A1AS           0.481    0.228       2.11 0.0345 \n##  5 AC093010.3       -0.651    0.244      -2.67 0.00755\n##  6 PCAT6             0.344    0.148       2.33 0.0198 \n##  7 AC036108.3        1.49     0.969       1.53 0.125  \n##  8 AL049555.1        0.240    0.159       1.51 0.132  \n##  9 `MIR1-1HG-AS1`   -1.95     1.21       -1.61 0.108  \n## 10 `SPINT1-AS1`      0.483    0.239       2.02 0.0434 \n## 11 LINC01980        -0.173    0.0856     -2.02 0.0430 \n## 12 `ZNF710-AS1`     -0.555    0.356      -1.56 0.120  \n## 13 AL161431.1        0.172    0.0885      1.94 0.0522 \n## 14 `PCCA-DT`        -0.354    0.195      -1.81 0.0697 \n## 15 U62317.1         -0.207    0.122      -1.70 0.0894 \n## 16 AL023284.4       -0.302    0.157      -1.92 0.0542 \n## 17 AC015912.3       -0.433    0.184      -2.35 0.0189\n\n一目了然，简洁清晰，broom真的是神包~\n还可以1行代码查看模型的各种统计值，包括P值、R2、AIC、BIC、C-index等等：\n\nbroom::glance(fit.step)\n## # A tibble: 1 × 18\n##       n nevent statistic.log p.value.log statistic.sc p.value.sc statistic.wald\n##   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;\n## 1   297     71          54.3  0.00000900         51.2  0.0000279           47.6\n## # ℹ 11 more variables: p.value.wald &lt;dbl&gt;, statistic.robust &lt;dbl&gt;,\n## #   p.value.robust &lt;dbl&gt;, r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;,\n## #   concordance &lt;dbl&gt;, std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;,\n## #   BIC &lt;dbl&gt;, nobs &lt;int&gt;",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>变量选择之逐步回归</span>"
    ]
  },
  {
    "objectID": "feature-selection_stepwise.html#自助法stepwise",
    "href": "feature-selection_stepwise.html#自助法stepwise",
    "title": "16  变量选择之逐步回归",
    "section": "16.4 自助法stepwise",
    "text": "16.4 自助法stepwise\n这里再给大家介绍下一种自助法stepwise，可以通过自助法重抽样进行逐步筛选变量，比如进行1000次bootstrap。\n该方法借助bootStepAIC实现，是基于stepAIC()函数的，支持”lm”, “aov”,“glm”, “negbin”, “polr”, “survreg”,以及”coxph”。\n使用方法也很简单，下面是一个10次bootstrap的逐步选择法(因为耗时太长了，我只用了10次) ：\n\nlibrary(bootStepAIC)\n\n# 10次bootstrap\nfit.boot &lt;- boot.stepAIC(fit.cox,data=dat.cox,direction=\"both\",B=10,seed=123)\n#fit.boot\n\n\nFinal Model:\nSurv(time_months, event) ~ AC005180.2 + MIR100HG + AP001107.5 + \n    NR4A1AS + AC093010.3 + PCAT6 + AC036108.3 + AL049555.1 + \n    `MIR1-1HG-AS1` + `SPINT1-AS1` + LINC01980 + `ZNF710-AS1` + \n    AL161431.1 + `PCCA-DT` + U62317.1 + AL023284.4 + AC015912.3\n\n提取变量名字：\n\nnames(coef(fit.boot$OrigStepAIC))\n\n [1] \"AC005180.2\"     \"MIR100HG\"       \"AP001107.5\"     \"NR4A1AS\"       \n [5] \"AC093010.3\"     \"PCAT6\"          \"AC036108.3\"     \"AL049555.1\"    \n [9] \"`MIR1-1HG-AS1`\" \"`SPINT1-AS1`\"   \"LINC01980\"      \"`ZNF710-AS1`\"  \n[13] \"AL161431.1\"     \"`PCCA-DT`\"      \"U62317.1\"       \"AL023284.4\"    \n[17] \"AC015912.3\"  \n\n和不进行bootstrap的方法得到的结果是一样的：\n\nidentical(sort(step.lnc),sort(names(coef(fit.boot$OrigStepAIC))))\n\n[1] TRUE",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>变量选择之逐步回归</span>"
    ]
  },
  {
    "objectID": "feature-selection_bestsubset.html",
    "href": "feature-selection_bestsubset.html",
    "title": "17  变量选择之最优子集",
    "section": "",
    "text": "17.1 准备数据\n使用孙振球版医学统计学例15-1的数据。使用多个变量预测患者的空腹血糖。\ndf &lt;- data.frame(\n  cho = c(5.68,3.79,6.02,4.85,4.60,6.05,4.90,7.08,3.85,4.65,4.59,4.29,7.97,\n      6.19,6.13,5.71,6.40,6.06,5.09,6.13,5.78,5.43,6.50,7.98,11.54,5.84,\n      3.84),\n  tg = c(1.90,1.64,3.56,1.07,2.32,0.64,8.50,3.00,2.11,0.63,1.97,1.97,1.93,\n      1.18,2.06,1.78,2.40,3.67,1.03,1.71,3.36,1.13,6.21,7.92,10.89,0.92,\n      1.20),\n  ri = c(4.53, 7.32,6.95,5.88,4.05,1.42,12.60,6.75,16.28,6.59,3.61,6.61,7.57,\n      1.42,10.35,8.53,4.53,12.79,2.53,5.28,2.96,4.31,3.47,3.37,1.20,8.61,\n      6.45),\n  hba = c(8.2,6.9,10.8,8.3,7.5,13.6,8.5,11.5,7.9,7.1,8.7,7.8,9.9,6.9,10.5,8.0,\n      10.3,7.1,8.9,9.9,8.0,11.3,12.3,9.8,10.5,6.4,9.6),\n  fpg = c(11.2,8.8,12.3,11.6,13.4,18.3,11.1,12.1,9.6,8.4,9.3,10.6,8.4,9.6,10.9,\n     10.1,14.8,9.1,10.8,10.2,13.6,14.9,16.0,13.2,20.0,13.3,10.4)\n  )",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>变量选择之最优子集</span>"
    ]
  },
  {
    "objectID": "feature-selection_bestsubset.html#建立模型",
    "href": "feature-selection_bestsubset.html#建立模型",
    "title": "17  变量选择之最优子集",
    "section": "17.2 建立模型",
    "text": "17.2 建立模型\n使用全部的4个变量建立回归方程：\n\nf &lt;- lm(fpg ~ cho + tg + ri + hba, data = df)\n\nsummary(f)\n## \n## Call:\n## lm(formula = fpg ~ cho + tg + ri + hba, data = df)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -3.6268 -1.2004 -0.2276  1.5389  4.4467 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)  \n## (Intercept)   5.9433     2.8286   2.101   0.0473 *\n## cho           0.1424     0.3657   0.390   0.7006  \n## tg            0.3515     0.2042   1.721   0.0993 .\n## ri           -0.2706     0.1214  -2.229   0.0363 *\n## hba           0.6382     0.2433   2.623   0.0155 *\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.01 on 22 degrees of freedom\n## Multiple R-squared:  0.6008, Adjusted R-squared:  0.5282 \n## F-statistic: 8.278 on 4 and 22 DF,  p-value: 0.0003121",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>变量选择之最优子集</span>"
    ]
  },
  {
    "objectID": "feature-selection_bestsubset.html#最优子集法",
    "href": "feature-selection_bestsubset.html#最优子集法",
    "title": "17  变量选择之最优子集",
    "section": "17.3 最优子集法",
    "text": "17.3 最优子集法\n使用最优子集法筛选变量，借助leaps包实现。使用起来其实就是1行代码而已：\n\nlibrary(leaps)\nleaps &lt;- regsubsets(fpg ~ cho + tg + ri + hba, data = df)\nsummary(leaps)\n## Subset selection object\n## Call: regsubsets.formula(fpg ~ cho + tg + ri + hba, data = df)\n## 4 Variables  (and intercept)\n##     Forced in Forced out\n## cho     FALSE      FALSE\n## tg      FALSE      FALSE\n## ri      FALSE      FALSE\n## hba     FALSE      FALSE\n## 1 subsets of each size up to 4\n## Selection Algorithm: exhaustive\n##          cho tg  ri  hba\n## 1  ( 1 ) \" \" \" \" \" \" \"*\"\n## 2  ( 1 ) \"*\" \" \" \" \" \"*\"\n## 3  ( 1 ) \" \" \"*\" \"*\" \"*\"\n## 4  ( 1 ) \"*\" \"*\" \"*\" \"*\"\n\n*表示变量被包含在模型中，这个结果看起来并不是很直观，下面会结合图进行解释。",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>变量选择之最优子集</span>"
    ]
  },
  {
    "objectID": "feature-selection_bestsubset.html#子集选择",
    "href": "feature-selection_bestsubset.html#子集选择",
    "title": "17  变量选择之最优子集",
    "section": "17.4 子集选择",
    "text": "17.4 子集选择\n我们首先查看rss(Residual sum of squares，残差平方和)最小的结果，因为RSS越小说明模型拟合结果越好：\n\nwhich.min(summary(leaps)$rss)\n## [1] 4\n\n结果表明有4个特征的模型具有最小的RSS，这是很明显的哈，因为这个数据最多就有4个自变量。。。\n增加特征数量必然会减少RSS！而且必然会增加R方。我们即使添加一个完全不相关的特征，比如洛杉矶湖人队的胜场数，模型的RSS也会减少，R方也会增加。\n所以只看RSS并不能帮助我们很好的选择变量。\n我们这里讨论4种用于特征选择的统计方法：\n\n赤池信息量准则\n马洛斯的Cp\n贝叶斯准则\n调整的R方\n\n赤池信息量准则(Akaike information criterion，AIC)，是评估统计模型的复杂度和衡量统计模型”拟合优度”（Goodness of Fit）的一种标准，是由日本统计学家赤池弘次创立和发展的。赤池信息量准则的方法是寻找可以最好地解释数据但包含最少自由参数的模型。\nAIC的计算方法如下，其中p是模型中的特征数量(也就是自变量数量)，n是样本大小：\n\\[\n\\mathrm{AIC}=n*\\log\\Bigg(\\frac{\\mathrm{RSS}_p}{n}\\Bigg)+2*p\n\\]\n贝叶斯信息量准则(Bayesian information criterion，BIC)和AIC类似，只不过BIC比AIC的惩罚力度更大。\nBIC的计算方法如下，BIC的前半部分计算和AIC是完全一样的：\n\\[\n\\mathrm{BIC}=n*\\log\\left(\\frac{\\mathrm{RSS}_p}n\\right)+p*\\log(n)\n\\]\nAIC和BIC的不同点：\n\nBIC的惩罚项比AIC大，考虑了样本个数，样本数量多，可以防止模型精度过高造成的模型复杂度过高。 AIC和BIC前半部分是一样的，BIC考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高。–参考资料2\n\n马洛斯的Cp(Mallows’Cp)与AIC的计算也是类似，其计算公式如下，其中MSE(mean-square error, MSE)是均方误差：\n\\[\n\\mathrm{CP}=\\frac{\\mathrm{RSS}_{p}}{\\mathrm{MSE}_{f}}-n+2*p\n\\]\n调整的R2(修正R方)的计算公式如下：\n\\[\n\\text{修正R方}=1-\\left(\\frac{\\mathrm{RSS}}{n-p-1}\\right)/\\left(\\frac{\\mathrm{R}\\text{方}}{ n - 1 }\\right)\n\\]\n前三种方法的目标是追求统计量的值最小化，调整的R方的目标是追求统计量的值最大化。这些统计方法的目的是建立一个尽可能简约的模型，换句话说，要对模型复杂性进行”惩罚”。\n在线性模型中，AIC和Cp成正比，所以我们只需关注Cp即可。\n下面以CP为纵坐标进行可视化：\n\npar(mfrow=c(1,2))\nplot(summary(leaps)$cp,type = \"l\",xlab = \"number of features\",ylab = \"cp\")\nplot(leaps, scale = \"Cp\") # 通过Cp判断\n\n\n\n\n\n\n\n\n左图横坐标是自变量数量，纵坐标是CP值大小，可以看到在变量数量为3时，CP是最小的；右边的图也是一样的意思，先看纵坐标，CP最小是3.2，此时对应的黑色块是tg,ri,hba这3个变量。\n也可以用其他指标作为纵坐标进行可视化，比如调整的R方adjr2:\n\nplot(leaps, scale = \"adjr2\")\n\n\n\n\n\n\n\n\n或者BIC，BIC和AIC意思是一样的：\n\nplot(leaps, scale = \"bic\")\n\n\n\n\n\n\n\n\n可以看到3种方法得到的结果都是一样的，都是选出了tg,ri,hba这3个变量，但有时结果也是不太一样的，不用纠结。\n上面是比较传统的方法，但是说实话得到的图不是很好看，如果没有教程完全不知道如何解读，非常的不优雅。\n神包broom可以用于这个筛选结果，结果会返回一个tibble，看起来非常清稀易懂：\n\nbroom::tidy(leaps)\n## # A tibble: 4 × 9\n##   `(Intercept)` cho   tg    ri    hba   r.squared adj.r.squared    BIC\n##   &lt;lgl&gt;         &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;     &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n## 1 TRUE          FALSE FALSE FALSE TRUE      0.372         0.347  -5.95\n## 2 TRUE          TRUE  FALSE FALSE TRUE      0.484         0.441  -7.99\n## 3 TRUE          FALSE TRUE  TRUE  TRUE      0.598         0.546 -11.4 \n## 4 TRUE          TRUE  TRUE  TRUE  TRUE      0.601         0.528  -8.32\n## # ℹ 1 more variable: mallows_cp &lt;dbl&gt;\n\n可以看到如果是根据R方来选择，则R方最大时4个变量都在，如果是根据BIC最小选择，那结果是tg,ri,hba这3个变量入选。这样我们不用画图也可以很直观的看出在不同指标下应该选择哪几个变量。\n如果还想更加炫酷一点，可以把这个结果变成一个图表（参考文章）：\n\nlibrary(gt)\nlibrary(tidyverse)\nlibrary(scales)\n\nbroom::tidy(leaps) %&gt;%\n  select(-`(Intercept)`) %&gt;%\n  rownames_to_column(var = \"n_vars\") %&gt;%\n  gt(rowname_col = \"n_vars\") %&gt;%\n  gt::data_color(\n    columns = cho:hba,\n    fn = col_numeric(\n      palette = c(\"#fdae61\", \"#abdda4\"),\n      domain = c(0, 1)) \n  ) %&gt;%\n  gt::fmt_number(r.squared:mallows_cp, n_sigfig = 4)\n\n\n\n\n\n\n\n\ncho\ntg\nri\nhba\nr.squared\nadj.r.squared\nBIC\nmallows_cp\n\n\n\n\n1\nFALSE\nFALSE\nFALSE\nTRUE\n0.3717\n0.3465\n−5.955\n11.63\n\n\n2\nTRUE\nFALSE\nFALSE\nTRUE\n0.4843\n0.4414\n−7.995\n7.419\n\n\n3\nFALSE\nTRUE\nTRUE\nTRUE\n0.5981\n0.5456\n−11.43\n3.152\n\n\n4\nTRUE\nTRUE\nTRUE\nTRUE\n0.6008\n0.5282\n−8.315\n5.000\n\n\n\n\n\n\n\n这样一来更加直观了，这里我用绿色表示留下的变量，黄色表示被剔除的变量，后面几列是对应的各种指标。\n做到这一步的时候，我真的觉得R语言太牛逼了，大神的可视化思路太强了，我差的太远了。\n如果只是想要看一下不同指标下保留的变量个数，我们可以根据上面的结果用ggplot2画图。\n\nbroom::tidy(leaps) %&gt;%\n  select(r.squared:mallows_cp) %&gt;%\n  mutate(n_vars = 1:n()) %&gt;%\n  pivot_longer(cols = -n_vars, names_to = \"metric\") %&gt;%\n  ggplot(aes(x = n_vars, y = value)) +\n  geom_point(size = 2) +\n  geom_line(linewidth = 1) +\n  geom_vline(\n    data = . %&gt;%\n      group_by(metric) %&gt;%\n      filter(value == ifelse(str_detect(metric, \"r.squared\"),\n                             max(value), min(value))),\n    aes(xintercept = n_vars), lty = 2) +\n  theme_bw()+\n  facet_wrap(~ metric, scales = \"free_y\")\n\n\n\n\n\n\n\n\n强大！牛B！专业！",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>变量选择之最优子集</span>"
    ]
  },
  {
    "objectID": "feature-selection_bestsubset.html#参考资料",
    "href": "feature-selection_bestsubset.html#参考资料",
    "title": "17  变量选择之最优子集",
    "section": "17.5 参考资料",
    "text": "17.5 参考资料\n\n维基百科：AIC\nhttps://zhuanlan.zhihu.com/p/293315874\nhttps://bookdown.org/taylordunn/islr-tidy-1655226885741/",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>变量选择之最优子集</span>"
    ]
  },
  {
    "objectID": "feature-selection_lasso.html",
    "href": "feature-selection_lasso.html",
    "title": "18  lasso回归筛选变量",
    "section": "",
    "text": "18.1 正则化逻辑回归\n用一个二分类数据进行演示，因为大家最常用的就是二分类数据和生存数据了。\ndata(BinomialExample)\nx &lt;- BinomialExample$x\ny &lt;- BinomialExample$y\n\ndim(x)\n## [1] 100  30\nclass(x)\n## [1] \"matrix\" \"array\"\nx[1:4,1:4]\n##            [,1]       [,2]       [,3]       [,4]\n## [1,] -0.6192614 0.01624409 -0.6260683  0.4126846\n## [2,]  1.0942728 0.47257285 -1.3371470 -0.6405813\n## [3,] -0.3567040 0.30121334  0.1905619  0.2340268\n## [4,] -2.4690701 2.84771447  1.6602435  1.5688130\n\nclass(y)\n## [1] \"integer\"\nhead(y)\n## [1] 0 1 1 0 1 0\n注意glmnet需要的自变量格式，需要是matrix或者稀疏矩阵格式！\nfamily用来指定不同的模型类型，对于二分类数据，应该选择binomial。\nfamily的其他选项如下：“gaussian”（默认）, “poisson”, “multinomial”, “cox”, “mgaussian”。\n建立正则化的逻辑回归模型（就是大家说的lasso-logistic模型）就是1句代码，非常简单：\nfit &lt;- glmnet(x, y, family = \"binomial\")\n官方不建议直接提取fit中的元素，因为提供了plot，print，coef，predict方法帮助大家探索结果。",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>lasso回归筛选变量</span>"
    ]
  },
  {
    "objectID": "feature-selection_lasso.html#正则化逻辑回归",
    "href": "feature-selection_lasso.html#正则化逻辑回归",
    "title": "18  lasso回归筛选变量",
    "section": "",
    "text": "18.1.1 可视化\n可视化各个变量系数的变化，这个图是大家最常见的图形之一：\n\nplot(fit,label = T)\n\n\n\n\n\n\n\n\n这个图形中的每一条线都代表1个变量，并且展示了在不同的L1范数（L1-Norm）下该变量的系数变化。这个图下面的横坐标是L1范数，上面的横坐标是L1范数下对应的非零系数的个数，比如当L1范数是20时，对应的非零系数有27个，也就是此时可以有27个变量保留下来。左侧纵坐标是变量的系数值。\n这里的plot()函数还有一个xvar参数，可以用于指定不同的横坐标：\n\nnorm：横坐标是L1 norm，这个是默认值；\nlambda：横坐标是log-lambda；\ndev：横坐标是模型解释的%deviance\n\n\nplot(fit, xvar = \"lambda\")\n\n\n\n\n\n\n\n\n这里的横坐标是log-lambda，可以看做是正则化程度。\n上面这幅图展示了随着lambda值的变化，每个变量系数的变化，可以看到随着lambda值变大，系数值逐渐减小，直至为0，上面的横坐标也显示随着lambda值变大，保留的变量数量也越来越少。\n\nplot(fit, xvar = \"dev\", label = TRUE)\n\n\n\n\n\n\n\n\n这幅图和上面图的解释是一样的，只有下面的横坐标不一样。\n最后一幅图下面的横坐标是模型解释的偏差百分比，也可以用来衡量模型复杂度。可以看出在图形的右侧部分，模型能够解释的偏差百分比基本变化不大，但是模型系数基本都是往上或往下“飘”的很厉害。\n虽然官方不建议提取数据，但是很明显大家都喜欢提取数据再自己美化图片，我之前也介绍过一种简便方法，可以实现自定义美化图形：lasso回归结果美化\n\n\n18.1.2 打印结果\n使用print(fit)可以查看不同lambda值对应的自由度和模型能够解释的偏差百分比：\n\nprint(fit) # 直接fit也可\n## \n## Call:  glmnet(x = x, y = y, family = \"binomial\") \n## \n##    Df  %Dev   Lambda\n## 1   0  0.00 0.240500\n## 2   1  2.90 0.219100\n## 3   1  5.34 0.199600\n## 4   2  8.86 0.181900\n## 5   2 11.95 0.165800\n## 6   2 14.59 0.151000\n## 7   2 16.88 0.137600\n## 8   3 18.95 0.125400\n## 9   7 22.38 0.114200\n## 10  8 26.26 0.104100\n## 11  8 29.73 0.094850\n## 12  8 32.77 0.086420\n## 13  9 35.58 0.078750\n## 14 11 38.98 0.071750\n## 15 12 42.23 0.065380\n## 16 12 45.29 0.059570\n## 17 13 48.09 0.054280\n## 18 13 50.63 0.049450\n## 19 14 53.00 0.045060\n## 20 14 55.19 0.041060\n## 21 15 57.33 0.037410\n## 22 15 59.43 0.034090\n## 23 16 61.36 0.031060\n## 24 17 63.15 0.028300\n## 25 17 64.85 0.025790\n## 26 18 66.42 0.023490\n## 27 19 67.98 0.021410\n## 28 20 69.44 0.019510\n## 29 20 70.80 0.017770\n## 30 21 72.10 0.016190\n## 31 21 73.33 0.014760\n## 32 23 74.52 0.013440\n## 33 23 75.65 0.012250\n## 34 24 76.72 0.011160\n## 35 24 77.77 0.010170\n## 36 25 78.77 0.009267\n## 37 25 79.73 0.008444\n## 38 26 80.66 0.007693\n## 39 26 81.57 0.007010\n## 40 27 82.48 0.006387\n## 41 27 83.39 0.005820\n## 42 27 84.30 0.005303\n## 43 27 85.21 0.004832\n## 44 27 86.12 0.004402\n## 45 27 87.05 0.004011\n## 46 28 87.96 0.003655\n## 47 28 88.87 0.003330\n## 48 28 89.76 0.003034\n## 49 28 90.61 0.002765\n## 50 28 91.41 0.002519\n## 51 28 92.16 0.002295\n## 52 28 92.86 0.002092\n## 53 28 93.50 0.001906\n## 54 28 94.08 0.001736\n## 55 29 94.61 0.001582\n## 56 29 95.10 0.001442\n## 57 29 95.54 0.001314\n## 58 29 95.95 0.001197\n## 59 29 96.31 0.001091\n## 60 29 96.64 0.000994\n## 61 29 96.94 0.000905\n## 62 29 97.22 0.000825\n## 63 29 97.47 0.000752\n## 64 29 97.69 0.000685\n## 65 29 97.90 0.000624\n## 66 29 98.09 0.000569\n## 67 29 98.26 0.000518\n## 68 29 98.41 0.000472\n## 69 29 98.55 0.000430\n## 70 29 98.68 0.000392\n## 71 29 98.80 0.000357\n## 72 30 98.91 0.000325\n## 73 30 99.00 0.000296\n## 74 30 99.09 0.000270\n## 75 30 99.17 0.000246\n## 76 30 99.25 0.000224\n## 77 30 99.31 0.000204\n## 78 30 99.37 0.000186\n## 79 30 99.43 0.000170\n## 80 30 99.48 0.000155\n## 81 30 99.52 0.000141\n## 82 30 99.57 0.000128\n## 83 30 99.61 0.000117\n## 84 30 99.64 0.000106\n## 85 30 99.67 0.000097\n## 86 30 99.70 0.000088\n## 87 30 99.73 0.000081\n## 88 30 99.75 0.000073\n## 89 30 99.77 0.000067\n## 90 30 99.79 0.000061\n## 91 30 99.81 0.000056\n## 92 30 99.83 0.000051\n## 93 30 99.84 0.000046\n## 94 30 99.86 0.000042\n## 95 30 99.87 0.000038\n## 96 30 99.88 0.000035\n## 97 30 99.89 0.000032\n## 98 30 99.90 0.000029\n\n左侧的df是非零系数的个数，中间的%Dev是模型解释的偏差百分比，右侧的Lambda是总惩罚值大小。\n默认情况下，glmnet()函数中的nlambda参数的取值是100，也就是会取100个不同的Lambda值，但是如果%Dev变化不大或者不再变化，它可能会提前停止，取不到100个值，比如我们这个例子就是这样。\n\n\n18.1.3 查看变量系数\n我们可以通过coef()查看某个Lambda值下的变量系数：\n\n# 比如让lambda=0.065380\ncoef(fit, s = 0.065380)\n## 31 x 1 sparse Matrix of class \"dgCMatrix\"\n##                       s1\n## (Intercept)  0.210158382\n## V1           .          \n## V2           0.193006823\n## V3          -0.069820214\n## V4          -0.606741531\n## V5          -0.081962193\n## V6          -0.285761723\n## V7           .          \n## V8          -0.165879158\n## V9           0.092678665\n## V10         -0.595865115\n## V11          .          \n## V12          .          \n## V13          .          \n## V14          .          \n## V15          .          \n## V16          .          \n## V17          .          \n## V18          .          \n## V19          .          \n## V20          .          \n## V21          .          \n## V22          0.054956208\n## V23          0.001474751\n## V24          .          \n## V25          0.187112112\n## V26         -0.113782733\n## V27          .          \n## V28          .          \n## V29          .          \n## V30          .\n\n可以看到此时一共有12个变量的系数不是0（没包括截距），其余系数是0的变量就可以去掉了，和上面print(fit)的结果是一样的。\n这里使用了s表示lambda，为什么不直接用lambda呢？这是作者为了以后的某些功能做准备，但是这一点在tidymodels中大受诟病…\n也可以同时指定多个lambda值：\n\ncoef(fit, s = c(0.065380,0.078750))\n## 31 x 2 sparse Matrix of class \"dgCMatrix\"\n##                       s1          s2\n## (Intercept)  0.210158382  0.22467551\n## V1           .            .         \n## V2           0.193006823  0.13578915\n## V3          -0.069820214  .         \n## V4          -0.606741531 -0.55088786\n## V5          -0.081962193 -0.08588769\n## V6          -0.285761723 -0.18303729\n## V7           .            .         \n## V8          -0.165879158 -0.12710236\n## V9           0.092678665  .         \n## V10         -0.595865115 -0.50054790\n## V11          .            .         \n## V12          .            .         \n## V13          .            .         \n## V14          .            .         \n## V15          .            .         \n## V16          .            .         \n## V17          .            .         \n## V18          .            .         \n## V19          .            .         \n## V20          .            .         \n## V21          .            .         \n## V22          0.054956208  0.01466017\n## V23          0.001474751  .         \n## V24          .            .         \n## V25          0.187112112  0.13534486\n## V26         -0.113782733 -0.08255906\n## V27          .            .         \n## V28          .            .         \n## V29          .            .         \n## V30          .            .\n\n除此之外，coef()还有一个exact参数，如果exact=TRUE，那么当一个lambda不在默认的lambda值中时，函数会重新使用这个lambda值拟合模型然后给出结果，如果exact=FALSE（默认值），那么会使用线性插值给出结果。\n举个例子，0.08并不在lambda值向量中：\n\n# 可以看前面的print(fit)的结果，看看lambda的取值有哪些\nany(fit$lambda == 0.08)\n## [1] FALSE\n\n此时两种情况下的系数是不太一样的：\n\ncoef.apprx &lt;- coef(fit, s = 0.08, exact = FALSE)\ncoef.exact &lt;- coef(fit, s = 0.08, exact = TRUE, x=x, y=y)\ncbind2(coef.exact[which(coef.exact != 0)], \n       coef.apprx[which(coef.apprx != 0)])\n##              [,1]        [,2]\n##  [1,]  0.22549572  0.22541853\n##  [2,]  0.13138628  0.13159475\n##  [3,] -0.54737500 -0.54723674\n##  [4,] -0.08464614 -0.08430109\n##  [5,] -0.17544453 -0.17586695\n##  [6,] -0.12334038 -0.12323991\n##  [7,] -0.49261301 -0.49314684\n##  [8,]  0.01036968  0.01227180\n##  [9,]  0.13183895  0.13169100\n## [10,] -0.07909589 -0.07914430\n\n注意在使用exact = TRUE时，需要提供x和y，因为需要重新拟合模型。\n\n\n18.1.4 预测新数据\n对于新数据，可直接使用predict()进行预测，此时也是可以指定lambda值的：\n\nnx &lt;- head(x) #随便准备的新的测试数据\n\npredict(fit, newx = nx, s = c(0.065380,0.078750))\n##              s1         s2\n## [1,] -0.7609757 -0.5755105\n## [2,]  1.4563904  1.1266031\n## [3,]  0.4415409  0.3981256\n## [4,] -1.1676684 -0.9923334\n## [5,]  0.5730604  0.5612494\n## [6,]  0.3064590  0.1926588\n\n由于glmnet包可以用于线性回归、逻辑回归、cox回归、泊松回归、多项式回归等（通过参数family指定即可，默认值是gaussian，可通过?glmnet查看帮助文档），所以在predict()时，type参数略有不同，对于逻辑回归，type可以是以下3种：\n\nlink：线性预测值，默认是这个\nresponse：预测概率\nclass：预测类别\n\n如果要获得预测概率：\n\npredict(fit, newx = nx, s = c(0.065380,0.078750), type = \"response\")\n##             s1        s2\n## [1,] 0.3184345 0.3599663\n## [2,] 0.8109800 0.7552115\n## [3,] 0.6086261 0.5982372\n## [4,] 0.2372767 0.2704514\n## [5,] 0.6394690 0.6367416\n## [6,] 0.5760207 0.5480163\n\n可以通过?predict.glmnet查看帮助文档。\n\n\n18.1.5 交叉验证\nglmnet()函数会返回多个模型（因为会使用多个lambda值），但是很多情况下，用户并不知道到底选择哪一个lambda值，即不知道到底保留哪些变量，或者希望函数能自动给出结果。\n所以glmnet包提供了交叉验证法，帮助用户做出选择，使用方法也非常简单：\n\ncvfit &lt;- cv.glmnet(x, y)\n\n除了glmnet()中的参数之外，cv.glmnet()还有一些独有的参数：\n\nnfolds：交叉验证的折数，默认是10折交叉验证；\nfoldid：指定哪个观测在哪一折中，一般用不到；\ntype.measure：模型性能指标，对于不同的family，也是略有不同，可查看帮助文档\n\n对于逻辑回归，type.measure可以是以下取值：\n\nmse：均方误差；\ndeviance：偏差；\nmae：平均绝对误差，mean absolute error；\nclass：错分率；\nauc：只能用于二分类逻辑回归\n\n\n\n18.1.6 plot方法\n对于cv.glmnet()的结果，也提供了plot，print，coef，predict方法。\n\nplot(cvfit)\n\n\n\n\n\n\n\n\n该图形下面的横坐标是log10(lambda)，上面的横坐标是非零系数的数量，左侧的纵坐标是MSE（均方误差），改图展示了不同lambda取值下MSE的变化以及MSE±1倍标准差的置信区间。\n图中的两条竖线就是函数帮你挑选的两个结果，一个是lambda.min，此时的lambda值可以使得MSE最小，另外一个是lambda.1se，此时的lambda值可以使得MSE在最小MSE的1倍标准误区间内，但是同时可以使模型的复杂度降低。（在模型误差之间的差距不是很大的时候，我们肯定是喜欢更简单的模型啦，这个不难理解吧？）\n查看这两个lambda值：\n\ncvfit$lambda.min\n## [1] 0.02829953\ncvfit$lambda.1se\n## [1] 0.04945423\n\n换一个type.measure试试看：\n\ncvfit1 &lt;- cv.glmnet(x, y, family = \"binomial\", type.measure = \"auc\")\nplot(cvfit1)\n\n\n\n\n\n\n\n\n这个图的解读和上面那个图的解读也是一样的，只不过左侧纵坐标不一样而已。\n交叉验证的图形也是可以自己美化的，参考推文：lasso回归结果美化\n\n\n18.1.7 coef方法\n查看这两个取值下保留的非零系数情况：\n\n# 此时s不能同时使用多个值\ncoef(cvfit, s = \"lambda.min\")\n## 31 x 1 sparse Matrix of class \"dgCMatrix\"\n##                       s1\n## (Intercept)  0.538475144\n## V1           .          \n## V2           0.054881645\n## V3          -0.044528447\n## V4          -0.145609945\n## V5          -0.023218071\n## V6          -0.104593647\n## V7           .          \n## V8          -0.057762149\n## V9           0.073669351\n## V10         -0.148264046\n## V11         -0.009489879\n## V12          .          \n## V13         -0.002021430\n## V14          .          \n## V15          .          \n## V16          0.013778043\n## V17          .          \n## V18          .          \n## V19          .          \n## V20          .          \n## V21          .          \n## V22          0.032149957\n## V23          0.034431329\n## V24          .          \n## V25          0.069884641\n## V26         -0.050479757\n## V27          .          \n## V28          0.021367958\n## V29         -0.021118533\n## V30          .\ncoef(cvfit, s = \"lambda.1se\") # 这个是默认值\n## 31 x 1 sparse Matrix of class \"dgCMatrix\"\n##                       s1\n## (Intercept)  0.541225753\n## V1           .          \n## V2           0.046087719\n## V3          -0.027102998\n## V4          -0.132840898\n## V5          -0.019424141\n## V6          -0.079980759\n## V7           .          \n## V8          -0.044011217\n## V9           0.043650956\n## V10         -0.133222487\n## V11          .          \n## V12          .          \n## V13          .          \n## V14          .          \n## V15          .          \n## V16          .          \n## V17          .          \n## V18          .          \n## V19          .          \n## V20          .          \n## V21          .          \n## V22          0.022463353\n## V23          0.015349808\n## V24          .          \n## V25          0.052132213\n## V26         -0.037104017\n## V27          .          \n## V28          0.002725018\n## V29         -0.005935917\n## V30          .\n\n此时你就可以根据实际情况选择使用lambda.min还是lambda.1se，如果你选择了lambda.1se的话，那么就是有以下变量被保留：V2/V3/V4/V5/V6/V8/V9/V10/V22/V23/V25/V26/28/V29，其他变量的系数都是0，说明不重要，就可以被丢掉了。\n可以看到coef()的结果都是稀疏矩阵格式，这种格式计算效率更高，但是不方便后续使用，可以使用as.matrix()转换为矩阵格式：\n\nas.matrix(coef(cvfit))\n##                       s1\n## (Intercept)  0.541225753\n## V1           0.000000000\n## V2           0.046087719\n## V3          -0.027102998\n## V4          -0.132840898\n## V5          -0.019424141\n## V6          -0.079980759\n## V7           0.000000000\n## V8          -0.044011217\n## V9           0.043650956\n## V10         -0.133222487\n## V11          0.000000000\n## V12          0.000000000\n## V13          0.000000000\n## V14          0.000000000\n## V15          0.000000000\n## V16          0.000000000\n## V17          0.000000000\n## V18          0.000000000\n## V19          0.000000000\n## V20          0.000000000\n## V21          0.000000000\n## V22          0.022463353\n## V23          0.015349808\n## V24          0.000000000\n## V25          0.052132213\n## V26         -0.037104017\n## V27          0.000000000\n## V28          0.002725018\n## V29         -0.005935917\n## V30          0.000000000\n\n\n\n18.1.8 predict方法\n对新数据进行预测也是一样的用法：\n\npredict(cvfit, newx = x[1:5,], s = \"lambda.min\")\n##      lambda.min\n## [1,]  0.2880810\n## [2,]  0.9411606\n## [3,]  0.6169352\n## [4,]  0.1604069\n## [5,]  0.5976043\n\n\n\n18.1.9 一些参数解释\n\nalpha：可以看做是L1正则化的比例，当alpha=1时，就是lasso，当alpha=0时，就是岭回归，当0&lt;alpha&lt;1时，就是弹性网络。\nweights：不同观测的权重，默认都是1。（glmnet会自动对权重进行重新标准化，使得所有观测的权重相加等于样本数量）。\nnlambda：lambda的取值个数，默认是100。\nlambda：用户可以通过这个参数自己指定lambda的取值。\nstandardize：逻辑值，是否在拟合模型前对自变量进行标准化，默认是TRUE。\n\n下面是一个对不同观测自定义权重的示例。\n我们这个示例中，样本量是100，所以我们为100个观测自定义以下权重：\n\n# 简单定义一下，前50个是1，后50个是2\nwts &lt;-  c(rep(1,50), rep(2,50))\nfit1 &lt;- glmnet(x, y, alpha = 0.2, weights = wts, nlambda = 20)\n\nprint(fit1)\n## \n## Call:  glmnet(x = x, y = y, weights = wts, alpha = 0.2, nlambda = 20) \n## \n##    Df  %Dev  Lambda\n## 1   0  0.00 1.18600\n## 2   2 11.40 0.73050\n## 3  10 31.21 0.44990\n## 4  11 48.89 0.27710\n## 5  15 59.86 0.17060\n## 6  21 66.72 0.10510\n## 7  26 71.32 0.06471\n## 8  28 73.71 0.03985\n## 9  29 74.84 0.02454\n## 10 29 75.37 0.01512\n## 11 29 75.58 0.00931\n## 12 29 75.66 0.00573\n## 13 30 75.70 0.00353\n## 14 30 75.71 0.00217\n## 15 30 75.72 0.00134\n## 16 30 75.72 0.00082\n## 17 30 75.72 0.00051\n\n可以看到结果中只有17个lambda值，少于我们指定的20个，原因已经在前面解释过了。",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>lasso回归筛选变量</span>"
    ]
  },
  {
    "objectID": "feature-selection_lasso.html#正则化cox回归",
    "href": "feature-selection_lasso.html#正则化cox回归",
    "title": "18  lasso回归筛选变量",
    "section": "18.2 正则化Cox回归",
    "text": "18.2 正则化Cox回归\n正则化的COX回归，也就是glmnet在生存分析中的应用，这里我们还是以lasso为例进行演示。\nglmnet包的详细使用介绍已经在前面都介绍过了，正则化的COX回归并没有太大的不同，所以这里简单介绍一下。\n下面是一些理论解释，大家随便看看就好。\n在glmnet中，我们使用弹性网络（elastic net）方法对部分似然的负对数进行惩罚。\n部分似然（partial-likelihood）是一种用于处理生存分析（survival-analysis）中右侧截尾（right-censored）观测的方法。而负对数部分似然（negative-log-partial-likelihood）则是对部分似然取反并求对数，目的是将最大化似然函数的问题转化为最小化负对数似然函数的问题。\n为了进一步约束模型的复杂度和提高模型的泛化能力，我们在负对数部分似然的基础上引入了弹性网络惩罚（elastic-net-penalty）。弹性网惩罚结合了L1正则化（L1-regularization）和L2正则化（L2-regularization）的特性，从而既能产生稀疏解，又能保留一些高度相关的特征。这样我们可以在建立模型时在部分似然的基础上，使用弹性网惩罚来进行模型的优化和参数选择，以提高模型的性能和泛化能力。\n\n18.2.1 基础使用\nglmnet对数据格式是有要求的，之前也说过，x必须是由自变量组成的matrix，y可以是一个两列的matrix，两列的列名必须是time和status，分别表示生存时间和生存状态，其中status必须使用数字0和数字1组成，0表示删失，1表示发生终点事件（又叫失效事件，比如死亡）。除此之外，y还可以是由Surv()函数生成的对象。\n下面是一个示例数据：\n\nlibrary(glmnet)\nlibrary(survival)\n\ndata(CoxExample)\nx &lt;- CoxExample$x\ny &lt;- CoxExample$y\n\n# 查看y的数据格式\ny[1:5, ]\n##            time status\n## [1,] 1.76877757      1\n## [2,] 0.54528404      1\n## [3,] 0.04485918      0\n## [4,] 0.85032298      0\n## [5,] 0.61488426      1\n\n建立模型，只需要使用family = \"cox\"即可：\n\nfit &lt;- glmnet(x, y, family = \"cox\")\n\n其中的一些参数比如alpha，weights，nlambda等，在前面已经介绍过了，这里就不再多介绍了。\n可视化、提取系数、预测新数据和之前介绍的用法也是一模一样，这里也不再多说了。\n\n\n18.2.2 交叉验证\n对于正则化的cox来说，cv.glmnet()中的type.measure只能是\"deviance\"（默认值，给出部分似然），或者\"C\"，给出 Harrell-C-index。\n\nset.seed(1)\ncvfit &lt;- cv.glmnet(x, y, family = \"cox\", type.measure = \"C\")\n\nprint(cvfit)\n## \n## Call:  cv.glmnet(x = x, y = y, type.measure = \"C\", family = \"cox\") \n## \n## Measure: C-index \n## \n##      Lambda Index Measure       SE Nonzero\n## min 0.03058    23  0.7304 0.005842      11\n## 1se 0.05865    16  0.7267 0.005993      10\n\n画图也是一样的，下面这幅图的解释在前面也已经详细介绍过了，这里就不再多做解释了：\n\nplot(cvfit)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n提示\n\n\n\n在glmnet中，对于生存时间的排列相同（ties）情况，使用的是Breslow近似（Breslow approximation）。这与survival软件包中的coxph函数的默认排列处理方法（tie-handling method）-Efron近似（Efron approximation）不同。\n当存在相同的生存时间观测时，例如多个个体在同一时间发生事件，排列的处理方法对估计结果和推断的准确性至关重要。Breslow近似与Efron近似是最常见的两种处理方法。\n在glmnet中，使用Breslow近似处理排列，该方法假设所有的排列发生在后一事件之前的所有时间上。这种近似方法在计算效率上比较高，但可能会导致估计的偏差。\n而在survival软件包中的coxph函数，默认使用的是Efron近似处理排列。Efron近似方法基于考虑排列发生的时间顺序进行调整，更接近真实的结果，但在计算过程中稍微耗时一些。\n因此，当在glmnet和survival软件包中处理生存分析时，需要注意到在处理排列的方法上的差异，以确保得到准确和一致的结果。\n\n\n\n\n18.2.3 分层COX\ncoxph()支持strata()函数，因为它是使用公式形式的，但是glmnet不支持公式形式，只能使用x/y形式的输入，所以如果要实现分层，需要使用stratifySurv()。\n继续使用上面的示例数据，我们把1000个观测分成5层：\n\n# 把1000个观测分5层\nstrata &lt;- rep(1:5, length.out = 1000)\ny2 &lt;- stratifySurv(y, strata) # 对y进行分层\nstr(y2[1:6])\n##  'stratifySurv' num [1:6, 1:2] 1.7688  0.5453  0.0449+ 0.8503+ 0.6149  0.2986+\n##  - attr(*, \"dimnames\")=List of 2\n##   ..$ : NULL\n##   ..$ : chr [1:2] \"time\" \"status\"\n##  - attr(*, \"type\")= chr \"right\"\n##  - attr(*, \"strata\")= int [1:6] 1 2 3 4 5 1\n\n接下来把y2提供给glmnet()或者cv.glmnet()就可以实现正则化的分层COX了。\n\nfit &lt;- glmnet(x, y2, family = \"cox\")\n\ncv.fit &lt;- cv.glmnet(x, y2, family = \"cox\", nfolds = 5)\nplot(cv.fit)\n\n\n\n\n\n\n\n\n\n\n18.2.4 生存曲线\nglmnet的结果可以直接提供给survfit()使用，可以用来画生存曲线。这里简单介绍一下，大家知道即可，因为大家在平时写文章时根本不会这么用……\n以下是一个示例。\n\ndata(CoxExample)\nx &lt;- CoxExample$x\ny &lt;- CoxExample$y\n\ny &lt;- Surv(y[,1],y[,2]) # 需要用Surv转换格式\n\nfit &lt;- glmnet(x, y, family = \"cox\")\nsurvival::survfit(fit, s = 0.05, x = x, y = y)\n## Call: survfit.coxnet(formula = fit, s = 0.05, x = x, y = y)\n## \n##         n events median\n## [1,] 1000    692  0.922\n\n直接画图即可：\n\nplot(survival::survfit(fit, s = 0.05, x = x, y = y))\n\n\n\n\n\n\n\n\n这个生存曲线有些奇怪，因为数据原因，大家可以自己尝试下。\n基于新的数据画生存曲线也是可以的：\n\nplot(survival::survfit(fit, s = 0.05, x = x, y = y, newx = x[1:3, ]))",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>lasso回归筛选变量</span>"
    ]
  },
  {
    "objectID": "feature-selection_randomforest.html",
    "href": "feature-selection_randomforest.html",
    "title": "19  随机森林筛选变量",
    "section": "",
    "text": "19.1 准备数据\n我们使用TCGA-BLCA的lncRNA数据(数据在粉丝QQ群文件，需要的加群下载即可)，其中包括408个样本，time_months是生存时间，event是生存状态，1代表死亡，0代表生存，其余变量都是自变量。\n先简单处理一下数据：\nrm(list = ls())\nload(file = \"datasets/lnc_expr_clin.RData\")\n#去掉没有生存信息的样本\nlnc_expr_clin &lt;- lnc_expr_clin[!is.na(lnc_expr_clin$time_months),]\nlnc_expr_clin &lt;- lnc_expr_clin[lnc_expr_clin$time_months&gt;0,]\n\n#选择其中一部分数据\ndat.cox &lt;- lnc_expr_clin[,c(72,1:59)]\n\n#把变量命中的“-”去掉\ncolnames(dat.cox)&lt;- gsub(\"-\",\"\",colnames(dat.cox))\n\n#结果变量变为因子型\ndat.cox$event &lt;- factor(dat.cox$event)\ndim(dat.cox)\n## [1] 297  60\ndat.cox[1:4,1:6]\n##   event    PGM5AS1 LINC01082 AC005180.2 AC005180.1    FENDRR\n## 1     0 0.15064007 0.2642238  0.0000000  0.1547768 0.7802599\n## 2     0 0.06309362 0.1666554  0.3105983  0.2436603 0.7239329\n## 3     1 2.16399508 3.5662920  2.2454129  2.0073496 2.8409939\n## 4     0 2.73075081 1.7314314  0.8609916  0.7323014 1.0531249",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>随机森林筛选变量</span>"
    ]
  },
  {
    "objectID": "feature-selection_randomforest.html#建立模型",
    "href": "feature-selection_randomforest.html#建立模型",
    "title": "19  随机森林筛选变量",
    "section": "19.2 建立模型",
    "text": "19.2 建立模型\n使用经典的randomForest建立随机森林模型：\n\nlibrary(randomForest)\n\nset.seed(124)\nfit &lt;- randomForest(event~., data = dat.cox)\n\nfit\n## \n## Call:\n##  randomForest(formula = event ~ ., data = dat.cox) \n##                Type of random forest: classification\n##                      Number of trees: 500\n## No. of variables tried at each split: 7\n## \n##         OOB estimate of  error rate: 23.91%\n## Confusion matrix:\n##     0 1 class.error\n## 0 225 1 0.004424779\n## 1  70 1 0.985915493\n\n结果给出了树的数量：500颗；OOB错误率：23.91%；还给出了混淆矩阵。",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>随机森林筛选变量</span>"
    ]
  },
  {
    "objectID": "feature-selection_randomforest.html#结果探索",
    "href": "feature-selection_randomforest.html#结果探索",
    "title": "19  随机森林筛选变量",
    "section": "19.3 结果探索",
    "text": "19.3 结果探索\n下面是可视化整体错误率和树的数量的关系，可以看到随着树的数量增加，错误率逐渐降低并渐趋平稳，中间的黑色线条是整体的错误率，上下两条是结果变量中两个类别的错误率。\n\nplot(fit)\n\n\n\n\n\n\n\n\n可以看到结果有一个类别的错误率竟然是逐渐增加的，因为我们这个数据的存在严重的类不平衡问题，也就是结果变量中的两种类别差异很大：\n\ntable(dat.cox$event)\n## \n##   0   1 \n## 226  71\n\n类别0有226个，类别1只有71个，模型为了提高整体准确率，就会牺牲掉类别为1的准确性。\n查看整体错误率最小时有几棵树：\n\nwhich.min(fit$err.rate[,1])\n## [1] 252\n\n查看各个变量的重要性，这里给出了mean decrease gini，数值越大说明变量越重要：\n\nimportance(fit)\n##             MeanDecreaseGini\n## PGM5AS1            0.9352510\n## LINC01082          1.3866068\n## AC005180.2         1.6168145\n## AC005180.1         1.3488141\n## FENDRR             1.3961145\n## AC053503.3         1.1375051\n## MIR100HG           1.8389235\n## AP001107.5         1.4790429\n## C5orf66AS1         1.9776753\n## NR4A1AS            1.5676917\n## AL162424.1         1.4297710\n## AF001548.1         1.4044652\n## AC099850.4         1.9485050\n## MBNL1AS1           1.7969564\n## ADAMTS9AS1         2.6993467\n## MIR22HG            1.7904790\n## MIR200CHG          2.0379430\n## AC093010.3         2.8789159\n## LINC00865          1.4885762\n## AP003071.4         1.6418555\n## PCAT6              2.0033471\n## LINC02657          2.2435347\n## PPP1R14BAS1        1.8262720\n## AC012085.2         1.3986750\n## ACTA2AS1           1.3608811\n## AC036108.3         1.6392733\n## AC079313.2         1.1854198\n## AC020916.1         1.5358508\n## SNHG25             3.2320090\n## AL049555.1         3.2795519\n## MIR11HGAS1         1.1433175\n## AC018904.1         1.5742751\n## SNHG12             2.9166977\n## SPINT1AS1          2.2857854\n## KRT7AS             2.1031232\n## MIR205HG           1.5659665\n## HAND2AS1           1.9955215\n## AL445524.1         2.2827356\n## LINC01980          1.4518537\n## ZNF710AS1          1.7042160\n## AC092718.4         1.7060641\n## AC008735.2         1.5337512\n## LINC01133          1.2802464\n## AC025575.2         1.5706176\n## MAFGDT             1.9238538\n## CASC9              2.6039129\n## AL390719.2         2.1003651\n## AC002398.2         0.7629889\n## AC008736.1         1.9839028\n## AL161431.1         3.0891759\n## PCCADT             1.5235273\n## AC245041.2         1.9197363\n## U62317.1           1.6662262\n## U62317.2           1.4415305\n## VPS9D1AS1          2.0524334\n## AL023284.4         1.8027226\n## AATBC              2.1357139\n## LINC00641          1.6734872\n## AC015912.3         2.4443188\n\n可视化变量重要性：\n\nvarImpPlot(fit)\n\n\n\n\n\n\n\n\n通过变量重要性，大家就可以选择比较重要的变量了。你可以选择前5个，前10个，或者大于所有变量性平均值(中位数，百分位数等)的变量等等。",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>随机森林筛选变量</span>"
    ]
  },
  {
    "objectID": "feature-selection_randomforest.html#交叉验证变量筛选",
    "href": "feature-selection_randomforest.html#交叉验证变量筛选",
    "title": "19  随机森林筛选变量",
    "section": "19.4 交叉验证变量筛选",
    "text": "19.4 交叉验证变量筛选\nrandomForest还提供了使用交叉验证法进行递归特征消除，筛选变量的方法：rfcv，下面是使用5折交叉验证进行递归特征消除：\n\nset.seed(647)\nres &lt;- rfcv(trainx = dat.cox[,-1],trainy = dat.cox[,1],\n            cv.fold = 5,\n            recursive = T\n            )\nres$n.var #变量个数\n## [1] 59 30 15  7  4  1\nres$error.cv #错误率\n##        59        30        15         7         4         1 \n## 0.2558923 0.2693603 0.2592593 0.2558923 0.2929293 0.3333333\n\n可以看到在变量个数为7的时候，错误率是最小的(和59一样，但是肯定选简单的)。\n可视化这个结果，很明显变量个数为7(和59)的时候错误率最小：\n\nwith(res, plot(n.var, error.cv, type=\"o\", lwd=2))\n\n\n\n\n\n\n\n\n结合上面的变量重要性，你可以选择前7个最重要的变量。\n\n\n\n\n\n\n注意\n\n\n\nrfcv得出的变量重要性和randomForest得出的变量重要性并不一样，而且rfcv的结果也并没有明确给出到底哪几个变量才是被选中的。这个方法并不常用，也不推荐大家用~\n参考：stackoverflow",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>随机森林筛选变量</span>"
    ]
  },
  {
    "objectID": "feature-selection_randomforest.html#boruta筛选变量",
    "href": "feature-selection_randomforest.html#boruta筛选变量",
    "title": "19  随机森林筛选变量",
    "section": "19.5 Boruta筛选变量",
    "text": "19.5 Boruta筛选变量\nBoruta是基于随机森林的一种变量筛选方法，它可以基于随机森林的变量重要性计算z-score，然后对每个变量标记确认 or 待定 or 拒绝，从而实现变量筛选。\n这种方法倾向于找到所有与结果变量最相关的变量，所以结果有可能是冗余的(或者存在共线性、相关性)。\n参考文献：Kursa M B, Rudnicki W R. Feature selection with the Boruta package[J]. Journal of statistical software, 2010, 36: 1-13.\n我们还是以这个数据集为例进行演示。\n\nlibrary(Boruta)\n\nset.seed(23)\n\nfs &lt;- Boruta(event ~ ., data = dat.cox, doTrace=1)\n\n查看筛选结果：变量确认，变量待定，变量拒绝：\n\ntable(fs$finalDecision)\n## \n## Tentative Confirmed  Rejected \n##        11         7        41\n\n获取确认变量的名字：\n\ngetSelectedAttributes(fs)\n## [1] \"MIR100HG\"   \"ADAMTS9AS1\" \"AC093010.3\" \"SNHG25\"     \"SPINT1AS1\" \n## [6] \"HAND2AS1\"   \"AL161431.1\"\n\n这样就搞定了！用这几个变量重新建立模型即可，当然也可以用这几个变量建立其他你喜欢的模型，都是可以的。\n公众号后台回复变量筛选即可获取相关推文合集，回复随机森林也可获取相关合集。",
    "crumbs": [
      "常见的变量选择方法",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>随机森林筛选变量</span>"
    ]
  },
  {
    "objectID": "conf_matrix-3d.html",
    "href": "conf_matrix-3d.html",
    "title": "20  三维混淆矩阵",
    "section": "",
    "text": "20.1 2d混淆矩阵可视化\n如果要可视化混淆矩阵，简单的2维非常简单，比如用ggplot2即可：\nggplot(df1, aes(pred, outcome))+\n  geom_tile(aes(fill=ca125))+\n  geom_label(data = df1 %&gt;% count(pred, outcome), aes(pred,outcome,label=n),size=12)+\n  theme_minimal()+\n  theme(legend.position = \"none\")\n想要修改更多细节，大家自己动手即可，非常简单！",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>三维混淆矩阵</span>"
    ]
  },
  {
    "objectID": "conf_matrix-3d.html#d版混淆矩阵可视化",
    "href": "conf_matrix-3d.html#d版混淆矩阵可视化",
    "title": "20  三维混淆矩阵",
    "section": "20.2 3d版混淆矩阵可视化",
    "text": "20.2 3d版混淆矩阵可视化\n也是很简单，使用barplot3d这个包即可。这个包需要本地安装。\n注意这个包画图的顺序：从左到右，从前到后！\n\nlibrary(barplot3d)\n\n# 把混淆矩阵结果放到1个向量里\ninputdata &lt;- c(15,5,1,9)\n\n# 定义4个颜色\nmycolors &lt;- c(\"#00468BB2\", \"#ED0000B2\", \"#42B540B2\", \"#0099B4B2\")\n\nbarplot3d(rows = 2,cols = 2, z = inputdata, # 一共4个数，2行，2列\n          scalexy=8, # 让柱子胖一点\n          topcolors=mycolors, # 柱子顶部的颜色\n          sidecolors=mycolors, # 柱子的填充色\n          xlabels = c(\"pred.No\",\"pred.Yes\"), \n          ylabels = c(\"No\",\"Yes\"),\n          xsub = \"Prediction\",\n          ysub = \"Outcome\",\n          zsub = \"Count\"\n          )\n\n出图如下：\n\n这个图是3d的，画出来之后会单独弹出一个窗口，你可以随意旋转，找到自己喜欢的角度保存即可！",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>三维混淆矩阵</span>"
    ]
  },
  {
    "objectID": "roc-binominal.html",
    "href": "roc-binominal.html",
    "title": "21  二分类ROC曲线绘制",
    "section": "",
    "text": "21.1 方法1：pROC\n使用pROC包，这个R包的功能非常强大，我这里只演示它的绘制ROC曲线以及计算AUC的功能，关于这个R包的详细使用，请参考文章：用pROC实现ROC曲线分析，关于pROC的使用在最后一章有详细介绍。\n这个包的使用有一些注意点如下：\n使用pROC包的aSAH数据，其中outcome列是结果变量，1代表Good，2代表Poor。这是一个动脉瘤性蛛网膜下腔出血的数据集，一共113行，7列。其中：\nlibrary(pROC)\n\ndata(aSAH)\ndim(aSAH)\n## [1] 113   7\nstr(aSAH)\n## 'data.frame':    113 obs. of  7 variables:\n##  $ gos6   : Ord.factor w/ 5 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 5 5 5 5 1 1 4 1 5 4 ...\n##  $ outcome: Factor w/ 2 levels \"Good\",\"Poor\": 1 1 1 1 2 2 1 2 1 1 ...\n##  $ gender : Factor w/ 2 levels \"Male\",\"Female\": 2 2 2 2 2 1 1 1 2 2 ...\n##  $ age    : int  42 37 42 27 42 48 57 41 49 75 ...\n##  $ wfns   : Ord.factor w/ 5 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 1 1 1 1 3 2 5 4 1 2 ...\n##  $ s100b  : num  0.13 0.14 0.1 0.04 0.13 0.1 0.47 0.16 0.18 0.1 ...\n##  $ ndka   : num  3.01 8.54 8.09 10.42 17.4 ...\n计算AUC及可信区间：\nres &lt;- roc(aSAH$outcome,aSAH$s100b,ci=T,auc=T)\nres\n## \n## Call:\n## roc.default(response = aSAH$outcome, predictor = aSAH$s100b,     auc = T, ci = T)\n## \n## Data: aSAH$s100b in 72 controls (aSAH$outcome Good) &lt; 41 cases (aSAH$outcome Poor).\n## Area under the curve: 0.7314\n## 95% CI: 0.6301-0.8326 (DeLong)\n绘制ROC曲线：\nplot(res,legacy.axes = TRUE)\n可以显示最佳截点（最佳截点的问题后续章节会详细介绍），比如AUC最大的点：\nplot(res,\n     legacy.axes = TRUE,\n     thresholds=\"best\", # AUC最大的点\n     print.thres=\"best\")\n多条ROC曲线画在一起：\nrocobj1 &lt;- plot.roc(aSAH$outcome, aSAH$s100,percent=TRUE, col=\"#1c61b6\")\nrocobj2 &lt;- lines.roc(aSAH$outcome, aSAH$ndka, percent=TRUE, col=\"#008600\")\n\nlegend(\"bottomright\", legend=c(\"S100B\", \"NDKA\"), \n       col=c(\"#1c61b6\", \"#008600\"), lwd=2)\n两条ROC曲线的比较，可以添加P值：\nrocobj1 &lt;- plot.roc(aSAH$outcome, aSAH$s100,percent=TRUE, col=\"#1c61b6\")\nrocobj2 &lt;- lines.roc(aSAH$outcome, aSAH$ndka, percent=TRUE, col=\"#008600\")\n\nlegend(\"bottomright\", legend=c(\"S100B\", \"NDKA\"), \n       col=c(\"#1c61b6\", \"#008600\"), lwd=2)\n\ntestobj &lt;- roc.test(rocobj1, rocobj2)\n\ntext(50, 50, labels=paste(\"p-value =\",format.pval(testobj$p.value)), \n     adj=c(0, .5))",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>二分类ROC曲线绘制</span>"
    ]
  },
  {
    "objectID": "roc-binominal.html#方法1proc",
    "href": "roc-binominal.html#方法1proc",
    "title": "21  二分类ROC曲线绘制",
    "section": "",
    "text": "一定要指定direction，否则可能会得出错误的结果。\n这个R包计算AUC是基于中位数的，哪一组的中位数大就计算哪一组的AUC。\n它可以绘制带有置信区间的ROC，但是并不是大家想要的那一种，具体请参考上面的文章\n\n\n\ngos6：格拉斯哥量表评分\noutcome：结果变量\ngender：性别\nage：年龄\nwfns：世界神经外科医师联合会公认的神经学量表评分\ns100b：生物标志物\nndka：生物标志物",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>二分类ROC曲线绘制</span>"
    ]
  },
  {
    "objectID": "roc-binominal.html#方法2rocr",
    "href": "roc-binominal.html#方法2rocr",
    "title": "21  二分类ROC曲线绘制",
    "section": "21.2 方法2：ROCR",
    "text": "21.2 方法2：ROCR\n使用ROCR，如果你只是为了画一条ROC曲线，这是我最推荐的方法了，美观又简单！\n\nlibrary(ROCR)\n\n使用非常简单，3句代码，其中第2句是关键，可以更改各种参数，然后就可以画出各种不同的图形：\n\npred &lt;- prediction(aSAH$s100b,aSAH$outcome)\nperf &lt;- performance(pred, \"tpr\",\"fpr\")\nauc &lt;- round(performance(pred, \"auc\")@y.values[[1]],digits = 4)\n\nplot(perf,lwd=2,col=\"tomato\")\nabline(0,1,lty=2)\nlegend(\"bottomright\", legend=\"AUC of s100b: 0.7314\", \n       col=\"tomato\", lwd=2,bty = \"n\")\n\n\n\n\n\n\n\n\n添加箱线图：\n\nperf &lt;- performance(pred, \"tpr\", \"fpr\")\nperf\n## A performance instance\n##   'False positive rate' vs. 'True positive rate' (alpha: 'Cutoff')\n##   with 51 data points\n\nplot(perf,\n     avg=\"threshold\",\n     spread.estimate=\"boxplot\")\n\n\n\n\n\n\n\n\n还可以绘制PR曲线，召回率recall为横坐标，精确率precision 为纵坐标：\n\nperf &lt;- performance(pred, \"prec\", \"rec\")\nplot(perf,\n     avg= \"threshold\",\n     colorize=TRUE,\n     lwd= 3,\n     main= \"Precision-Recall plot\")\nplot(perf,\n     lty=3,\n     col=\"grey78\",\n     add=TRUE)\n\n\n\n\n\n\n\n\n这个包还可以计算非常多其他的指标，各种图都能画，大家可以自己探索。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>二分类ROC曲线绘制</span>"
    ]
  },
  {
    "objectID": "roc-binominal.html#方法3yardstick",
    "href": "roc-binominal.html#方法3yardstick",
    "title": "21  二分类ROC曲线绘制",
    "section": "21.3 方法3：yardstick",
    "text": "21.3 方法3：yardstick\n使用yardstick，它是tidymodels的核心R包之一，tidymodels是R中专门做机器学习和统计建模的，可以到公众号：医学和生信笔记，后台回复tidymodels查看更多关于它的教程，它也是目前R语言机器学习领域两大当红辣子鸡之一！另一个是mlr3。\n\nlibrary(yardstick)\nlibrary(ggplot2)\n\n它很优雅，如果你要计算AUC，那么就是roc_auc()函数：\n\naSAH |&gt; roc_auc(outcome, s100b,event_level=\"second\")\n## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 roc_auc binary         0.731\n\n如果你是要画ROC曲线，那么就是roc_curve()函数：\n\naSAH |&gt; roc_curve(outcome, s100b,event_level=\"second\") |&gt; \n  ggplot(aes(x = 1 - specificity, y = sensitivity)) +\n  geom_path(size=1.2,color=\"firebrick\") +\n  geom_abline(lty = 3) +\n  coord_equal() +\n  theme_bw()\n\n\n\n\n\n\n\n\n还有太多方法可以画ROC了，不过pROC和ROCR基本上能解决99%的问题了。\n最后，给大家看看cran中比较常见的画ROC曲线的包，大家有兴趣可以自己探索：\n\nlibrary(pkgsearch) \nlibrary(dplyr)\n\nrocPkg &lt;-  pkg_search(query=\"ROC\",size=200)\n\nrocPkgShort &lt;- rocPkg |&gt; \n               filter(maintainer_name != \"ORPHANED\") |&gt;\n               select(score, package, downloads_last_month) |&gt;\n               arrange(desc(downloads_last_month))\nhead(rocPkgShort,20)\n## # A data frame: 20 × 3\n##     score package              downloads_last_month\n##  *  &lt;dbl&gt; &lt;chr&gt;                               &lt;int&gt;\n##  1 12743. pROC                               151995\n##  2   961. ROCR                                57388\n##  3  2866. PRROC                               12230\n##  4   432. riskRegression                       8820\n##  5   410. PresenceAbsence                      3378\n##  6  1992. plotROC                              3155\n##  7  2291. cvAUC                                2955\n##  8   526. ROCit                                2663\n##  9  2021. survivalROC                          2661\n## 10  1818. timeROC                              2653\n## 11  2024. precrec                              1859\n## 12   218. logcondens                           1829\n## 13   190. WVPlots                              1583\n## 14   164. PredictABEL                           869\n## 15   190. RISCA                                 706\n## 16   220. hmeasure                              681\n## 17   159. cubfits                               659\n## 18  1599. plotwidgets                           654\n## 19   137. ThresholdROCsurvival                  649\n## 20  1000. ROCnReg                               643\n\npROC高居榜首，遥遥领先！",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>二分类ROC曲线绘制</span>"
    ]
  },
  {
    "objectID": "roc-binominal.html#推荐阅读",
    "href": "roc-binominal.html#推荐阅读",
    "title": "21  二分类ROC曲线绘制",
    "section": "21.4 推荐阅读",
    "text": "21.4 推荐阅读\nROC曲线的其他问题可参考以下推文：\n\n多时间点和多指标的ROC曲线\n临床预测模型之二分类资料ROC曲线的绘制\n临床预测模型之生存资料ROC曲线的绘制\nROC曲线(AUC)的显著性检验\n生存资料ROC曲线的最佳截点和平滑曲线\nROC曲线纯手工绘制\nR语言计算AUC(ROC曲线)的注意事项\nROC阴性结果还是阳性结果\n多指标联合诊断的ROC曲线\nROC曲线最佳截点\nbootstrap ROC/AUC\nR语言多分类ROC曲线绘制\n\n公众号后台回复ROC即可获取以上合集链接。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>二分类ROC曲线绘制</span>"
    ]
  },
  {
    "objectID": "roc-survive.html",
    "href": "roc-survive.html",
    "title": "22  生存数据ROC曲线绘制",
    "section": "",
    "text": "22.1 加载数据\nrm(list = ls())\nload(file = \"./datasets/timeROC.RData\")",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>生存数据ROC曲线绘制</span>"
    ]
  },
  {
    "objectID": "roc-survive.html#多个时间点roc",
    "href": "roc-survive.html#多个时间点roc",
    "title": "22  生存数据ROC曲线绘制",
    "section": "22.2 多个时间点ROC",
    "text": "22.2 多个时间点ROC\n计算生存数据的ROC曲线以及AUC值，需要3列数据：生存时间，生存状态，以及你的分类依据（也就是你根据什么把样本分成生存还是死亡），在具体执行时，还必须指定时间点。\n看一下画图所需的数据长什么样子，event这一列是生存状态，0代表living，1代表dead，futime这一列是生存时间，单位是年，riskScore这一列是分类依据。\n\nstr(df)\n## 'data.frame':    297 obs. of  3 variables:\n##  $ event    : num  0 0 1 0 0 1 0 0 0 0 ...\n##  $ riskScore: num  -0.249 -0.511 -0.211 -0.427 0.279 ...\n##  $ futime   : num  3.03 1.16 1.82 1.52 1.34 ...\nhead(df)\n##   event    riskScore   futime\n## 1     0 -0.249325687 3.027500\n## 2     0 -0.511105679 1.155833\n## 3     1 -0.211305578 1.819167\n## 4     0 -0.427056800 1.516667\n## 5     0  0.278585747 1.344167\n## 7     1 -0.006760815 0.050000\n\n下面我们使用timeROC包中的timeROC()函数计算不同时间点的AUC值。\n\n# 加载R包\nlibrary(timeROC)\nlibrary(survival)\n\n# 构建timeroc\nROC &lt;- timeROC(T=df$futime,   \n               delta=df$event,   \n               marker=df$riskScore,   \n               cause=1,                #阳性结局指标数值\n               weighting=\"marginal\",   #计算方法，默认为marginal\n               times=c(1, 2, 3),       #时间点，选取1年2年3年\n               iid=TRUE)\n\nROC   #查看模型变量信息\n## Time-dependent-Roc curve estimated using IPCW  (n=297, without competing risks). \n##     Cases Survivors Censored AUC (%)   se\n## t=1    57       203       37   71.02 3.68\n## t=2    66       106      125   69.23 3.94\n## t=3    68        74      155   65.53 4.85\n## \n## Method used for estimating IPCW:marginal \n## \n## Total computation time : 0.07  secs.\n\n结果中给出了时间点在1年、2年、3年是的AUC值以及标准误(se)\n然后我们就可以根据这个结果绘制ROC曲线了。\n\n# 第1年的\nplot(ROC, \n     time=1, col=\"red\", lwd=2, title = \"\")   #time是时间点，col是线条颜色\n# 第2年的\nplot(ROC,\n     time=2, col=\"blue\", add=TRUE, lwd=2)    #add指是否添加在上一张图中\n# 第3年的\nplot(ROC,\n     time=3, col=\"orange\", add=TRUE, lwd=2)\n\n#添加图例信息\nlegend(\"bottomright\",\n       c(paste0(\"AUC at 1 year: \",round(ROC[[\"AUC\"]][1],2)), \n         paste0(\"AUC at 2 year: \",round(ROC[[\"AUC\"]][2],2)), \n         paste0(\"AUC at 3 year: \",round(ROC[[\"AUC\"]][3],2))),\n       col=c(\"red\", \"blue\", \"orange\"),\n       lty=1, lwd=2,bty = \"n\") \n\n\n\n\n\n\n\n\n如果你想绘制其他时间点的AUC以及ROC曲线，只需要在timeROC()函数中更改时间点即可。\n由于我们使用了不同的时间点，每一个时间点都有一个AUC值，所以我们可以很简单的就画出time-dependent-AUC曲线：\n\nplotAUCcurve(ROC, conf.int = T, col = \"firebrick\")",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>生存数据ROC曲线绘制</span>"
    ]
  },
  {
    "objectID": "roc-survive.html#多指标roc",
    "href": "roc-survive.html#多指标roc",
    "title": "22  生存数据ROC曲线绘制",
    "section": "22.3 多指标ROC",
    "text": "22.3 多指标ROC\n大家在文献中也可能见到过多个指标的ROC曲线绘制在一张图上。下面给大家演示。\n首先也是看一下所需要的数据结构，其中futime和event是必须的，另外的几列是你想要用来画ROC曲线的指标，在这里我使用了riskScore，gender，age，TNM分期。\n在gender这一列，1是female，2是male，t，n，m这3列，数字代表不同的分期。\n\nstr(df2)\n## 'data.frame':    297 obs. of  8 variables:\n##  $ event    : num  0 0 1 0 0 1 0 0 0 0 ...\n##  $ age      : int  59 63 65 73 59 66 56 42 61 48 ...\n##  $ riskScore: num  -0.249 -0.511 -0.211 -0.427 0.279 ...\n##  $ futime   : num  3.03 1.16 1.82 1.52 1.34 ...\n##  $ gender   : num  2 2 2 1 2 2 1 2 2 2 ...\n##  $ t        : num  4 4 4 3 3 3 5 3 NA 4 ...\n##  $ n        : num  1 5 1 1 1 1 3 1 NA 1 ...\n##  $ m        : num  1 1 1 1 1 3 1 1 3 3 ...\n\n多指标的ROC曲线非常简单，就是构建多个ROC，依次添加即可，时间点我们统一选择3年：\n\n# riskScore的ROC曲线\nROC.risk &lt;- timeROC(T=df2$futime,\n                    delta=df2$event,   \n                    marker=df2$riskScore,   \n                    cause=1,                \n                    weighting=\"marginal\",   \n                    times=3,   \n                    iid=TRUE)\n\n# gender的ROC曲线\nROC.gender &lt;- timeROC(T=df2$futime,   \n                      delta=df2$event,   \n                      marker=df2$gender,   \n                      cause=1,   \n                      weighting=\"marginal\",   \n                      times=3,   \n                      iid=TRUE)\n\n# age的ROC曲线\nROC.age &lt;- timeROC(T=df2$futime,   \n                   delta=df2$event,   \n                   marker=df2$age,   \n                   cause=1,   \n                   weighting=\"marginal\",   \n                   times=3,   \n                   iid=TRUE)\n\n# T分期的ROC曲线\nROC.T &lt;- timeROC(T=df2$futime,\n                 delta=df2$event,  \n                 marker=df2$t,   \n                 cause=1, \n                 weighting=\"marginal\", \n                 times=3, \n                 iid=TRUE)\n\n# N分期的ROC曲线\nROC.N &lt;- timeROC(T=df2$futime,   \n                 delta=df2$event,   \n                 marker=df2$n,   \n                 cause=1,   \n                 weighting=\"marginal\",   \n                 times=3,   \n                 iid=TRUE)\n\n# M分期的ROC曲线\nROC.M &lt;- timeROC(T=df2$futime,   \n                 delta=df2$event,   \n                 marker=df2$m,   \n                 cause=1,   \n                 weighting=\"marginal\",   \n                 times=3,   \n                 iid=TRUE)\n\n把每个曲线拼在一起即可，添加一个图例：\n\nplot(ROC.risk, time = 3, col=\"#E41A1C\", lwd=2, title = \"\")\nplot(ROC.gender, time = 3, col=\"#A65628\", lwd=2, add = T)\nplot(ROC.age, time = 3, col=\"#4DAF4A\", lwd=2, add = T)\nplot(ROC.T, time = 3, col=\"#377EB8\", lwd=2, add = T)\nplot(ROC.N, time = 3, col=\"#984EA3\", lwd=2, add = T)\nplot(ROC.M, time = 3, col=\"#FFFF33\", lwd=2, add = T)\nlegend(\"bottomright\",\n       c(paste0(\"Risk score: \",round(ROC.risk[[\"AUC\"]][2],2)), \n         paste0(\"gender: \",round(ROC.gender[[\"AUC\"]][2],2)), \n         paste0(\"age: \",round(ROC.age[[\"AUC\"]][2],2)),\n         paste0(\"T: \",round(ROC.T[[\"AUC\"]][2],2)),\n         paste0(\"N: \",round(ROC.N[[\"AUC\"]][2],2)),\n         paste0(\"M: \",round(ROC.M[[\"AUC\"]][2],2))\n         ),\n       col=c(\"#E41A1C\", \"#A65628\", \"#4DAF4A\",\"#377EB8\",\"#984EA3\",\"#FFFF33\"),\n       lty=1, lwd=2,bty = \"n\")",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>生存数据ROC曲线绘制</span>"
    ]
  },
  {
    "objectID": "roc-survive.html#推荐阅读",
    "href": "roc-survive.html#推荐阅读",
    "title": "22  生存数据ROC曲线绘制",
    "section": "22.4 推荐阅读",
    "text": "22.4 推荐阅读\nROC曲线的其他问题可参考以下推文：\n\n多时间点和多指标的ROC曲线\n临床预测模型之二分类资料ROC曲线的绘制\n临床预测模型之生存资料ROC曲线的绘制\nROC曲线(AUC)的显著性检验\n生存资料ROC曲线的最佳截点和平滑曲线\nROC曲线纯手工绘制\nR语言计算AUC(ROC曲线)的注意事项\nROC阴性结果还是阳性结果\n多指标联合诊断的ROC曲线\nROC曲线最佳截点\nbootstrap ROC/AUC\nR语言多分类ROC曲线绘制\n\n公众号后台回复ROC即可获取以上合集链接。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>生存数据ROC曲线绘制</span>"
    ]
  },
  {
    "objectID": "roc-compare.html",
    "href": "roc-compare.html",
    "title": "23  ROC曲线的显著性检验",
    "section": "",
    "text": "23.1 二分类资料的ROC比较\n可以通过pROC包实现的，使用其中roc.test()函数可实现两个ROC的Delong检验。\n使用pROC包的aSAH数据，其中outcome列是结果变量，1代表Good，2代表Poor。这是一个动脉瘤性蛛网膜下腔出血的数据集，一共113行，7列。其中：\nlibrary(pROC)\n\ndata(aSAH)\ndim(aSAH)\n## [1] 113   7\n\nstr(aSAH)\n## 'data.frame':    113 obs. of  7 variables:\n##  $ gos6   : Ord.factor w/ 5 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 5 5 5 5 1 1 4 1 5 4 ...\n##  $ outcome: Factor w/ 2 levels \"Good\",\"Poor\": 1 1 1 1 2 2 1 2 1 1 ...\n##  $ gender : Factor w/ 2 levels \"Male\",\"Female\": 2 2 2 2 2 1 1 1 2 2 ...\n##  $ age    : int  42 37 42 27 42 48 57 41 49 75 ...\n##  $ wfns   : Ord.factor w/ 5 levels \"1\"&lt;\"2\"&lt;\"3\"&lt;\"4\"&lt;..: 1 1 1 1 3 2 5 4 1 2 ...\n##  $ s100b  : num  0.13 0.14 0.1 0.04 0.13 0.1 0.47 0.16 0.18 0.1 ...\n##  $ ndka   : num  3.01 8.54 8.09 10.42 17.4 ...\n构建两个ROC对象，然后直接比较即可：\nroc1 &lt;- roc(aSAH$outcome,aSAH$s100b)\nroc2 &lt;- roc(aSAH$outcome,aSAH$ndka)\n\nres &lt;- roc.test(roc1,roc2)\nres\n## \n##  DeLong's test for two correlated ROC curves\n## \n## data:  roc1 and roc2\n## Z = 1.3908, p-value = 0.1643\n## alternative hypothesis: true difference in AUC is not equal to 0\n## 95 percent confidence interval:\n##  -0.04887061  0.28769174\n## sample estimates:\n## AUC of roc1 AUC of roc2 \n##   0.7313686   0.6119580\n这个函数里面有个method参数：delong/bootstrap/venkatraman，默认是delong，delong和bootstrap用于比较AUC，如果只是ROC曲线的比较，需要用venkatraman。关于这几种方法的具体原理，大家可以去翻相关的论文~\nroc.test只能用于两个ROC的比较，如果是多个比较，可以使用MedCalc软件，这个是和SPSS类似的软件，只要点点点即可。\n当然也是可以直接画在图里的：\nrocobj1 &lt;- plot.roc(aSAH$outcome, aSAH$s100,percent=TRUE, col=\"#1c61b6\")\nrocobj2 &lt;- lines.roc(aSAH$outcome, aSAH$ndka, percent=TRUE, col=\"#008600\")\n\nlegend(\"bottomright\", legend=c(\"S100B\", \"NDKA\"), \n       col=c(\"#1c61b6\", \"#008600\"), lwd=2)\n\ntestobj &lt;- roc.test(rocobj1, rocobj2)\n\ntext(50, 50, labels=paste(\"p-value =\",format.pval(testobj$p.value)), \n     adj=c(0, .5))\n当然你也可以用其他非参数检验的方法进行比较，比如mann whitney u检验。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>ROC曲线的显著性检验</span>"
    ]
  },
  {
    "objectID": "roc-compare.html#二分类资料的roc比较",
    "href": "roc-compare.html#二分类资料的roc比较",
    "title": "23  ROC曲线的显著性检验",
    "section": "",
    "text": "gos6：格拉斯哥量表评分\noutcome：结果变量\ngender：性别\nage：年龄\nwfns：世界神经外科医师联合会公认的神经学量表评分\ns100b：生物标志物\nndka：生物标志物",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>ROC曲线的显著性检验</span>"
    ]
  },
  {
    "objectID": "roc-compare.html#生存资料roc的比较",
    "href": "roc-compare.html#生存资料roc的比较",
    "title": "23  ROC曲线的显著性检验",
    "section": "23.2 生存资料ROC的比较",
    "text": "23.2 生存资料ROC的比较\n使用timeROC包实现。还是用之前用过的例子。\n\nrm(list = ls())\nlibrary(timeROC)\nlibrary(survival)\n\nload(file = \"./datasets/timeROC.RData\")\n\n使用其中的df2这个数据：\n\nstr(df2)\n## 'data.frame':    297 obs. of  8 variables:\n##  $ event    : num  0 0 1 0 0 1 0 0 0 0 ...\n##  $ age      : int  59 63 65 73 59 66 56 42 61 48 ...\n##  $ riskScore: num  -0.249 -0.511 -0.211 -0.427 0.279 ...\n##  $ futime   : num  3.03 1.16 1.82 1.52 1.34 ...\n##  $ gender   : num  2 2 2 1 2 2 1 2 2 2 ...\n##  $ t        : num  4 4 4 3 3 3 5 3 NA 4 ...\n##  $ n        : num  1 5 1 1 1 1 3 1 NA 1 ...\n##  $ m        : num  1 1 1 1 1 3 1 1 3 3 ...\n\n构建几个timeROC:\n\n# riskScore的ROC曲线\nROC.risk &lt;- timeROC(T=df2$futime,\n                    delta=df2$event,   \n                    marker=df2$riskScore,   \n                    cause=1,                \n                    weighting=\"marginal\",   \n                    times=3,  # c(1,2) \n                    iid=TRUE)\n\n\n# age的ROC曲线\nROC.age &lt;- timeROC(T=df2$futime,   \n                   delta=df2$event,   \n                   marker=df2$age,   \n                   cause=1,   \n                   weighting=\"marginal\",   \n                   times=3,   # c(1,2)\n                   iid=TRUE)\n\n比较就用compare()函数即可：\n\ncompare(ROC.risk, ROC.age)\n## $p_values_AUC\n##       t=0       t=3 \n##        NA 0.4544231\n\n同时使用多个时间点也是可以的：\n\n# riskScore的ROC曲线\nROC.risk &lt;- timeROC(T=df2$futime,\n                    delta=df2$event,   \n                    marker=df2$riskScore,   \n                    cause=1,                \n                    weighting=\"marginal\",   \n                    times=c(1,2),\n                    iid=TRUE)\n\n\n# age的ROC曲线\nROC.age &lt;- timeROC(T=df2$futime,   \n                   delta=df2$event,   \n                   marker=df2$age,   \n                   cause=1,   \n                   weighting=\"marginal\",   \n                   times=c(1,2),\n                   iid=TRUE)\n\ncompare(ROC.risk, ROC.age)\n## $p_values_AUC\n##        t=1        t=2 \n## 0.09758546 0.27995259\n\ncompare(ROC.risk, ROC.age, adjusted = T) # 计算调整p值\n## $p_values_AUC\n##                     t=1       t=2\n## Non-adjusted 0.09758546 0.2799526\n## Adjusted     0.14983636 0.3984702\n## \n## $Cor\n##           [,1]      [,2]\n## [1,] 1.0000000 0.7750774\n## [2,] 0.7750774 1.0000000\n\n画图就不演示了，可以参考前面的内容。\n但是要注意，如果两条ROC曲线比较得到的结果是P&gt;0.05的，只能说两者没有统计学意义，并不能直接说这两个ROC曲线的效能是一样的！",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>ROC曲线的显著性检验</span>"
    ]
  },
  {
    "objectID": "roc-bootstrap.html",
    "href": "roc-bootstrap.html",
    "title": "24  bootstrap ROC/AUC",
    "section": "",
    "text": "24.1 fbroc\n先介绍一个最简单的，用fbroc这个包实现，因为你在必应或者谷歌搜索bootstrap ROC in R，前几个结果中就是这个包。\nlibrary(fbroc)\n这个包在使用时需要把结果变量变为逻辑型：\noutcome1 &lt;- ifelse(aSAH$outcome == \"Good\",FALSE,TRUE)\n然后1行代码即可实现，默认是1000次bootstrap：\nset.seed(123)\nresult.boot &lt;- boot.roc(aSAH$s100b, outcome1)\nresult.boot\n## \n## Bootstraped uncached ROC Curve with 41 positive and 72 negative samples. \n##  \n## The AUC is 0.73.\n##  \n## 1000 bootstrap samples will be calculated. \n## The results use up 0 MB of memory.\n获取1000次bootstrap AUC的可信区间，还同时给出了标准误：\nset.seed(123)\nperf(result.boot, \"auc\", conf.level = 0.95)\n## \n## \n##                 Bootstrapped ROC performance metric\n## \n## Metric: AUC\n## Bootstrap replicates: 1000\n## Observed: 0.731\n## Std. Error: 0.052\n## 95% confidence interval:\n## 0.625 0.824\n把这1000条ROC曲线画在一起，就得到bootstrap ROC了：\nplot(result.boot)\n这个是我目前找到的最简单的方法。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>bootstrap ROC/AUC</span>"
    ]
  },
  {
    "objectID": "roc-bootstrap.html#tidyverse",
    "href": "roc-bootstrap.html#tidyverse",
    "title": "24  bootstrap ROC/AUC",
    "section": "24.2 tidyverse",
    "text": "24.2 tidyverse\n后面的方法就是根据开头说的思路，一步一步的实现了。\n先说个tidy的方法，借助tidyverse和tidymodels实现。\n\nlibrary(yardstick)\nlibrary(rsample)\nlibrary(tidyverse)\n\n先说下如何在tidymodels中绘制ROC曲线，详情可参考：tidymodels-yardstick：衡量模型性能\n在tidymodels中画一条ROC曲线非常简单，首先是计算画图需要的数据：\n\nroc_data &lt;- roc_curve(aSAH, outcome, s100b,event_level = \"second\")\nroc_data\n## # A tibble: 52 × 3\n##    .threshold specificity sensitivity\n##         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n##  1    -Inf         0            1    \n##  2       0.03      0            1    \n##  3       0.04      0            0.976\n##  4       0.05      0.0694       0.976\n##  5       0.06      0.111        0.976\n##  6       0.07      0.139        0.976\n##  7       0.08      0.222        0.902\n##  8       0.09      0.306        0.878\n##  9       0.1       0.389        0.829\n## 10       0.11      0.486        0.780\n## # ℹ 42 more rows\n\n然后是画图：\n\nautoplot(roc_data)\n\n\n\n\n\n\n\n\n接下来只要使用bootstrap生成1000个自助集就可以很方便的绘制1000条ROC曲线了。\n生成1000个自助集：\n\nset.seed(123)\nasb &lt;- bootstraps(aSAH, times = 1000)\nasb\n## # Bootstrap sampling \n## # A tibble: 1,000 × 2\n##    splits           id           \n##    &lt;list&gt;           &lt;chr&gt;        \n##  1 &lt;split [113/44]&gt; Bootstrap0001\n##  2 &lt;split [113/43]&gt; Bootstrap0002\n##  3 &lt;split [113/47]&gt; Bootstrap0003\n##  4 &lt;split [113/41]&gt; Bootstrap0004\n##  5 &lt;split [113/37]&gt; Bootstrap0005\n##  6 &lt;split [113/37]&gt; Bootstrap0006\n##  7 &lt;split [113/39]&gt; Bootstrap0007\n##  8 &lt;split [113/38]&gt; Bootstrap0008\n##  9 &lt;split [113/33]&gt; Bootstrap0009\n## 10 &lt;split [113/42]&gt; Bootstrap0010\n## # ℹ 990 more rows\n\n定义一个函数，获取自助集：这是tidymodels中的常见操作，可参考：tidymodels数据划分\n\nff &lt;- function(split){analysis(split)}\n\n下面就是提取1000个自助集的数据，对每个自助集进行1次ROC分析，以获取画图数据：\n\nplot_data &lt;- asb %&gt;% \n  mutate(boot_data = map(splits, ff)) %&gt;% \n  unnest(boot_data) %&gt;% \n  group_by(id) %&gt;% \n  roc_curve(outcome, s100b,event_level = \"second\") \n\ndim(plot_data)\n## [1] 40007     4\nhead(plot_data)\n## # A tibble: 6 × 4\n## # Groups:   id [1]\n##   id            .threshold specificity sensitivity\n##   &lt;chr&gt;              &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n## 1 Bootstrap0001    -Inf         0            1    \n## 2 Bootstrap0001       0.04      0            1    \n## 3 Bootstrap0001       0.05      0.0779       1    \n## 4 Bootstrap0001       0.06      0.143        1    \n## 5 Bootstrap0001       0.07      0.195        1    \n## 6 Bootstrap0001       0.08      0.312        0.944\n\n最后把1000条ROC曲线画在一起即可：也就是大家需要的bootstrap ROC：\n\nggplot()+\n  # 自助集的ROC曲线，共1000条\n  geom_path(data = plot_data,\n            mapping=aes(1-specificity, sensitivity,group=id),color = \"grey\")+\n  # 原始数据的ROC曲线\n  geom_path(data = roc_data, mapping = aes(1-specificity, sensitivity),\n            color=\"blue\", linewidth=1.5)+\n  theme_bw()\n\n\n\n\n\n\n\n\n由于我们已经进行了1000次ROC分析，那自然就可以获得1000个AUC，所以根据这1000个AUC，就可以计算均值、标准差、标准误、可信区间。\n先获取1000个AUC：\n\nboot_auc &lt;- asb %&gt;% \n  mutate(boot_data = map(splits, ff)) %&gt;% \n  unnest(boot_data) %&gt;% \n  group_by(id) %&gt;% \n  roc_auc(outcome, s100b,event_level = \"second\") \n#boot_auc\ndim(boot_auc)\n## [1] 1000    4\nhead(boot_auc)\n## # A tibble: 6 × 4\n##   id            .metric .estimator .estimate\n##   &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n## 1 Bootstrap0001 roc_auc binary         0.799\n## 2 Bootstrap0002 roc_auc binary         0.721\n## 3 Bootstrap0003 roc_auc binary         0.774\n## 4 Bootstrap0004 roc_auc binary         0.707\n## 5 Bootstrap0005 roc_auc binary         0.743\n## 6 Bootstrap0006 roc_auc binary         0.701\n\n这1000个AUC基本接近正态分布：\n\nggplot(boot_auc, aes(x=.estimate))+\n  geom_density()\n\n\n\n\n\n\n\n\n计算置信区间，公式如下（数学知识和统计知识，网络搜索或者看课本都可以）：\n\n可信区间下限 = 均值 - z * 标准误\n可信区间上限 = 均值 + z * 标准误\n\n先计算标准误：\n\nsample_mean &lt;- mean(boot_auc$.estimate)\nsample_mean\n## [1] 0.7315554\nsample_size &lt;- nrow(boot_auc)\nstandard_d &lt;- sd(boot_auc$.estimate)\nse &lt;- standard_d/sqrt(sample_size)\nse\n## [1] 0.001544964\n\n计算置信区间：\n\nconf_low &lt;- sample_mean - 1.96 * se\nconf_low\n## [1] 0.7285273\n\nconf_high &lt;- sample_mean + 1.96 * se\nconf_high\n## [1] 0.7345836",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>bootstrap ROC/AUC</span>"
    ]
  },
  {
    "objectID": "roc-bootstrap.html#base-r",
    "href": "roc-bootstrap.html#base-r",
    "title": "24  bootstrap ROC/AUC",
    "section": "24.3 base R",
    "text": "24.3 base R\n和tidy的方法没有本质区别，只是实现方式使用base R语法而已。这让我想起了某个外国网友对R的评论：目前很多人不是纠结于用R还是用Python，而是纠结于用base R还是tidy R。base R和tidy R真是太割裂了。\n先进行1次bootstrap（获取样本编号）看看效果：\n\nset.seed(123)\nbootset &lt;- sample(nrow(aSAH), size = nrow(aSAH), replace = T)\nbootset\n##   [1]  31  79  51  14  67  42  50  43 101  14  25  90  91  69  91  57  92   9\n##  [19]  93  99  72  26   7  42   9  83  36  78  81  43 103  76  15  32 106 109\n##  [37]   7   9  41  74  23  27  60  53   7  53  27  96  38  89  34  93  69  72\n##  [55]  76  63  13  82  97  91  25  38  21  79  41  47  90  60  95  16  94   6\n##  [73] 107  72  86  86  39  31 112  81  50 113  34   4  13  69  25  52  22  89\n##  [91]  32 110  25  87  35  40 112  30  12  31 110  30  64  99  14  93  96  71\n## [109]  67  23  79  85  37\n\n然后定义一个函数，获取每次的自助集：\n\nget_bootset &lt;- function(data){\n  boot_index &lt;- sample(nrow(data), size = nrow(data), replace = T)\n  bootset &lt;- data[boot_index,]\n  return(bootset)\n}\n\n#set.seed(123)\n#get_bootset(aSAH)\n\n使用bootstrap获取1000个自助集，通过for循环实现：\n\n# 每次结果都不一样\nbootsets &lt;- list()\nfor(i in 1:1000){\n  bootsets[[i]] &lt;- get_bootset(aSAH)\n}\nlength(bootsets)\n## [1] 1000\n\n对每一个自助集进行1次ROC分析，通过for循环实现：\n\nlibrary(pROC)\nrocs &lt;- list()\n\nfor(i in 1:1000){\n  rocs[[i]] &lt;- pROC::roc(bootsets[[i]][,\"outcome\"], bootsets[[i]][,\"s100b\"],\n                   quiet=T)\n}\n\n画1000条ROC曲线，还是通过for循环实现：\n\n# 提供一个画布\nplot(roc(aSAH$outcome, aSAH$s100b),col=\"blue\")\n\n# 画1000条ROC曲线\nfor(i in 1:1000){\n  lines.roc(rocs[[i]],col=\"grey\")\n}\n\n# 画完1000条把原来的挡住了，重新画一条\nlines.roc(roc(aSAH$outcome, aSAH$s100b),col=\"blue\")\n\n\n\n\n\n\n\n\n然后是计算1000个AUC的置信区间，和tidy的方法一样的。\n计算1000个AUC：\n\naucs &lt;- list()\n\nfor(i in 1:1000){\n  aucs[[i]] &lt;- auc(pROC::roc(bootsets[[i]][,\"outcome\"],bootsets[[i]][,\"s100b\"],\n                   quiet=T))\n}\naucs &lt;- unlist(aucs)\n\n计算可信区间：\n\nsample_mean &lt;- mean(aucs)\nsample_mean\n## [1] 0.7312995\nsample_size &lt;- length(aucs)\nstandard_d &lt;- sd(aucs)\nse &lt;- standard_d/sqrt(sample_size)\nse\n## [1] 0.001569356\n\n95%的可信区间，参考课本或者这个知乎的解释\n\nconf_low &lt;- sample_mean - 1.96 * se\nconf_low\n## [1] 0.7282235\n\nconf_high &lt;- sample_mean + 1.96 * se\nconf_high\n## [1] 0.7343754\n\n这种方法由于我没有在每次重抽样时设定种子数，导致结果是不可重复的哈，每次都不太一样~",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>bootstrap ROC/AUC</span>"
    ]
  },
  {
    "objectID": "roc-bootstrap.html#boot",
    "href": "roc-bootstrap.html#boot",
    "title": "24  bootstrap ROC/AUC",
    "section": "24.4 boot",
    "text": "24.4 boot\nboot是专门做重抽样的经典R包，在《R语言实战》一书中有详细介绍。\n通过这个包也可以计算bootstrap AUC的置信区间，但是这种方法只能计算指标，不能画ROC曲线。\n\nlibrary(boot)\nlibrary(pROC)\n\n定义一个函数，提取AUC：\n\n# boot的使用方式很奇怪\nget_auc &lt;- function(data, ind, outcome, predictor){\n  d = data[ind,] #这句必须加\n  au &lt;- as.numeric(auc(pROC::roc(d[,outcome], d[,predictor],quiet=T)))\n  au\n}\n\nget_auc(aSAH, outcome=\"outcome\",predictor=\"s100b\")\n## [1] 0.7313686\n\n提供给boot使用即可：\n\nset.seed(123)\nba &lt;- boot(aSAH, get_auc, R = 1000,\n           outcome=\"outcome\",predictor=\"s100b\")\nba\n## \n## ORDINARY NONPARAMETRIC BOOTSTRAP\n## \n## \n## Call:\n## boot(data = aSAH, statistic = get_auc, R = 1000, outcome = \"outcome\", \n##     predictor = \"s100b\")\n## \n## \n## Bootstrap Statistics :\n##      original       bias    std. error\n## t1* 0.7313686 0.0001084232  0.05365581\n\n结果给出了原始的AUC，以及1000次bootstrap得到的AUC的标准误。\n可以对这个结果画个图看看这1000个AUC的分布：\n\nplot(ba)\n\n\n\n\n\n\n\n\n获取这1000个AUC的置信区间，默认会给出95%的置信区间，并包含4种计算方法的结果：\n\nboot.ci(ba)\n## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\n## Based on 1000 bootstrap replicates\n## \n## CALL : \n## boot.ci(boot.out = ba)\n## \n## Intervals : \n## Level      Normal              Basic         \n## 95%   ( 0.6261,  0.8364 )   ( 0.6314,  0.8479 )  \n## \n## Level     Percentile            BCa          \n## 95%   ( 0.6148,  0.8313 )   ( 0.6048,  0.8228 )  \n## Calculations and Intervals on Original Scale\n\n4种计算方法的置信区间都有了。\nOVER！",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>bootstrap ROC/AUC</span>"
    ]
  },
  {
    "objectID": "cindex.html",
    "href": "cindex.html",
    "title": "25  C-index的计算",
    "section": "",
    "text": "25.1 logistic回归\n今天学习C-index的4种计算方法，在二分类变量中，C-statistic就是AUC，二者在数值上是一样的。\n使用lowbirth数据集，这个数据集是关于低出生体重儿是否会死亡的数据集，其中dead这一列是结果变量，0代表死亡，1代表存活，其余列都是预测变量（获取lowbirth数据请在公众号：医学和生信笔记 后台回复20220520，或者在粉丝qq群文件自取）。\n我们首先对这个数据做一些预处理（参考：Chapter 7）\nrm(list = ls())\nlowbirth &lt;- read.csv(\"./datasets/lowbirth.csv\")\n\nlibrary(dplyr)\n\ntmp &lt;- lowbirth %&gt;% \n  mutate(across(where(is.character),as.factor),\n         vent = factor(vent),\n         #dead = factor(dead), 下面介绍的方法2不能是因子型，所以不转换了\n         race = case_when(race %in% \n                            c(\"native American\",\"oriental\") ~ \"other\",\n                          .default = race),\n         race = factor(race))\n\nstr(tmp)\n## 'data.frame':    565 obs. of  10 variables:\n##  $ birth   : num  81.5 81.6 81.6 81.6 81.6 ...\n##  $ lowph   : num  7.25 7.06 7.25 6.97 7.32 ...\n##  $ pltct   : int  244 114 182 54 282 153 229 182 361 378 ...\n##  $ race    : Factor w/ 3 levels \"black\",\"other\",..: 3 1 1 1 1 1 3 1 3 3 ...\n##  $ bwt     : int  1370 620 1480 925 1255 1350 1310 1110 1180 970 ...\n##  $ delivery: Factor w/ 2 levels \"abdominal\",\"vaginal\": 1 2 2 1 2 1 2 2 1 2 ...\n##  $ apg1    : int  7 1 8 5 9 4 6 6 6 2 ...\n##  $ vent    : Factor w/ 2 levels \"0\",\"1\": 1 2 1 2 1 1 2 1 1 2 ...\n##  $ sex     : Factor w/ 2 levels \"female\",\"male\": 1 1 2 1 1 1 2 2 2 1 ...\n##  $ dead    : int  0 1 0 1 0 0 0 0 0 1 ...",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>C-index的计算</span>"
    ]
  },
  {
    "objectID": "cindex.html#logistic回归",
    "href": "cindex.html#logistic回归",
    "title": "25  C-index的计算",
    "section": "",
    "text": "25.1.1 方法1：rms\n使用rms包构建模型，模型结果中Rank Discrim.下面的C就是C-Statistic，本模型中C-Statistic = 0.879。\n\nlibrary(rms)\n\ndd &lt;- datadist(tmp)\noptions(datadist=\"dd\")\n\nfit2 &lt;- lrm(dead ~ birth + lowph + pltct + bwt + vent + race,\n            data = tmp)\n\nfit2\n## Logistic Regression Model\n## \n## lrm(formula = dead ~ birth + lowph + pltct + bwt + vent + race, \n##     data = tmp)\n## \n##                        Model Likelihood      Discrimination    Rank Discrim.    \n##                              Ratio Test             Indexes          Indexes    \n## Obs           565    LR chi2     167.56      R2       0.432    C       0.879    \n##  0            471    d.f.             7      R2(7,565)0.247    Dxy     0.759    \n##  1             94    Pr(&gt; chi2) &lt;0.0001    R2(7,235.1)0.495    gamma   0.759    \n## max |deriv| 1e-06                            Brier    0.095    tau-a   0.211    \n## \n##            Coef    S.E.    Wald Z Pr(&gt;|Z|)\n## Intercept  39.5788 11.0070  3.60  0.0003  \n## birth      -0.1201  0.0914 -1.31  0.1890  \n## lowph      -4.1451  1.1881 -3.49  0.0005  \n## pltct      -0.0017  0.0019 -0.91  0.3644  \n## bwt        -0.0031  0.0006 -5.14  &lt;0.0001 \n## vent=1      2.7526  0.7436  3.70  0.0002  \n## race=other -1.1974  0.8448 -1.42  0.1564  \n## race=white -0.3377  0.2953 -1.14  0.2529\n\n\n\n25.1.2 方法2：Hmisc\n使用Hmisc包。结果中的C就是C-Statistic。\n\n# 先计算线性预测值\ntmp$predvalue&lt;-predict(fit2)\n\nlibrary(Hmisc)\nsomers2(tmp$predvalue, tmp$dead)\n##           C         Dxy           n     Missing \n##   0.8793875   0.7587749 565.0000000   0.0000000\n\n# 或者用\nrcorr.cens(tmp$predvalue, tmp$dead)\n##        C Index            Dxy           S.D.              n        missing \n##   8.793875e-01   7.587749e-01   3.417295e-02   5.650000e+02   0.000000e+00 \n##     uncensored Relevant Pairs     Concordant      Uncertain \n##   5.650000e+02   8.854800e+04   7.786800e+04   0.000000e+00\n\n\n\n25.1.3 方法3：ROCR\nROCR包计算AUC，logistic回归的AUC就是C-statistic。这种方法和SPSS得到的一样。\n\nlibrary(ROCR)\n\ntmp$predvalue&lt;-predict(fit2)\n\n# 取出C-Statistics，和上面结果一样\npred &lt;- prediction(tmp$predvalue, tmp$dead)\n\nauc &lt;- round(performance(pred, \"auc\")@y.values[[1]],digits = 4)\nauc\n## [1] 0.8794\n\n这个包也是用来画ROC曲线常用的包，可以根据上面的结果直接画出ROC曲线，这里就不重复演示了。\n\n\n25.1.4 方法4：pROC\npROC包计算AUC，这个包也是画ROC曲线常用的R包，但是这个包在使用时需要注意，这部分内容会在后面详细介绍。\n\nlibrary(pROC)\n\n# 计算AUC，也就是C-statistic\nroc(tmp$dead, tmp$predvalue, legacy.axes = T, print.auc = T, print.auc.y = 45)\n## \n## Call:\n## roc.default(response = tmp$dead, predictor = tmp$predvalue, legacy.axes = T,     print.auc = T, print.auc.y = 45)\n## \n## Data: tmp$predvalue in 471 controls (tmp$dead 0) &lt; 94 cases (tmp$dead 1).\n## Area under the curve: 0.8794\n\n也是可以直接画法ROC曲线的，请参考前面的文章。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>C-index的计算</span>"
    ]
  },
  {
    "objectID": "cindex.html#cox回归",
    "href": "cindex.html#cox回归",
    "title": "25  C-index的计算",
    "section": "25.2 cox回归",
    "text": "25.2 cox回归\ncox回归的C-statistic可以用survival包计算，需要注意，生存分析的C-statistic和AUC是不一样的，生存分析的C指数一般是指Harrell’s C指数（Harrell就是rms包的作者，统计学大佬）。\n使用survival包自带的lung数据集进行演示。\n\nrm(list = ls())\nlibrary(survival)\nlibrary(dplyr)\n\ndf1 &lt;- lung %&gt;% \n  mutate(status=ifelse(status == 1,1,0))\n\nstr(df1)\n## 'data.frame':    228 obs. of  10 variables:\n##  $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n##  $ time     : num  306 455 1010 210 883 ...\n##  $ status   : num  0 0 1 0 0 1 0 0 0 0 ...\n##  $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n##  $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n##  $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n##  $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n##  $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n##  $ meal.cal : num  1175 1225 NA 1150 NA ...\n##  $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ...\n\nR语言自带的coxph函数即可给出C-index，非常简单：\n\ncox_fit1 &lt;- coxph(Surv(time, status) ~ age + sex + ph.ecog,\n              data = df1,x = T, y = T)\n\nsummary(cox_fit1)\n## Call:\n## coxph(formula = Surv(time, status) ~ age + sex + ph.ecog, data = df1, \n##     x = T, y = T)\n## \n##   n= 227, number of events= 63 \n##    (1 observation deleted due to missingness)\n## \n##             coef exp(coef) se(coef)      z Pr(&gt;|z|)  \n## age     -0.02193   0.97831  0.01496 -1.465   0.1428  \n## sex      0.63989   1.89626  0.26588  2.407   0.0161 *\n## ph.ecog -0.19941   0.81922  0.20708 -0.963   0.3356  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##         exp(coef) exp(-coef) lower .95 upper .95\n## age        0.9783     1.0222    0.9500     1.007\n## sex        1.8963     0.5274    1.1261     3.193\n## ph.ecog    0.8192     1.2207    0.5459     1.229\n## \n## Concordance= 0.584  (se = 0.042 )\n## Likelihood ratio test= 10.28  on 3 df,   p=0.02\n## Wald test            = 10.14  on 3 df,   p=0.02\n## Score (logrank) test = 10.43  on 3 df,   p=0.02\n\nConcordance就是C-statistic，本次示例中为0.584。\n也可以用以下代码提取结果：\n\nsummary(cox_fit1)$concordance\n##          C      se(C) \n## 0.58390352 0.04179314\n\n以上就是C-statistic的计算。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>C-index的计算</span>"
    ]
  },
  {
    "objectID": "cindex-compare.html",
    "href": "cindex-compare.html",
    "title": "26  C-index的比较",
    "section": "",
    "text": "26.1 二分类资料C-index的比较\n二分类资料的AUC和C-index是一样的，所以可以参考Chapter 23关于ROC曲线的显著性检验。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>C-index的比较</span>"
    ]
  },
  {
    "objectID": "cindex-compare.html#生存资料c-index的比较",
    "href": "cindex-compare.html#生存资料c-index的比较",
    "title": "26  C-index的比较",
    "section": "26.2 生存资料C-index的比较",
    "text": "26.2 生存资料C-index的比较\n可以使用compareC包，专门用来比较生存资料的C-index。\n\nrm(list = ls())\nlibrary(compareC)\n\n还是用之前推文的数据，获取数据可以查看历史推文。\n\nload(file = \"./datasets/timeROC.RData\")\nstr(df2)\n## 'data.frame':    297 obs. of  8 variables:\n##  $ event    : num  0 0 1 0 0 1 0 0 0 0 ...\n##  $ age      : int  59 63 65 73 59 66 56 42 61 48 ...\n##  $ riskScore: num  -0.249 -0.511 -0.211 -0.427 0.279 ...\n##  $ futime   : num  3.03 1.16 1.82 1.52 1.34 ...\n##  $ gender   : num  2 2 2 1 2 2 1 2 2 2 ...\n##  $ t        : num  4 4 4 3 3 3 5 3 NA 4 ...\n##  $ n        : num  1 5 1 1 1 1 3 1 NA 1 ...\n##  $ m        : num  1 1 1 1 1 3 1 1 3 3 ...\n\n只要提供4个参数：time，status，第一个指标，第二个指标，即可。\n\ncompareC(df2$futime,\n         df2$event,\n         df2$riskScore,\n         df2$age\n         )\n## $est.c\n##       Cxy       Cxz \n## 0.3383690 0.3894508 \n## \n## $est.diff_c\n## [1] -0.05108181\n## \n## $est.vardiff_c\n## [1] 0.002124315\n## \n## $est.varCxy\n## [1] 0.001046384\n## \n## $est.varCxz\n## [1] 0.00112578\n## \n## $est.cov\n## [1] 2.392402e-05\n## \n## $zscore\n## [1] -1.108299\n## \n## $pval\n## [1] 0.2677329\n\n第1行给出了2个C指数；第2行是2个C指数相减的差值；第3行是2个C指数方差相减的差值；第4、5行是方差；第6行是协方差；第7、8行是z值和p值。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>C-index的比较</span>"
    ]
  },
  {
    "objectID": "cindex-compare.html#两个cox模型的比较",
    "href": "cindex-compare.html#两个cox模型的比较",
    "title": "26  C-index的比较",
    "section": "26.3 两个cox模型的比较",
    "text": "26.3 两个cox模型的比较\n下面再多说一点两个cox模型的比较，也是很简单的，方差分析即可，使用anova()函数。\n我们用lung数据集进行演示。\n\nlibrary(survival)\nlibrary(dplyr)\n\ndf1 &lt;- lung %&gt;% \n  mutate(status=ifelse(status == 1,1,0))\n\n建立两个cox模型：\n\ncox_fit1 &lt;- coxph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno,\n                  data = df1,x = T, y = T)\n\ncox_fit2 &lt;- coxph(Surv(time, status) ~ ph.ecog + ph.karno + pat.karno,\n                  data = df1,x = T, y = T)\n\n直接使用anova()即可：\n\nanova(cox_fit1,cox_fit2)\n## Analysis of Deviance Table\n##  Cox model: response is  Surv(time, status)\n##  Model 1: ~ age + sex + ph.ecog + ph.karno + pat.karno\n##  Model 2: ~ ph.ecog + ph.karno + pat.karno\n##    loglik  Chisq Df Pr(&gt;|Chi|)  \n## 1 -257.97                       \n## 2 -261.94 7.9486  2    0.01879 *\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nrms包也带了一个lrtest()函数，也是直接构建两个cph模型即可进行比较，简单演示一下。\n\nsuppressMessages(library(rms))\ndd &lt;- datadist(lung)\noptions(datadist=\"dd\")\n\ncox_fit1 &lt;- cph(Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno,\n                data = df1,x = T, y = T)\n\ncox_fit2 &lt;- cph(Surv(time, status) ~ ph.ecog + ph.karno + pat.karno,\n                data = df1,x = T, y = T)\n\nlrtest(cox_fit1,cox_fit2)\n## \n## Model 1: Surv(time, status) ~ age + sex + ph.ecog + ph.karno + pat.karno\n## Model 2: Surv(time, status) ~ ph.ecog + ph.karno + pat.karno\n## \n## L.R. Chisq       d.f.          P \n## 7.94861288 2.00000000 0.01879233\n\n可以看到P值是一样的~",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>C-index的比较</span>"
    ]
  },
  {
    "objectID": "nri.html",
    "href": "nri.html",
    "title": "27  净重分类指数NRI",
    "section": "",
    "text": "27.1 二分类模型的NRI",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>净重分类指数NRI</span>"
    ]
  },
  {
    "objectID": "nri.html#二分类模型的nri",
    "href": "nri.html#二分类模型的nri",
    "title": "27  净重分类指数NRI",
    "section": "",
    "text": "27.1.1 nricens\n首先我们加载R包和数据。\n使用survival包中的pbc数据集用于演示，这是一份关于原发性硬化性胆管炎的数据，其实是一份用于生存分析的数据，是有时间变量的，但是这里我们用于演示分类模型，只要不使用time这一列就可以了。\n\n#install.packages(\"nricens\") # 安装R包\nlibrary(nricens)\nlibrary(survival)\n\n# 只使用部分数据\ndat &lt;- pbc[1:312,] \ndat &lt;- dat[dat$time &gt; 2000 | (dat$time &lt; 2000 & dat$status == 2), ]\n\nstr(dat) # 数据长这样\n## 'data.frame':    232 obs. of  20 variables:\n##  $ id      : int  1 2 3 4 6 8 9 10 11 12 ...\n##  $ time    : int  400 4500 1012 1925 2503 2466 2400 51 3762 304 ...\n##  $ status  : int  2 0 2 2 2 2 2 2 2 2 ...\n##  $ trt     : int  1 1 1 1 2 2 1 2 2 2 ...\n##  $ age     : num  58.8 56.4 70.1 54.7 66.3 ...\n##  $ sex     : Factor w/ 2 levels \"m\",\"f\": 2 2 1 2 2 2 2 2 2 2 ...\n##  $ ascites : int  1 0 0 0 0 0 0 1 0 0 ...\n##  $ hepato  : int  1 1 0 1 1 0 0 0 1 0 ...\n##  $ spiders : int  1 1 0 1 0 0 1 1 1 1 ...\n##  $ edema   : num  1 0 0.5 0.5 0 0 0 1 0 0 ...\n##  $ bili    : num  14.5 1.1 1.4 1.8 0.8 0.3 3.2 12.6 1.4 3.6 ...\n##  $ chol    : int  261 302 176 244 248 280 562 200 259 236 ...\n##  $ albumin : num  2.6 4.14 3.48 2.54 3.98 4 3.08 2.74 4.16 3.52 ...\n##  $ copper  : int  156 54 210 64 50 52 79 140 46 94 ...\n##  $ alk.phos: num  1718 7395 516 6122 944 ...\n##  $ ast     : num  137.9 113.5 96.1 60.6 93 ...\n##  $ trig    : int  172 88 55 92 63 189 88 143 79 95 ...\n##  $ platelet: int  190 221 151 183 NA 373 251 302 258 71 ...\n##  $ protime : num  12.2 10.6 12 10.3 11 11 11 11.5 12 13.6 ...\n##  $ stage   : int  4 3 4 4 3 3 2 4 4 4 ...\ndim(dat) # 232 20\n## [1] 232  20\n\n然后就是准备计算NRI所需要的各个参数。\n\n# 定义结局事件，0是存活，1是死亡\nevent &lt;- ifelse(dat$time &lt; 2000 & dat$status == 2, 1, 0)\n\n# 两个只由预测变量组成的矩阵\nz.std &lt;- as.matrix(subset(dat, select = c(age, bili, albumin)))\nz.new &lt;- as.matrix(subset(dat, select = c(age, bili, albumin, protime)))\n\n# 建立2个模型用于比较\nmstd &lt;- glm(event ~ age + bili + albumin, family = binomial(), \n            data = dat, x=TRUE)\nmnew &lt;- glm(event ~ age + bili + albumin + protime, family = binomial(), \n            data = dat, x=TRUE)\n\n# 取出模型预测概率\np.std &lt;- mstd$fitted.values\np.new &lt;- mnew$fitted.values\n\n\n\n\n\n\n\n提示\n\n\n\n在建立模型时可以选择任何能够计算概率的模型，并不一定需要是逻辑回归模型，随机森林、支持向量机等机器学习模型也都可以的。\n\n\n然后就是计算NRI，对于二分类变量，使用nribin()函数，这个函数提供了3种参数使用组合，任选一种都可以计算出来（结果一样），以下3组参数任选1组即可。 - mdl.std和mdl.new - event, z.std, z.new - event, p.std, p.new\n我个人更推荐使用第3组参数，只需要提供结局变量和模型的预测概率即可，适用范围更广，其他模型（比如随机森林、支持向量机等）的概率也可以用。\n\n# 这3种方法算出来都是一样的结果\n\n# 两个模型\nnribin(mdl.std = mstd, mdl.new = mnew, \n       cut = c(0.3,0.7), \n       niter = 500, \n       updown = 'category')\n\n# 结果变量 + 两个只有预测变量的矩阵\nnribin(event = event, z.std = z.std, z.new = z.new, \n       cut = c(0.3,0.7), \n       niter = 500, \n       updown = 'category')\n\n## 结果变量 + 两个模型得到的预测概率\nnribin(event = event, p.std = p.std, p.new = p.new, \n       cut = c(0.3,0.7), \n       niter = 500, \n       updown = 'category')\n\n其中，cut是判断风险高低的阈值，我们使用了0.3,0.7，代表0-0.3是低风险，0.3-0.7是中风险，0.7-1是高风险，这个阈值是自己设置的，大家根据经验或者文献设置即可。\nniter是使用bootstrap法进行重抽样的次数，默认是1000。\nupdown参数，当设置为category时，表示使用低、中、高风险这种方式；当设置为diff时，此时cut的取值只能设置1个，比如设置0.2，即表示当新模型预测的风险和旧模型相差20%时，认为是重新分类。\n上面的代码运行后结果是这样的：\n\nUP and DOWN calculation:\n  #of total, case, and control subjects at t0:  232 88 144\n\n  Reclassification Table for all subjects:\n        New\nStandard &lt; 0.3 &lt; 0.7 &gt;= 0.7\n  &lt; 0.3    135     4      0\n  &lt; 0.7      1    31      4\n  &gt;= 0.7     0     2     55\n\n  Reclassification Table for case:\n        New\nStandard &lt; 0.3 &lt; 0.7 &gt;= 0.7\n  &lt; 0.3     14     0      0\n  &lt; 0.7      0    18      3\n  &gt;= 0.7     0     1     52\n\n  Reclassification Table for control:\n        New\nStandard &lt; 0.3 &lt; 0.7 &gt;= 0.7\n  &lt; 0.3    121     4      0\n  &lt; 0.7      1    13      1\n  &gt;= 0.7     0     1      3\n\nNRI estimation:\nPoint estimates:\n                  Estimate\nNRI            0.001893939\nNRI+           0.022727273\nNRI-          -0.020833333\nPr(Up|Case)    0.034090909\nPr(Down|Case)  0.011363636\nPr(Down|Ctrl)  0.013888889\nPr(Up|Ctrl)    0.034722222\n\nNow in bootstrap..\n\nPoint & Interval estimates:\n                  Estimate   Std.Error        Lower       Upper\nNRI            0.001893939 0.027816095 -0.053995513 0.055354449\nNRI+           0.022727273 0.021564394 -0.019801980 0.065789474\nNRI-          -0.020833333 0.017312438 -0.058823529 0.007518797\nPr(Up|Case)    0.034090909 0.019007629  0.000000000 0.072164948\nPr(Down|Case)  0.011363636 0.010924271  0.000000000 0.039603960\nPr(Down|Ctrl)  0.013888889 0.009334685  0.000000000 0.035211268\nPr(Up|Ctrl)    0.034722222 0.014716046  0.006993007 0.066176471\n\n首先是3个重分类表格，第一个是所有患者的，第2个是case（结局为1）组的，第3个是control（结局为2）组的，有了这3个表格，我们可以根据之前的介绍，自己计算NRI。\ncase组（n=88）：\n\n重新分对的：3个\n重新分错的：1个\n净重分类：3-1=2\n净重分类的比例是：2/88=0.022727273\n\ncontrol组（n=144）：\n\n重新分对的：2个\n重新分错的：5个\n净重分类：2-5=-3\n净重分类的比例是：-3/144=-0.020833333\n相加NRI=2/88 + (-3/144) = 0.001893939 绝对NRI=（2-3）/232=-0.000431\n这个结果和上面的结果（也就是中间的Point-estimates部分）是完全一样的，而且上面的结果只给出了相加NRI，没有绝对NRI。\n最后是做了500次bootstrap后得到的估计值，并且有标准误和可信区间。\n最后还会得到一张图：\n\n这张图中的虚线对应的坐标，就是我们在cut中设置的阈值，这张图对应的是上面结果中的第一个重分类表格，反应的是总体的情况，case是结果为1的组，也就是发生结局的组，control是结果为0的组，也就是未发生结局的组。\nP值没有直接给出，但是可以自己计算。\n\n# 计算P值\nz &lt;- abs(0.001893939/0.027816095)\np &lt;- (1 - pnorm(z))*2\np\n## [1] 0.9457157\n\n以上是训练集的NRI，那么测试集（验证集，外部验证集）的NRI如何实现呢？很简单，只要拿到测试集（验证集，外部验证集）的概率即可。\n我们先随机建立一个测试集（验证集，外部验证集）：\n\n# 取前100行作为测试集，这个方法是不正规的哈\ntestset &lt;- dat[1:100,]\n\n# 计算测试集的概率\np.std_test &lt;- predict(mstd, newdata = testset,type = \"response\")\np.new_test &lt;- predict(mnew, newdata = testset,type = \"response\")\n\n然后准备下测试集（验证集，外部验证集）的结果变量，就可以计算NRI了：\n\nevent_test &lt;- ifelse(testset$time &lt; 2000 & testset$status == 2, 1, 0)\n## 结果变量 + 两个模型得到的预测概率\nnribin(event = event_test, p.std = p.std_test, p.new = p.new_test, \n       cut = c(0.3,0.7), \n       niter = 500, \n       updown = 'category')\n\n结果就不展示了，结果解读也是和测试集（验证集，外部验证集）完全一样的。\n\n\n27.1.2 PredictABEL\nPredictABEL只能计算二分类模型的NRI，除此之外，它还会自动给出IDI。\n\n#install.packages(\"PredictABEL\") #安装R包\nlibrary(PredictABEL)  \n\n# 取出模型预测概率，这个包只能用预测概率计算\np.std = mstd$fitted.values\np.new = mnew$fitted.values \n\n然后就是计算NRI：\n\ndat$event &lt;- event\n\nreclassification(data = dat,\n                 cOutcome = 21, # 结果变量在哪一列\n                 predrisk1 = p.std,\n                 predrisk2 = p.new,\n                 cutoff = c(0,0.3,0.7,1)\n                 )\n##  _________________________________________\n##  \n##      Reclassification table    \n##  _________________________________________\n## \n##  Outcome: absent \n##   \n##              Updated Model\n## Initial Model [0,0.3) [0.3,0.7) [0.7,1]  % reclassified\n##     [0,0.3)       121         4       0               3\n##     [0.3,0.7)       1        13       1              13\n##     [0.7,1]         0         1       3              25\n## \n##  \n##  Outcome: present \n##   \n##              Updated Model\n## Initial Model [0,0.3) [0.3,0.7) [0.7,1]  % reclassified\n##     [0,0.3)        14         0       0               0\n##     [0.3,0.7)       0        18       3              14\n##     [0.7,1]         0         1      52               2\n## \n##  \n##  Combined Data \n##   \n##              Updated Model\n## Initial Model [0,0.3) [0.3,0.7) [0.7,1]  % reclassified\n##     [0,0.3)       135         4       0               3\n##     [0.3,0.7)       1        31       4              14\n##     [0.7,1]         0         2      55               4\n##  _________________________________________\n## \n##  NRI(Categorical) [95% CI]: 0.0019 [ -0.0551 - 0.0589 ] ; p-value: 0.94806 \n##  NRI(Continuous) [95% CI]: 0.0391 [ -0.2238 - 0.3021 ] ; p-value: 0.77048 \n##  IDI [95% CI]: 0.0044 [ -0.0037 - 0.0126 ] ; p-value: 0.28396\n\n这个结果首先也是3个重分类表格，下面是NRI和IDI，第一行NRI(Categorical)的结果和nricens的结果是一样的，也是相加净重分类指数，也同时给出了P值。最后一行还给出了IDI和P值。\n测试集的计算毫无难度，也是只要提供测试集数据以及相应的概率即可，这里就不再重复演示了。\n两个包算是各有优劣吧，大家可以自由选择。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>净重分类指数NRI</span>"
    ]
  },
  {
    "objectID": "nri.html#生存模型的nri",
    "href": "nri.html#生存模型的nri",
    "title": "27  净重分类指数NRI",
    "section": "27.2 生存模型的NRI",
    "text": "27.2 生存模型的NRI\n还是使用survival包中的pbc数据集用于演示，这次要构建生存分析模型，因此我们要使用time这一列了。\n\n27.2.1 nricens\n加载数据和R包：\n\nrm(list = ls())\nlibrary(nricens)\nlibrary(survival)\n\ndat &lt;- pbc[1:312,]\ndat$status &lt;- ifelse(dat$status==2, 1, 0) # 0表示活着，1表示死亡\n\n然后准备所需参数：\n\n# 两个只由预测变量组成的矩阵\nz.std &lt;- as.matrix(subset(dat, select = c(age, bili, albumin)))\nz.new &lt;- as.matrix(subset(dat, select = c(age, bili, albumin, protime)))\n\n# 建立2个cox模型，建立其他模型也可以，只要能计算概率就行\nmstd &lt;- coxph(Surv(time,status) ~ age + bili + albumin, data = dat, x=TRUE)\nmnew &lt;- coxph(Surv(time,status) ~ age + bili + albumin + protime, data = dat, x=TRUE)\n\n# 计算在2000天的模型预测的生存概率\np.std &lt;- get.risk.coxph(mstd, t0=2000)\np.new &lt;- get.risk.coxph(mnew, t0=2000)\n\n\n\n\n\n\n\n提示\n\n\n\n在建立模型时可以选择任何能够计算概率的模型，并不一定需要是cox回归模型，随机生存森林、生存支持向量机等机器学习模型也都可以的。\n\n\n然后就是计算NRI，但是要注意，生存模型的NRI只能选择计算某一个时间点的NRI，比如计算1年的NRI，计算3年的NRI这种。\n\nnricens(mdl.std= mstd, mdl.new = mnew, \n        t0 = 2000, \n        cut = c(0.3, 0.7),\n        niter = 1000, \n        updown = 'category')\n\nUP and DOWN calculation:\n  #of total, case, and control subjects at t0:  312 88 144\n\n  Reclassification Table for all subjects:\n        New\nStandard &lt; 0.3 &lt; 0.7 &gt;= 0.7\n  &lt; 0.3    202     7      0\n  &lt; 0.7     13    53      6\n  &gt;= 0.7     0     0     31\n\n  Reclassification Table for case:\n        New\nStandard &lt; 0.3 &lt; 0.7 &gt;= 0.7\n  &lt; 0.3     19     3      0\n  &lt; 0.7      3    32      4\n  &gt;= 0.7     0     0     27\n\n  Reclassification Table for control:\n        New\nStandard &lt; 0.3 &lt; 0.7 &gt;= 0.7\n  &lt; 0.3    126     3      0\n  &lt; 0.7      5     7      2\n  &gt;= 0.7     0     0      1\n\nNRI estimation by KM estimator:\n\nPoint estimates:\n                Estimate\nNRI           0.05377635\nNRI+          0.03748660\nNRI-          0.01628974\nPr(Up|Case)   0.07708938\nPr(Down|Case) 0.03960278\nPr(Down|Ctrl) 0.04256352\nPr(Up|Ctrl)   0.02627378\n\nNow in bootstrap..\n\nPoint & Interval estimates:\n                Estimate        Lower      Upper\nNRI           0.05377635 -0.082230381 0.16058172\nNRI+          0.03748660 -0.084245197 0.13231776\nNRI-          0.01628974 -0.030861213 0.06753616\nPr(Up|Case)   0.07708938  0.000000000 0.19102291\nPr(Down|Case) 0.03960278  0.000000000 0.15236016\nPr(Down|Ctrl) 0.04256352  0.004671535 0.09863170\nPr(Up|Ctrl)   0.02627378  0.006400463 0.05998424\n\n\n结果的解读以及和分类模型的一模一样，这里就不再重复了。\n测试集（验证集，外部验证集）也是只要拿到概率就好了，下面演示下。\n首先随机建立一个测试集：\n\n# 取前100行作为测试集，这个方法并不正规哈\ntestset &lt;- dat[1:100,]\n\n# 获取测试集在2000天时的生存概率\np.std_test &lt;- 1-c((summary(survfit(mstd, newdata=testset), times=2000)$surv))\np.new_test &lt;- 1-c((summary(survfit(mnew, newdata=testset), times=2000)$surv))\n\n然后计算NRI即可：\n\nnricens(time = testset$time, event = testset$status,\n        p.std = p.std_test, p.new = p.new_test,\n        t0 = 2000, \n        cut = c(0.3, 0.7),\n        niter = 1000, \n        updown = 'category')\n\n结果解读是一模一样的，所以就不重复了。\n\n\n27.2.2 survNRI\nsurvNRI不在CRAN上，可以通过github安装或者下载到本地安装，这个包的作者和rmda的作者是同一个人。\n\n# 安装R包\ndevtools::install_github(\"mdbrown/survNRI\")\n\n加载R包并使用，还是用上面的pbc数据集。\n\nrm(list = ls())\nlibrary(survNRI)\nlibrary(survival)\n\n# 使用部分数据\ndat &lt;- pbc[1:312,]\ndat$status &lt;- ifelse(dat$status==2, 1, 0) # 0表示活着，1表示死亡\n\n下面就是计算NRI，时间点我们选择2000天，你可以任意选择你感兴趣的时间点。注意这个包计算NRI就不能只提供概率了，所以对于随机生存森林这种机器学习模型就不行了。\n\nres &lt;- survNRI(time  = \"time\", event = \"status\", \n        model1 = c(\"age\", \"bili\", \"albumin\"), # 模型1的自变量\n        model2 = c(\"age\", \"bili\", \"albumin\", \"protime\"), # 模型2的自变量\n        data = dat, \n        predict.time = 2000, # 预测的时间点\n        method = \"all\", # 所有方法都计算\n        bootMethod = \"normal\",  \n        bootstraps = 500, # 重抽样次数\n        alpha = .05)\n\n下面是查看结果，这个结果很清晰，给出了5种方法得到的相加NRI，并且以表格的方式呈现。分别给出了死亡组和生存组的NRI以及总的NRI，并且也有可信区间：\n\nprint.survNRI(res)\n## \n##  Net Reclassification Improvement at time t = 2000\n##   with 95% bootstrap confidence intervals based on normal approximation.\n## \n##  method     |  event NRI              non-event NRI             NRI \n## -------------------------------------------------------------------------------\n##   KM        |  0.204 (-0.034,0.443)   0.319 (0.132,0.710)   0.523 (-0.046,0.888)   \n##   IPW       |  0.224 (-0.014,0.463)   0.327 (0.141,0.738)   0.552 (-0.036,0.915)   \n##   SmoothIPW |  0.196 (-0.041,0.434)   0.314 (0.129,0.696)   0.511 (-0.047,0.873)   \n##   SEM       |  0.075 (-0.116,0.266)   0.263 (0.084,0.518)   0.338 (-0.047,0.649)   \n##   Combined  |  0.196 (-0.041,0.434)   0.314 (0.129,0.696)   0.511 (-0.048,0.873)   \n## -------------------------------------------------------------------------------\n\n这个包在计算可信区间时有两种方法：正态近似法和分位数法，默认正态近似法。\n上面给出的5种方法，其实是估计生存概率的方法，并不是计算NRI的方法，NRI的计算方法都是一样的，无非就是相加NRI和绝对NRI。\n但是这个函数无法计算测试集（或者叫验证集、外部验证集都可以）的IDI，因为它不支持使用概率，如果你提供测试集的数据给它，也只是在测试集重新拟合模型而已，这样就不是原来的模型了。如果大家知道其他R包，欢迎告诉我。\n但是在实际使用时，NRI和IDI都是作为比较最终模型准确性的，所以通常都是只做一遍就可以了，不需要在训练集、验证集各来一遍。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>净重分类指数NRI</span>"
    ]
  },
  {
    "objectID": "idi.html",
    "href": "idi.html",
    "title": "28  综合判别改善指数IDI",
    "section": "",
    "text": "28.1 二分类模型的IDI\n二分类模型的NRI和IDI计算使用PredictABEL包，这个包在之前演示二分类模型的NRI时也演示过了，使用起来非常简单，可以同时给出NRI和IDI。\n使用survival包中的pbc数据集用于演示，这是一份关于原发性硬化性胆管炎的数据，其实是一份用于生存分析的数据，是有时间变量的，但是这里我们用于演示分类模型，只要不使用time这一列就可以了。\nrm(list = ls())\nlibrary(survival)\n\n# 只使用部分数据\ndat &lt;- pbc[1:312,] \ndat &lt;- dat[ dat$time &gt; 2000 | (dat$time &lt; 2000 & dat$status == 2), ]\n\nstr(dat) # 数据长这样\n## 'data.frame':    232 obs. of  20 variables:\n##  $ id      : int  1 2 3 4 6 8 9 10 11 12 ...\n##  $ time    : int  400 4500 1012 1925 2503 2466 2400 51 3762 304 ...\n##  $ status  : int  2 0 2 2 2 2 2 2 2 2 ...\n##  $ trt     : int  1 1 1 1 2 2 1 2 2 2 ...\n##  $ age     : num  58.8 56.4 70.1 54.7 66.3 ...\n##  $ sex     : Factor w/ 2 levels \"m\",\"f\": 2 2 1 2 2 2 2 2 2 2 ...\n##  $ ascites : int  1 0 0 0 0 0 0 1 0 0 ...\n##  $ hepato  : int  1 1 0 1 1 0 0 0 1 0 ...\n##  $ spiders : int  1 1 0 1 0 0 1 1 1 1 ...\n##  $ edema   : num  1 0 0.5 0.5 0 0 0 1 0 0 ...\n##  $ bili    : num  14.5 1.1 1.4 1.8 0.8 0.3 3.2 12.6 1.4 3.6 ...\n##  $ chol    : int  261 302 176 244 248 280 562 200 259 236 ...\n##  $ albumin : num  2.6 4.14 3.48 2.54 3.98 4 3.08 2.74 4.16 3.52 ...\n##  $ copper  : int  156 54 210 64 50 52 79 140 46 94 ...\n##  $ alk.phos: num  1718 7395 516 6122 944 ...\n##  $ ast     : num  137.9 113.5 96.1 60.6 93 ...\n##  $ trig    : int  172 88 55 92 63 189 88 143 79 95 ...\n##  $ platelet: int  190 221 151 183 NA 373 251 302 258 71 ...\n##  $ protime : num  12.2 10.6 12 10.3 11 11 11 11.5 12 13.6 ...\n##  $ stage   : int  4 3 4 4 3 3 2 4 4 4 ...\ndim(dat) # 232 20\n## [1] 232  20\n然后就是准备计算IDI所需要的各个参数。\n# 定义结局事件，0是存活，1是死亡\nevent &lt;- ifelse(dat$time &lt; 2000 & dat$status == 2, 1, 0)\n\n# 建立2个模型\nmstd &lt;- glm(event ~ age + bili + albumin, family = binomial(), data = dat, x=TRUE)\nmnew &lt;- glm(event ~ age + bili + albumin + protime, family = binomial(), data = dat, x=TRUE)\n\n# 取出模型预测概率\np.std &lt;- mstd$fitted.values\np.new &lt;- mnew$fitted.values\n接下来就是使用PredictABEL计算IDI：\n#install.packages(\"PredictABEL\") #安装R包\nlibrary(PredictABEL)  \n\ndat$event &lt;- event\n\nreclassification(data = dat,\n                 cOutcome = 21, # 结果变量在哪一列\n                 predrisk1 = p.std,\n                 predrisk2 = p.new,\n                 cutoff = c(0,0.3,0.7,1)\n                 )\n##  _________________________________________\n##  \n##      Reclassification table    \n##  _________________________________________\n## \n##  Outcome: absent \n##   \n##              Updated Model\n## Initial Model [0,0.3) [0.3,0.7) [0.7,1]  % reclassified\n##     [0,0.3)       121         4       0               3\n##     [0.3,0.7)       1        13       1              13\n##     [0.7,1]         0         1       3              25\n## \n##  \n##  Outcome: present \n##   \n##              Updated Model\n## Initial Model [0,0.3) [0.3,0.7) [0.7,1]  % reclassified\n##     [0,0.3)        14         0       0               0\n##     [0.3,0.7)       0        18       3              14\n##     [0.7,1]         0         1      52               2\n## \n##  \n##  Combined Data \n##   \n##              Updated Model\n## Initial Model [0,0.3) [0.3,0.7) [0.7,1]  % reclassified\n##     [0,0.3)       135         4       0               3\n##     [0.3,0.7)       1        31       4              14\n##     [0.7,1]         0         2      55               4\n##  _________________________________________\n## \n##  NRI(Categorical) [95% CI]: 0.0019 [ -0.0551 - 0.0589 ] ; p-value: 0.94806 \n##  NRI(Continuous) [95% CI]: 0.0391 [ -0.2238 - 0.3021 ] ; p-value: 0.77048 \n##  IDI [95% CI]: 0.0044 [ -0.0037 - 0.0126 ] ; p-value: 0.28396\nIDI在最后一行，同时给出了95%的可信区间和P值。重分类表格中，absent是event=0的结果，present是event=1的结果。\n这个包还是很全面的，如果你的模型只涉及分类，不涉及生存分析，那么在计算NRI和IDI时我推荐你使用这个包，因为使用简单，1行代码即可得到两个结果。\n测试集（验证集，外部验证集）的计算也是很简单，只要计算出概率就可以了。\n我们先随机建立一个测试集：\n# 取前100行作为测试集，这个方法是不正规的哈\ntestset &lt;- dat[1:100,]\n\n# 计算测试集的概率\np.std_test &lt;- predict(mstd, newdata = testset,type = \"response\")\np.new_test &lt;- predict(mnew, newdata = testset,type = \"response\")\n计算IDI即可：\nreclassification(data = testset,\n                 cOutcome = 21, # 结果变量在哪一列\n                 predrisk1 = p.std_test,\n                 predrisk2 = p.new_test,\n                 cutoff = c(0,0.3,0.7,1)\n                 )\n##  _________________________________________\n##  \n##      Reclassification table    \n##  _________________________________________\n## \n##  Outcome: absent \n##   \n##              Updated Model\n## Initial Model [0,0.3) [0.3,0.7) [0.7,1]  % reclassified\n##     [0,0.3)        49         1       0               2\n##     [0.3,0.7)       0         6       1              14\n##     [0.7,1]         0         0       3               0\n## \n##  \n##  Outcome: present \n##   \n##              Updated Model\n## Initial Model [0,0.3) [0.3,0.7) [0.7,1]  % reclassified\n##     [0,0.3)         6         0       0               0\n##     [0.3,0.7)       0         7       2              22\n##     [0.7,1]         0         1      24               4\n## \n##  \n##  Combined Data \n##   \n##              Updated Model\n## Initial Model [0,0.3) [0.3,0.7) [0.7,1]  % reclassified\n##     [0,0.3)        55         1       0               2\n##     [0.3,0.7)       0        13       3              19\n##     [0.7,1]         0         1      27               4\n##  _________________________________________\n## \n##  NRI(Categorical) [95% CI]: -0.0083 [ -0.1043 - 0.0876 ] ; p-value: 0.86483 \n##  NRI(Continuous) [95% CI]: -0.15 [ -0.5466 - 0.2466 ] ; p-value: 0.45847 \n##  IDI [95% CI]: 7e-04 [ -0.0091 - 0.0105 ] ; p-value: 0.89138\neasy！结果解读也是一模一样的。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>综合判别改善指数IDI</span>"
    ]
  },
  {
    "objectID": "idi.html#二分类模型的idi",
    "href": "idi.html#二分类模型的idi",
    "title": "28  综合判别改善指数IDI",
    "section": "",
    "text": "提示\n\n\n\n在建立模型时可以选择任何能够计算概率的模型，并不一定需要是逻辑回归模型，随机森林、支持向量机等机器学习模型也都可以的。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>综合判别改善指数IDI</span>"
    ]
  },
  {
    "objectID": "idi.html#生存资料的idi",
    "href": "idi.html#生存资料的idi",
    "title": "28  综合判别改善指数IDI",
    "section": "28.2 生存资料的IDI",
    "text": "28.2 生存资料的IDI\n生存资料的IDI使用survIDINRI包计算。\n\n# 安装R包\ninstall.packages(\"survIDINRI\")\n\n加载R包并使用，还是用上面的pbc数据集。\n\nrm(list = ls())\nlibrary(survival)\nlibrary(survIDINRI)\n\n# 使用部分数据\ndat &lt;- pbc[1:312,]\ndat$status &lt;- ifelse(dat$status==2, 1, 0) # 0表示活着，1表示死亡\n\nstr(dat)\n## 'data.frame':    312 obs. of  20 variables:\n##  $ id      : int  1 2 3 4 5 6 7 8 9 10 ...\n##  $ time    : int  400 4500 1012 1925 1504 2503 1832 2466 2400 51 ...\n##  $ status  : num  1 0 1 1 0 1 0 1 1 1 ...\n##  $ trt     : int  1 1 1 1 2 2 2 2 1 2 ...\n##  $ age     : num  58.8 56.4 70.1 54.7 38.1 ...\n##  $ sex     : Factor w/ 2 levels \"m\",\"f\": 2 2 1 2 2 2 2 2 2 2 ...\n##  $ ascites : int  1 0 0 0 0 0 0 0 0 1 ...\n##  $ hepato  : int  1 1 0 1 1 1 1 0 0 0 ...\n##  $ spiders : int  1 1 0 1 1 0 0 0 1 1 ...\n##  $ edema   : num  1 0 0.5 0.5 0 0 0 0 0 1 ...\n##  $ bili    : num  14.5 1.1 1.4 1.8 3.4 0.8 1 0.3 3.2 12.6 ...\n##  $ chol    : int  261 302 176 244 279 248 322 280 562 200 ...\n##  $ albumin : num  2.6 4.14 3.48 2.54 3.53 3.98 4.09 4 3.08 2.74 ...\n##  $ copper  : int  156 54 210 64 143 50 52 52 79 140 ...\n##  $ alk.phos: num  1718 7395 516 6122 671 ...\n##  $ ast     : num  137.9 113.5 96.1 60.6 113.2 ...\n##  $ trig    : int  172 88 55 92 72 63 213 189 88 143 ...\n##  $ platelet: int  190 221 151 183 136 NA 204 373 251 302 ...\n##  $ protime : num  12.2 10.6 12 10.3 10.9 11 9.7 11 11 11.5 ...\n##  $ stage   : int  4 3 4 4 3 3 3 3 2 4 ...\n\n构建参数需要的值：\n\n# 两个只由预测变量组成的矩阵\nz.std &lt;- as.matrix(subset(dat, select = c(age, bili, albumin)))\nz.new &lt;- as.matrix(subset(dat, select = c(age, bili, albumin, protime)))\n\n然后使用IDI.INF()函数计算IDI：\n\nres &lt;- IDI.INF(indata = dat[,c(2,3)],\n               covs0 = z.std,\n               covs1 = z.new,\n               t0 = 2000, # 时间点\n               npert = 500, # 重抽样次数\n               seed1 = 1234 # 设定重抽样的种子数\n               )\n\nIDI.INF.OUT(res) # 提取结果\n##     Est.  Lower Upper p-value\n## M1 0.020 -0.004 0.055   0.104\n## M2 0.202 -0.064 0.382   0.084\n## M3 0.011 -0.003 0.033   0.088\n\n\nm1：IDI的值，可信区间，P值\nm2：NRI的值，可信区间，P值\nm3：风险分数的中位数提升（median improvement of risk score），可信区间，p值。\n\n这里的NRI是连续型NRI，定义是当“1/2 NRI(&gt;0)”时的值，详细内容请参考该函数的帮助文档。\n计算IDI也是基于概率的，这个函数默认会帮你建立cox模型从而计算生存概率，所以这个函数计算的其实是两个cox模型的IDI。\n除此之外这个包还可以绘制图形，以图形的方式同时展示IDI、NRI、中位数提升分数：\n\nIDI.INF.GRAPH(res)\n\n\n\n\n\n\n\n\n红色面积减去蓝色面积得到的值就是IDI；两个黑点之间的垂直距离就是连续NRI；两个灰点之间的距离是中位数提升。\n由于这个函数计算IDI时不支持使用概率，只能使用原始数据，所以理论上这个函数无法计算测试集（验证集，外部验证集）的IDI，而且也不支持计算机器学习模型（比如随机生存森林、生存支持向量机等）的IDI。目前我并没有发现其他更好的R包，大家有知道的欢迎评论区留言。\n但是在实际使用时，NRI和IDI都是作为比较最终模型准确性的，所以通常都是只做一遍就可以了，不需要再训练集、验证集各来一遍。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>综合判别改善指数IDI</span>"
    ]
  },
  {
    "objectID": "calibration-logistic.html",
    "href": "calibration-logistic.html",
    "title": "29  分类模型校准曲线绘制",
    "section": "",
    "text": "29.1 准备数据\n使用lowbirth数据集，这个数据集是关于低出生体重儿能否存活的数据集，其中dead这一列是结果变量，0代表存活，1代表死亡，但是存活和死亡的比例严重失衡，存活的只有94个，死亡的有471个。其余列都是预测变量。该数据集没有缺失值，也没有高度相关的自变量。\n获取lowbirth数据请在公众号：医学和生信笔记，后台回复20220520。或者到粉丝QQ群文件自取。\nrm(list = ls())\nlowbirth &lt;- read.csv(\"./datasets/lowbirth.csv\")\n查看一下数据：\ndim(lowbirth) # 565行，10列\n## [1] 565  10\nstr(lowbirth) \n## 'data.frame':    565 obs. of  10 variables:\n##  $ birth   : num  81.5 81.6 81.6 81.6 81.6 ...\n##  $ lowph   : num  7.25 7.06 7.25 6.97 7.32 ...\n##  $ pltct   : int  244 114 182 54 282 153 229 182 361 378 ...\n##  $ race    : chr  \"white\" \"black\" \"black\" \"black\" ...\n##  $ bwt     : int  1370 620 1480 925 1255 1350 1310 1110 1180 970 ...\n##  $ delivery: chr  \"abdominal\" \"vaginal\" \"vaginal\" \"abdominal\" ...\n##  $ apg1    : int  7 1 8 5 9 4 6 6 6 2 ...\n##  $ vent    : int  0 1 0 1 0 0 1 0 0 1 ...\n##  $ sex     : chr  \"female\" \"female\" \"male\" \"female\" ...\n##  $ dead    : int  0 1 0 1 0 0 0 0 0 1 ...\n\n# 看下结果变量的比例\ntable(lowbirth$dead)\n## \n##   0   1 \n## 471  94\nrace这一列有4个类别，分别表示4个人种，但是东方人和美洲人太少了，这样会影响模型拟合，所以我们这两个人种变成other：\n# 其中两个人种人数太少了\ntable(lowbirth$race)\n## \n##           black native American        oriental           white \n##             325              14               4             222\n\n# 把人数太少的变成other\nlowbirth[lowbirth == \"oriental\"] &lt;- \"other\"\nlowbirth[lowbirth == \"native American\"] &lt;- \"other\"\n在R语言中一定要把分类变量因子型，这样才能在建模时进行正确的编码：\nlibrary(dplyr)\n\nlowbirth &lt;- lowbirth %&gt;% \n  mutate(across(where(is.character),as.factor)\n         #dead = factor(dead, levels=c(1,0),labels=c(\"live\",\"death\"))\n         )\nstr(lowbirth)\n## 'data.frame':    565 obs. of  10 variables:\n##  $ birth   : num  81.5 81.6 81.6 81.6 81.6 ...\n##  $ lowph   : num  7.25 7.06 7.25 6.97 7.32 ...\n##  $ pltct   : int  244 114 182 54 282 153 229 182 361 378 ...\n##  $ race    : Factor w/ 3 levels \"black\",\"other\",..: 3 1 1 1 1 1 3 1 3 3 ...\n##  $ bwt     : int  1370 620 1480 925 1255 1350 1310 1110 1180 970 ...\n##  $ delivery: Factor w/ 2 levels \"abdominal\",\"vaginal\": 1 2 2 1 2 1 2 2 1 2 ...\n##  $ apg1    : int  7 1 8 5 9 4 6 6 6 2 ...\n##  $ vent    : int  0 1 0 1 0 0 1 0 0 1 ...\n##  $ sex     : Factor w/ 2 levels \"female\",\"male\": 1 1 2 1 1 1 2 2 2 1 ...\n##  $ dead    : int  0 1 0 1 0 0 0 0 0 1 ...\n然后把数据划分为训练集、测试集，划分比例为7:3：\nset.seed(123)\nind &lt;- sample(1:nrow(lowbirth),nrow(lowbirth)*0.7)\n\ntrain_df &lt;- lowbirth[ind,]\ntest_df &lt;- lowbirth[- ind, ]\n\ndim(train_df)\n## [1] 395  10\ndim(test_df)\n## [1] 170  10\n接下来就是绘制校准曲线，首先我们会在训练集拟合模型，并使用bootstrap法进行内部验证，然后绘制内部验证的校准曲线，最后绘制测试集的校准曲线（其实就是外部验证集的校准曲线，但是我们数据量不多，只能这样演示了）。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>分类模型校准曲线绘制</span>"
    ]
  },
  {
    "objectID": "calibration-logistic.html#准备数据",
    "href": "calibration-logistic.html#准备数据",
    "title": "29  分类模型校准曲线绘制",
    "section": "",
    "text": "注释\n\n\n\n如果结果变量是分类变量，我建议把结果变量也变为因子型，并设定好因子的顺序，但是对于rms来说，最好是使用数值型，所以这里我没改。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>分类模型校准曲线绘制</span>"
    ]
  },
  {
    "objectID": "calibration-logistic.html#方法1rms",
    "href": "calibration-logistic.html#方法1rms",
    "title": "29  分类模型校准曲线绘制",
    "section": "29.2 方法1：rms",
    "text": "29.2 方法1：rms\nrms可以使用内部重抽样的方法绘制校准曲线，可以选择bootstrap法或者交叉验证法，下面我们选择500次bootstrap的内部验证方法：\n\nlibrary(rms)\n# 必须先打包数据\ndd &lt;- datadist(train_df)\noptions(datadist=\"dd\")\n\n# 建立模型\nfit2 &lt;- lrm(dead ~ birth + lowph + pltct + bwt + vent + race,\n            data = train_df, x=T,y=T)\n\n# 进行内部验证\ncal2 &lt;- calibrate(fit2, method='boot', B=500)\n\n\n29.2.1 训练集\n接下来就是画图，可以直接使用plot()函数：\n\nplot(cal2)\n\n\n\n\n\n\n\n## \n## n=395   Mean absolute error=0.009   Mean squared error=0.00013\n## 0.9 Quantile of absolute error=0.018\n\n也可以提取数据，自己画，以实现更多的细节控制：\n\nplot(cal2,\n     xlim = c(0,1),\n     ylim = c(0,1),\n     xlab = \"Prediced Probability\",\n     ylab = \"Observed Probability\",\n     cex.lab=1.2, cex.axis=1, cex.main=1.2, cex.sub=0.8,\n     #subtitles = FALSE,\n     legend = FALSE\n     ) \n## \n## n=395   Mean absolute error=0.009   Mean squared error=0.00013\n## 0.9 Quantile of absolute error=0.018\nlines(cal2[,c(\"predy\",\"calibrated.corrected\")], \n      type = 'l', #连线的类型，可以是\"p\",\"b\",\"o\"\n      lwd = 3, #连线的粗细\n      pch = 16, #点的形状，可以是0-20\n      col = \"#2166AC\") #连线的颜色\nlines(cal2[,c(\"predy\",\"calibrated.orig\")],type=\"l\",pch=16,lwd=3,col=\"tomato\")\nabline(0,1,\n       lty = 2, #对角线为虚线\n       lwd = 2, #对角线的粗细\n       col = \"#224444\") #对角线的颜色\nlegend(0.6,0.2,\n       c(\"Ideal\",\"Bias-corrected\",\"Apparent\"), \n       lty = c(2,1,1), \n       lwd = c(2,3,3), \n       col = c(\"black\",\"#2166AC\",\"tomato\"), \n       bty = \"n\"\n)\n\n\n\n\n\n\n\n\n这个图就是训练集的校准曲线，同时是经过500次bootstrap内部验证过的校准曲线。\n虚线是理想情况下的校准曲线，红线是模型的校准曲线，蓝线是经过校正的校准曲线。\n\n\n29.2.2 测试集\n然后是外部验证集的校准曲线：\n\n# 首先获取测试集的预测结果\nphat &lt;- predict(fit2, test_df, type = 'fitted')\n\n# 直接使用val.prob即可实现，statloc=F可不显示各种指标\n# 赋值给aa是为了减少输出信息\naa &lt;- val.prob(phat, test_df$dead,cex = 1)\n\n\n\n\n\n\n\n\n你可能在文献看见过训练集和测试集的校准曲线都是下面这张图展示的，训练集和测试集一样的图，实现方法也很简单。\n\n上面是测试集（即外部验证集）的校准曲线，我们也可以用同样的方法绘制训练集的校准曲线：\n\n# 获取训练集的预测结果\nphat_train &lt;- predict(fit2, train_df, type = 'fitted')\n\n# 直接使用val.prob即可实现\naa &lt;- val.prob(phat_train, train_df$dead,cex = 1)\n\n\n\n\n\n\n\n\n这张图就是内部验证集（或者叫训练集）的校准曲线了。\n这个图上有很多指标，其实就在函数的帮助文档里，我就是帮大家翻译一下：\n\nDxy：预测概率与实际概率的相关性，Dxy=2C-1\nC：ROC曲线下面积。\nR2：复决定系数，越大越好，最大是1。\nD：discrimination index，区分度指数，越大越好。\nU：unreliability index，不可靠指数，越小越好。\nQ：quality index，质量指数，越大越好。\nBrier：布里尔分数，预测概率与实际概率的均方误差，brier越小，校准效果越好。\nIntercept：截距，为0的时候最好。\nSlope：斜率，为1的时候最好。\nEmax：预测概率和实际概率的最大绝对差。\nE90：预测概率和实际概率差值的90%分位数\nEavg：预测概率和实际概率的平均差值。\nS:z：Z检验的z值\nS:p：Z检验的p值。p=0.842说明拟合效果好，P&gt;0.05说明拟合线和参考线无统计学差异，吻合度高。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>分类模型校准曲线绘制</span>"
    ]
  },
  {
    "objectID": "calibration-logistic.html#方法2riskregression",
    "href": "calibration-logistic.html#方法2riskregression",
    "title": "29  分类模型校准曲线绘制",
    "section": "29.3 方法2：riskRegression",
    "text": "29.3 方法2：riskRegression\nriskRegression也是非常好用的R包，使用起来也非常简单，可同时实现内部验证集和外部验证集的校准曲线绘制。\n首先是建立一个模型：\n\nfit2 &lt;- glm(dead ~ birth + lowph + pltct + bwt + vent + race,\n            data = train_df, family = binomial)\n\n\n29.3.1 训练集\n然后是使用Score()函数，最后使用plotCalibration()函数画图即可：\n\nlibrary(riskRegression)\n\nfit22 &lt;- Score(list(\"fit\"=fit2),\n               formula = dead ~ 1,\n               data = train_df,\n               metrics = c(\"auc\",\"brier\"),\n               #summary = c(\"risks\",\"IPA\",\"riskQuantile\",\"ibs\"),\n               plots = \"calibration\",\n               null.model = T,\n               conf.int = T,\n               B = 500,\n               M = 50 # 每组的人数\n               )\n\n# 画图\nplotCalibration(fit22,col=\"tomato\",\n                method = \"quantile\", # 默认是nne,quantile是分组计算的传统方法\n                xlab = \"Predicted Risk\",\n                ylab = \"Observerd RISK\",\n                brier.in.legend = F, # 不显示brier分数\n                auc.in.legend = F,  # 不显示auc值\n                bars = F)\n\n\n\n\n\n\n\n\n非常神奇的是，还可以用ggplot2来画！\n\nplotdata &lt;- plotCalibration(fit22,plot = F,method = \"quantile\"\n                            #bandwidth = 0.1\n                            )\n\nlibrary(ggplot2)\n\nggplot(plotdata$plotFrames$fit, aes(x=Pred,y=Obs))+\n  geom_line(color=\"tomato\",linewidth=1.5)+\n  scale_x_continuous(limits = c(0,1),name = \"Predicted Risk\")+\n  scale_y_continuous(limits = c(0,1),name = \"Observerd Risk\")+\n  geom_abline(slope = 1,intercept = 0,lty=2)+\n  geom_rug(color=\"grey\")+\n  theme_bw()\n\n\n\n\n\n\n\n\n除了这种校准曲线，riskRegression还提供另外一种预测风险的频率分布图（这个也就是前面提到过的预测概率直方图）：\n\nplotCalibration(fit22,\n                method = \"quantile\", # 默认是nne,quantile是分组计算的传统方法\n                bars = T, # 这里选择TRUE即可\n                q = 10 # 把风险分为10组\n                )\n\n\n\n\n\n\n\n\n横坐标是风险分组，被分成了10组，纵坐标是风险的频率，黑色表示实际的频率，灰色表示预测的频率，两者之间越接近说明模型预测的越准确。\n这个图也是可以用ggplot2自己绘制的。\n\nplotdata &lt;- plotCalibration(fit22,plot = F,method = \"quantile\",\n                            bars = T, \n                            q = 10 )\nplotdata &lt;- plotdata$plotFrames$fit\nplotdata$risk &lt;- rownames(plotdata)\n\nlibrary(tidyr)\nplotdata &lt;- plotdata %&gt;% \n  pivot_longer(cols = 1:2,names_to = \"type\",values_to = \"values\")\n\nlibrary(ggplot2)\n\nggplot(plotdata, aes(x=risk,y=values))+\n  geom_bar(position = \"dodge\",aes(fill=type),stat = \"identity\")+\n  theme(axis.text.x = element_text(hjust = 1,angle = 30))\n\n\n\n\n\n\n\n\n横坐标的大小和顺序还有点问题，大家需要的话可以自己慢慢调整，这里就不演示了。\n\n\n29.3.2 测试集\n下面是绘制测试集（外部验证集）的校准曲线。\n\nfit22 &lt;- Score(list(\"fit\"=fit2),\n               formula = dead ~ 1,\n               data = test_df, # 这里写测试集即可\n               metrics = c(\"auc\",\"brier\"),\n               #summary = c(\"risks\",\"IPA\",\"riskQuantile\",\"ibs\"),\n               plots = \"calibration\",\n               null.model = T,\n               conf.int = T,\n               B = 500,\n               M = 50\n               )\n\n# 画图\nplotCalibration(fit22,col=\"tomato\",\n                method = \"quantile\", # 默认是nne,quantile是分组计算的传统方法\n                xlab = \"Predicted Risk\",\n                ylab = \"Observerd RISK\",\n                brier.in.legend = F, # 不显示brier分数\n                auc.in.legend = F,  # 不显示auc值\n                bars = F)\n\n\n\n\n\n\n\n\n测试集也是可以绘制风险频率分布图的，同时也支持返回数据使用ggplot2绘制，这里就不再重复了。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>分类模型校准曲线绘制</span>"
    ]
  },
  {
    "objectID": "calibration-logistic.html#方法3tidymodels",
    "href": "calibration-logistic.html#方法3tidymodels",
    "title": "29  分类模型校准曲线绘制",
    "section": "29.4 方法3：tidymodels",
    "text": "29.4 方法3：tidymodels\n这个方法是我目前最推荐的方法，它是基于tidymodels实现的，主要优势有以下几个：\n\n支持所有的tidyverse语法，\n支持所有的分类模型，\n使用语法一致，\n使用的统计方法清晰\n\n我下面给大家展示一下随机森林模型，其他模型都是完全一致的语法，只要换个“引擎”即可，学习起来非常简单。\n\nlibrary(tidymodels) # 注意版本，我的是1.1.1\n\n# 先把结果变量变成因子型\nlowbirth$dead &lt;- factor(lowbirth$dead,levels=c(1,0),labels=c(\"death\",\"live\"))\n\n# 划分数据\nset.seed(123)\nsplit &lt;- initial_split(lowbirth, strata = \"dead\", prop = 0.7)\ntrain &lt;- training(split)\ntest &lt;- testing(split)\n\n# 重抽样方法选择，也就是内部验证方法\nset.seed(123)\nrs &lt;- bootstraps(train, times = 500)\n\n# 选择模型，选择预处理，建立工作流\nrf_spec &lt;- rand_forest(mode = \"classification\",engine = \"ranger\",trees = 500)\nrf_rec &lt;- recipe(dead ~ birth + lowph + pltct + bwt + vent + race,data = train)\nrf_wf &lt;- workflow(preprocessor = rf_rec, spec = rf_spec)\n\n# 开始建模\nrf_res &lt;- fit_resamples(rf_wf,\n                        resamples = rs,\n                        metrics = metric_set(roc_auc, sens, spec, mcc, f_meas, \n                                          j_index, brier_class),\n                        control = control_resamples(save_pred = T))\n\n查看模型结果,我在建模时同时选择了7个评价指标，所以结果也会同时展示出来：\n\ncollect_metrics(rf_res)\n## # A tibble: 7 × 6\n##   .metric     .estimator  mean     n  std_err .config             \n##   &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n## 1 brier_class binary     0.111   500 0.000591 Preprocessor1_Model1\n## 2 f_meas      binary     0.415   500 0.00388  Preprocessor1_Model1\n## 3 j_index     binary     0.287   500 0.00392  Preprocessor1_Model1\n## 4 mcc         binary     0.359   500 0.00394  Preprocessor1_Model1\n## 5 roc_auc     binary     0.835   500 0.00136  Preprocessor1_Model1\n## 6 sens        binary     0.337   500 0.00427  Preprocessor1_Model1\n## 7 spec        binary     0.950   500 0.00107  Preprocessor1_Model1\n\n所有指标都是通过500次bootstrap的内部重抽样得到的，并且同时给出了均值和标准差，很容易通过计算得到可信区间，比如95%的可信区间就是：均值±1.96*标准误：\n\n# 计算置信区间\ncollect_metrics(rf_res) %&gt;% \n  dplyr::select(1,3,5) %&gt;% \n  mutate(lower = mean - 1.96*std_err,\n         upper = mean + 1.96*std_err)\n## # A tibble: 7 × 5\n##   .metric      mean  std_err lower upper\n##   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1 brier_class 0.111 0.000591 0.109 0.112\n## 2 f_meas      0.415 0.00388  0.407 0.422\n## 3 j_index     0.287 0.00392  0.279 0.294\n## 4 mcc         0.359 0.00394  0.351 0.367\n## 5 roc_auc     0.835 0.00136  0.832 0.838\n## 6 sens        0.337 0.00427  0.328 0.345\n## 7 spec        0.950 0.00107  0.948 0.952\n\n\n29.4.1 训练集\n画校准曲线也只要1行代码即可，无缝衔接，而且是基于ggplot2绘制的，风格更加统一：\n\nlibrary(probably)\nlibrary(ggplot2)\n\n# 3种方法\ncal_plot_breaks(rf_res,num_breaks = 9)\n\n\n\n\n\n\n\ncal_plot_logistic(rf_res)\n\n\n\n\n\n\n\ncal_plot_windowed(rf_res)\n\n\n\n\n\n\n\n\n\n\n29.4.2 测试集\n以上是训练集的校准曲线，也就是内部验证的校准曲线，那么测试集（也就是外部验证集）的校准曲线如何绘制呢？\n首先要把训练好的模型应用到测试集上，获取测试集的预测结果：\n\npred_test &lt;- last_fit(rf_wf, split = split)\n\n# 查看模型在测试集的表现\ncollect_metrics(pred_test)\n## # A tibble: 3 × 4\n##   .metric     .estimator .estimate .config             \n##   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n## 1 accuracy    binary         0.860 Preprocessor1_Model1\n## 2 roc_auc     binary         0.836 Preprocessor1_Model1\n## 3 brier_class binary         0.108 Preprocessor1_Model1\n\n提取测试集的预测概率，并绘制校准曲线即可：\n\ntest %&gt;% dplyr::select(dead) %&gt;% \n  bind_cols(collect_predictions(pred_test) %&gt;% dplyr::select(.pred_death)) %&gt;% \n  cal_plot_breaks(dead, .pred_death,conf_level = 0.95) # 其他方法略\n\n\n\n\n\n\n\n\n是不是非常简单呢？\n除此之外，还有很多R包可以绘制校准曲线，比如caret、PredictABEL等，但是用的比较少，就不给大家在这里介绍了，caret绘制校准曲线介绍过了，可以在公众号后台回复caret获取相关推文。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>分类模型校准曲线绘制</span>"
    ]
  },
  {
    "objectID": "hosmer-lemeshow检验.html",
    "href": "hosmer-lemeshow检验.html",
    "title": "30  hosmer-lemeshow检验",
    "section": "",
    "text": "30.1 准备数据\n使用lowbirth数据集，这个数据集是关于低出生体重儿能否存活的数据集，其中dead这一列是结果变量，0代表存活，1代表死亡，但是存活和死亡的比例严重失衡，存活的只有94个，死亡的有471个。其余列都是预测变量。该数据集没有缺失值，也没有高度相关的自变量。\n获取lowbirth数据请在公众号：医学和生信笔记，后台回复20220520。或者到粉丝QQ群文件自取。\nrm(list = ls())\nlowbirth &lt;- read.csv(\"./datasets/lowbirth.csv\")\n查看一下数据：\ndim(lowbirth) # 565行，10列\n## [1] 565  10\nstr(lowbirth) \n## 'data.frame':    565 obs. of  10 variables:\n##  $ birth   : num  81.5 81.6 81.6 81.6 81.6 ...\n##  $ lowph   : num  7.25 7.06 7.25 6.97 7.32 ...\n##  $ pltct   : int  244 114 182 54 282 153 229 182 361 378 ...\n##  $ race    : chr  \"white\" \"black\" \"black\" \"black\" ...\n##  $ bwt     : int  1370 620 1480 925 1255 1350 1310 1110 1180 970 ...\n##  $ delivery: chr  \"abdominal\" \"vaginal\" \"vaginal\" \"abdominal\" ...\n##  $ apg1    : int  7 1 8 5 9 4 6 6 6 2 ...\n##  $ vent    : int  0 1 0 1 0 0 1 0 0 1 ...\n##  $ sex     : chr  \"female\" \"female\" \"male\" \"female\" ...\n##  $ dead    : int  0 1 0 1 0 0 0 0 0 1 ...\n\n# 看下结果变量的比例\ntable(lowbirth$dead)\n## \n##   0   1 \n## 471  94\nrace这一列有4个类别，分别表示4个人种，但是东方人和美洲人太少了，这样会影响模型拟合，所以我们这两个人种变成other：\n# 其中两个人种人数太少了\ntable(lowbirth$race)\n## \n##           black native American        oriental           white \n##             325              14               4             222\n\n# 把人数太少的变成other\nlowbirth[lowbirth == \"oriental\"] &lt;- \"other\"\nlowbirth[lowbirth == \"native American\"] &lt;- \"other\"\n在R语言中一定要把分类变量因子型，这样才能在建模时进行正确的编码：\nlibrary(dplyr)\n\nlowbirth &lt;- lowbirth %&gt;% \n  mutate(across(where(is.character),as.factor)\n         #dead = factor(dead, levels=c(1,0),labels=c(\"live\",\"death\"))\n         )\nstr(lowbirth)\n## 'data.frame':    565 obs. of  10 variables:\n##  $ birth   : num  81.5 81.6 81.6 81.6 81.6 ...\n##  $ lowph   : num  7.25 7.06 7.25 6.97 7.32 ...\n##  $ pltct   : int  244 114 182 54 282 153 229 182 361 378 ...\n##  $ race    : Factor w/ 3 levels \"black\",\"other\",..: 3 1 1 1 1 1 3 1 3 3 ...\n##  $ bwt     : int  1370 620 1480 925 1255 1350 1310 1110 1180 970 ...\n##  $ delivery: Factor w/ 2 levels \"abdominal\",\"vaginal\": 1 2 2 1 2 1 2 2 1 2 ...\n##  $ apg1    : int  7 1 8 5 9 4 6 6 6 2 ...\n##  $ vent    : int  0 1 0 1 0 0 1 0 0 1 ...\n##  $ sex     : Factor w/ 2 levels \"female\",\"male\": 1 1 2 1 1 1 2 2 2 1 ...\n##  $ dead    : int  0 1 0 1 0 0 0 0 0 1 ...",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>hosmer-lemeshow检验</span>"
    ]
  },
  {
    "objectID": "hosmer-lemeshow检验.html#准备数据",
    "href": "hosmer-lemeshow检验.html#准备数据",
    "title": "30  hosmer-lemeshow检验",
    "section": "",
    "text": "注释\n\n\n\n如果结果变量是分类变量，我建议把结果变量也变为因子型，并设定好因子的顺序，但是对于rms来说，最好是使用数值型，所以这里我没改。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>hosmer-lemeshow检验</span>"
    ]
  },
  {
    "objectID": "hosmer-lemeshow检验.html#方法1resourceselection",
    "href": "hosmer-lemeshow检验.html#方法1resourceselection",
    "title": "30  hosmer-lemeshow检验",
    "section": "30.2 方法1：ResourceSelection",
    "text": "30.2 方法1：ResourceSelection\n这个R包进行H-L检验应该是大家见的比较多的方法。\n首先是建立逻辑回归模型：\n\nmodel_glm &lt;- glm(dead ~ birth + lowph + pltct + bwt + vent + race,\n                 data = lowbirth, family = binomial)\n\n然后使用模型预测的概率，和模型的真是结果，就可以进行H-L检验了：\n\n# 加载R包\nlibrary(ResourceSelection)\n\n# hosmer-lemeshow 检验\nhoslem.test(model_glm$y, fitted(model_glm), g=10) # g=10表示分成10组\n## \n##  Hosmer and Lemeshow goodness of fit (GOF) test\n## \n## data:  model_glm$y, fitted(model_glm)\n## X-squared = 10.463, df = 8, p-value = 0.234\n\n只提取P值也可以，方便加在校准曲线图中：\n\np.hoslem &lt;- hoslem.test(model_glm$y, fitted(model_glm), g=10)$p.value\np.hoslem\n## [1] 0.2340365\n\n下面我们绘制一个校准曲线，并把H-L检验的结果放在图里：\n\nlibrary(rms)\n\n# 必须先打包数据\ndd &lt;- datadist(lowbirth)\noptions(datadist=\"dd\")\n\n# 构建 calibration\nfit &lt;- lrm(dead ~ birth + lowph + pltct + bwt + vent + race, \n           data = lowbirth,x = TRUE, y = TRUE)\ncal &lt;- calibrate(fit, method='boot', B=500)\n\n画图还是和上面一样，就是多了一个添加 hosmer-lemeshow P值的步骤。\n\nplot(cal,\n     xlim = c(0,1),\n     ylim = c(0,1),\n     xlab = \"Prediced Probability\",\n     ylab = \"Observed Probability\",\n     cex.lab=1.2, cex.axis=1, cex.main=1.2, cex.sub=0.8,\n     #subtitles = FALSE,\n     legend = FALSE\n     ) \n## \n## n=565   Mean absolute error=0.012   Mean squared error=0.00028\n## 0.9 Quantile of absolute error=0.032\nlines(cal[,c(\"predy\",\"calibrated.corrected\")], \n      type = 'l', #连线的类型，可以是\"p\",\"b\",\"o\"\n      lwd = 3, #连线的粗细\n      pch = 16, #点的形状，可以是0-20\n      col = \"#2166AC\") #连线的颜色\nlines(cal[,c(\"predy\",\"calibrated.orig\")],type=\"l\",pch=16,lwd=3,col=\"tomato\")\nabline(0,1,\n       lty = 2, #对角线为虚线\n       lwd = 2, #对角线的粗细\n       col = \"#224444\")#对角线的颜色\nlegend(0.6,0.2,\n       c(\"Ideal\",\"Bias-corrected\",\"Apparent\"), \n       lty = c(2,1,1), \n       lwd = c(2,3,3), \n       col = c(\"black\",\"#2166AC\",\"tomato\"), \n       bty = \"n\"\n)\ntext(0,0.9,bquote(\"Hosmer-Lemeshow \"~italic(P)~\" = \"~.(round(p.hoslem,3))),\n     adj = 0)",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>hosmer-lemeshow检验</span>"
    ]
  },
  {
    "objectID": "hosmer-lemeshow检验.html#方法2generalhoslem",
    "href": "hosmer-lemeshow检验.html#方法2generalhoslem",
    "title": "30  hosmer-lemeshow检验",
    "section": "30.3 方法2：generalhoslem",
    "text": "30.3 方法2：generalhoslem\n这个R包的使用方法和ResourceSelection完全一样，结果也是一样的：\n\nlibrary(generalhoslem)\n\nlogitgof(model_glm$y, fitted(model_glm), g=10, ord = F)\n## \n##  Hosmer and Lemeshow test (binary model)\n## \n## data:  model_glm$y, fitted(model_glm)\n## X-squared = 10.463, df = 8, p-value = 0.234",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>hosmer-lemeshow检验</span>"
    ]
  },
  {
    "objectID": "hosmer-lemeshow检验.html#方法3performance",
    "href": "hosmer-lemeshow检验.html#方法3performance",
    "title": "30  hosmer-lemeshow检验",
    "section": "30.4 方法3：performance",
    "text": "30.4 方法3：performance\n这个包非常强大，它属于easystats这个包的一部分，我在之前也介绍过：\n\n线性模型回归诊断图\n\n但是它只能对一些统计模型进行检验，不能对机器学习模型进行检验，而且在计算模型性能指标方面，和yardstick有很多重合，所以我平常还是用yardstick更多。\n\nlibrary(performance)\n\nperformance_hosmer(model_glm, n_bins = 10)\n## # Hosmer-Lemeshow Goodness-of-Fit Test\n## \n##   Chi-squared: 10.463\n##            df:  8    \n##       p-value:  0.234",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>hosmer-lemeshow检验</span>"
    ]
  },
  {
    "objectID": "hosmer-lemeshow检验.html#方法4predictabel",
    "href": "hosmer-lemeshow检验.html#方法4predictabel",
    "title": "30  hosmer-lemeshow检验",
    "section": "30.5 方法4：PredictABEL",
    "text": "30.5 方法4：PredictABEL\n这个包在计算NRI和IDI时使用过，非常强大，还可以绘制校准曲线并且进行H-L检验，只需要使用plotCalibration()函数即可。\n\nlibrary(PredictABEL)\n\n# 首先获得预测概率,和fitted(model_glm)完全一样\npredRisk &lt;- PredictABEL::predRisk(model_glm)\n\nrr &lt;- plotCalibration(data=lowbirth, cOutcome=10, #结果变量在数据的第几列\n                predRisk=predRisk, \n                groups=10)\n\n\n\n\n\n\n\n\n提取H-L检验的P值：\n\nrr$p_value\n## [1] 0.2805\n\n也是和其他方法不一样，建议别用这个结果。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>hosmer-lemeshow检验</span>"
    ]
  },
  {
    "objectID": "hosmer-lemeshow检验.html#方法5glmtoolbox",
    "href": "hosmer-lemeshow检验.html#方法5glmtoolbox",
    "title": "30  hosmer-lemeshow检验",
    "section": "30.6 方法5：glmtoolbox",
    "text": "30.6 方法5：glmtoolbox\n这个方法得到的结果与其他几种方法的结果都不一样，我没查看源码，不知道有啥区别，大家还是选择其他几个方法吧。\n\nlibrary(glmtoolbox)\n\nhltest(model_glm,verbose = F)$p.value\n## [1] \"0.3410089\"\n\n多种方法，任君选择，搭配校准曲线教程一起，食用更佳。\n公众号后台回复校准曲线集合获取合集。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>hosmer-lemeshow检验</span>"
    ]
  },
  {
    "objectID": "calibration-cox.html",
    "href": "calibration-cox.html",
    "title": "31  Cox回归校准曲线绘制",
    "section": "",
    "text": "31.1 准备数据\n使用自带数据lung数据集进行演示。\n这个是关于肺癌的生存数据，一共有228行，10列，其中time是生存时间，单位是天，status是生存状态，1是删失，2是死亡。其余变量是自变量，意义如下：\nlibrary(survival)\n\nrm(list = ls())\n\ndim(lung)\n## [1] 228  10\nstr(lung)\n## 'data.frame':    228 obs. of  10 variables:\n##  $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n##  $ time     : num  306 455 1010 210 883 ...\n##  $ status   : num  2 2 1 2 2 1 2 2 2 2 ...\n##  $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n##  $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n##  $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n##  $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n##  $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n##  $ meal.cal : num  1175 1225 NA 1150 NA ...\n##  $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ...\n大多数情况下都是使用1代表死亡，0代表删失，这个数据集用2代表死亡，但有的R包会报错，需要注意！\n我们这里给它改过来：\nlibrary(dplyr)\nlibrary(tidyr)\n\nlung &lt;- lung %&gt;% \n  mutate(status=ifelse(status == 2,1,0))\n\nstr(lung)\n## 'data.frame':    228 obs. of  10 variables:\n##  $ inst     : num  3 3 3 5 1 12 7 11 1 7 ...\n##  $ time     : num  306 455 1010 210 883 ...\n##  $ status   : num  1 1 0 1 1 0 1 1 1 1 ...\n##  $ age      : num  74 68 56 57 60 74 68 71 53 61 ...\n##  $ sex      : num  1 1 1 1 1 1 2 2 1 1 ...\n##  $ ph.ecog  : num  1 0 0 1 0 1 2 2 1 2 ...\n##  $ ph.karno : num  90 90 90 90 100 50 70 60 70 70 ...\n##  $ pat.karno: num  100 90 90 60 90 80 60 80 80 70 ...\n##  $ meal.cal : num  1175 1225 NA 1150 NA ...\n##  $ wt.loss  : num  NA 15 15 11 0 0 10 1 16 34 ...\n然后把数据划分为训练集、测试集，下面这个划分方法是错的哈，这个示例数据样本量太少了，我想让训练集和测试集样本量都尽量多一点，所以用了一个错误的方法进行演示：\nset.seed(123)\nind1 &lt;- sample(1:nrow(lung),nrow(lung)*0.7)\ntrain_df &lt;- lung[ind1,]\n\nset.seed(563435)\nind2 &lt;- sample(1:nrow(lung),nrow(lung)*0.7)\ntest_df &lt;- lung[ind2, ]\n\ndim(train_df)\n## [1] 159  10\ndim(test_df)\n## [1] 159  10",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Cox回归校准曲线绘制</span>"
    ]
  },
  {
    "objectID": "calibration-cox.html#准备数据",
    "href": "calibration-cox.html#准备数据",
    "title": "31  Cox回归校准曲线绘制",
    "section": "",
    "text": "inst：机构代码，对于我们这次建模没啥用\nage：年龄\nsex：1是男性，2是女性\nph.ecog：ECOG评分。0=无症状，1=有症状但完全可以走动，2=每天&lt;50%的时间在床上，3=在床上&gt;50%的时间但没有卧床，4=卧床不起\nph.karno：医生评的KPS评分，范围是0-100，得分越高，健康状况越好，越能忍受治疗给身体带来的副作用。\npat.karno：患者自己评的KPS评分\nmeal.cal：用餐时消耗的卡路里\nwt.loss：过去6个月的体重减少量，单位是磅",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Cox回归校准曲线绘制</span>"
    ]
  },
  {
    "objectID": "calibration-cox.html#方法1rms",
    "href": "calibration-cox.html#方法1rms",
    "title": "31  Cox回归校准曲线绘制",
    "section": "31.2 方法1：rms",
    "text": "31.2 方法1：rms\n\nlibrary(rms)\n\n# 必须先打包数据\ndd &lt;- datadist(train_df)\noptions(datadist = \"dd\")\nunits(train_df$time) &lt;- \"day\" # 单位设置为：天\n\n构建cox比例风险模型。rms可以使用内部重抽样的方法绘制校准曲线，可以选择bootstrap法或者交叉验证法，下面我们选择500次bootstrap的内部验证方法，计算时间点为第1年的校准曲线（样本太少，给警告了）：\n\n# 建立cox回归模型，时间点选择1年\ncoxfit1 &lt;- cph(Surv(time, status) ~ sex + ph.ecog + ph.karno + wt.loss,\n              data = train_df, x = T, y = T, surv = T,\n              time.inc = 100 # 100天\n              )\n\n# m=40表示以40个样本为1组，一般取4-6组，我们这个数据样本量太少了\n# u=100和上面的time.inc对应\ncal1 &lt;- calibrate(coxfit1, cmethod = \"KM\", method = \"boot\",\n                  u = 100, m = 40, B = 500) \n## Using Cox survival estimates at  100 days\n\n\n31.2.1 训练集\n接下来就是画图，可以直接使用plot()函数：\n\nplot(cal1)\n\n\n\n\n\n\n\n\n也可以提取数据，自己画，以实现更多的细节控制：\n\nplot(cal1,\n     lwd = 2, # 误差线粗细\n     lty = 1, # 误差线类型，可选0-6\n     errbar.col = c(\"#2166AC\"), # 误差线颜色\n     xlim = c(0.7,1),ylim= c(0.7,1), # 坐标轴范围\n     xlab = \"Prediced OS\",ylab = \"Observed OS\",\n     cex.lab=1.2, cex.axis=1, cex.main=1.2, cex.sub=0.6) # 字体大小\nlines(cal1[,c('mean.predicted',\"KM\")], \n      type = 'b', # 连线的类型，可以是\"p\",\"b\",\"o\"\n      lwd = 3, # 连线的粗细\n      pch = 16, # 点的形状，可以是0-20\n      col = \"tomato\") # 连线的颜色\nbox(lwd = 2) # 边框粗细\nabline(0,1,lty = 3, # 对角线为虚线\n       lwd = 2, # 对角线的粗细\n       col = \"grey70\" # 对角线的颜色\n       ) \n\n\n\n\n\n\n\n\n\n\n31.2.2 测试集\n然后是外部验证集的校准曲线：\n\n# 获取测试集的预测的生存概率，这一步有没有都行\nestimates &lt;- survest(coxfit1,newdata=test_df,times=100)$surv\n\nvs &lt;- val.surv(coxfit1, newdata = test_df,\n               S = Surv(test_df$time,test_df$status),\n               est.surv = estimates,# 这一步有没有都行\n               u = 100 # 时间点，也是选100天\n               )\nplot(vs)",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Cox回归校准曲线绘制</span>"
    ]
  },
  {
    "objectID": "calibration-cox.html#方法2riskregression",
    "href": "calibration-cox.html#方法2riskregression",
    "title": "31  Cox回归校准曲线绘制",
    "section": "31.3 方法2：riskRegression",
    "text": "31.3 方法2：riskRegression\n这个R包也非常好用，但是这种方法不能有缺失值，所以我先把缺失值去掉，然后再划分训练集和测试集，但是由于样本量太少，这里的划分方法是不正确的哈。\n\n# 删除缺失值\ndf2 &lt;- na.omit(lung)\n\n# 划分数据\nset.seed(123)\nind1 &lt;- sample(1:nrow(df2),nrow(df2)*0.9)\ntrain_df &lt;- df2[ind1,]\n\nset.seed(563435)\nind2 &lt;- sample(1:nrow(df2),nrow(df2)*0.9)\ntest_df &lt;- df2[ind2, ]\n\ndim(train_df)\n## [1] 150  10\ndim(test_df)\n## [1] 150  10\n\n# 构建模型\ncox_fit1 &lt;- coxph(Surv(time, status) ~ sex + ph.ecog + ph.karno,\n                  data = train_df,x = T, y = T)\n\n\n31.3.1 训练集\n\n# 画图\nlibrary(riskRegression)\nset.seed(1)\ncox_fit_s &lt;- Score(list(\"fit1\" = cox_fit1),\n               formula = Surv(time, status) ~ 1,\n               data = train_df,\n               plots = \"calibration\",\n               conf.int = T,\n               B = 500,\n               M = 50, # 每组的人数\n               times=c(100) # 时间点选100天\n               )\nplotCalibration(cox_fit_s,cens.method=\"local\",# 减少输出日志\n                xlab = \"Predicted Risk\",\n                ylab = \"Observerd RISK\")\n\n\n\n\n\n\n\n\n当然也是可以用ggplot2画图的。\n\n# 获取数据\ndata_all &lt;- plotCalibration(cox_fit_s,plot = F,cens.method=\"local\")\n\n# 数据转换\nplot_df &lt;- data_all$plotFrames$fit1\n\n# 画图\nlibrary(ggplot2)\nggplot(plot_df, aes(Pred,Obs))+\n  geom_point()+\n  geom_line(linewidth=1.2)+\n  scale_x_continuous(limits = c(0,0.5),name = \"Predicted Risk\")+\n  scale_y_continuous(limits = c(0,0.5),name = \"Observerd Risk\")+\n  geom_abline(slope = 1,intercept = 0,lty=2)+\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n31.3.2 测试集\n使用起来完全一样，只需要提供测试集即可：\n\nset.seed(1)\ncox_fit_s &lt;- Score(list(\"fit1\" = cox_fit1),\n               formula = Surv(time, status) ~ 1,\n               data = test_df, # 测试集\n               plots = \"calibration\",\n               B = 500,\n               M = 50,\n               times=c(100) # 时间点\n               )\nplotCalibration(cox_fit_s,cens.method=\"local\",# 减少输出日志\n                xlab = \"Predicted Risk\",\n                ylab = \"Observerd Risk\")\n\n\n\n\n\n\n\n\n这个结果也是可以用ggplot2绘制的，就不再重复了。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Cox回归校准曲线绘制</span>"
    ]
  },
  {
    "objectID": "calibration-qhscrnomo.html",
    "href": "calibration-qhscrnomo.html",
    "title": "32  竞争风险模型的校准曲线",
    "section": "",
    "text": "32.1 安装\n2选1：\ndevtools::install_github(\"ClevelandClinicQHS/QHScrnomo\")\ninstall.packages(\"QHScrnomo\")",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>竞争风险模型的校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-qhscrnomo.html#准备数据",
    "href": "calibration-qhscrnomo.html#准备数据",
    "title": "32  竞争风险模型的校准曲线",
    "section": "32.2 准备数据",
    "text": "32.2 准备数据\n使用casebase中的bmtcrr数据，只使用其中的一部分，并且把字符型变成因子型。\n\nlibrary(QHScrnomo)\n\ndata(\"bmtcrr\",package = \"casebase\")\nbmtcrr[,c(1,2,3,6)] &lt;- lapply(bmtcrr[,c(1,2,3,6)],as.factor)\nstr(bmtcrr)\n## 'data.frame':    177 obs. of  7 variables:\n##  $ Sex   : Factor w/ 2 levels \"F\",\"M\": 2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : Factor w/ 2 levels \"ALL\",\"AML\": 1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : Factor w/ 4 levels \"CR1\",\"CR2\",\"CR3\",..: 4 2 3 2 2 4 1 1 1 4 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Status: int  2 1 0 2 2 2 0 2 0 1 ...\n##  $ Source: Factor w/ 2 levels \"BM+PB\",\"PB\": 1 1 1 1 1 1 1 1 1 1 ...\n##  $ ftime : num  0.67 9.5 131.77 24.03 1.47 ...",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>竞争风险模型的校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-qhscrnomo.html#拟合竞争风险模型",
    "href": "calibration-qhscrnomo.html#拟合竞争风险模型",
    "title": "32  竞争风险模型的校准曲线",
    "section": "32.3 拟合竞争风险模型",
    "text": "32.3 拟合竞争风险模型\n先使用rms拟合cox回归模型，这几个变量只是我为了演示随便挑选的，可能并不是完全适合。\n\ndd &lt;- datadist(bmtcrr)\noptions(datadist = \"dd\")\n\n# 对Age这个变量进行样条变换\nfit &lt;- cph(Surv(ftime,Status == 1) ~ Sex + rcs(Age,3)+D+Phase, data = bmtcrr,\n           x = TRUE, y= TRUE, surv=TRUE, time.inc = 24)\n\n拟合好之后再使用crr.fit变为竞争风险模型，其实是借助了cmprsk::crr：\n\ncrr &lt;- crr.fit(fit = fit, cencode = 0, failcode = 1)\nclass(crr)\n## [1] \"cmprsk\" \"crr\"\nsummary(crr)\n##              Effects              Response : Surv(ftime, Status == 1) \n## \n##  Factor              Low High Diff. Effect    S.E.    Lower 0.95 Upper 0.95\n##  Age                 20  40   20    -0.337350 0.23489 -0.79772    0.12303  \n##   Hazard Ratio       20  40   20     0.713660      NA  0.45035    1.13090  \n##  Sex - F:M            2   1   NA     0.022279 0.28692 -0.54007    0.58463  \n##   Hazard Ratio        2   1   NA     1.022500      NA  0.58271    1.79430  \n##  D - ALL:AML          2   1   NA     0.363100 0.29546 -0.21599    0.94219  \n##   Hazard Ratio        2   1   NA     1.437800      NA  0.80575    2.56560  \n##  Phase - CR1:Relapse  4   1   NA    -1.135800 0.37803 -1.87670   -0.39488  \n##   Hazard Ratio        4   1   NA     0.321160      NA  0.15309    0.67376  \n##  Phase - CR2:Relapse  4   2   NA    -1.034200 0.35885 -1.73750   -0.33084  \n##   Hazard Ratio        4   2   NA     0.355520      NA  0.17596    0.71832  \n##  Phase - CR3:Relapse  4   3   NA    -0.914910 0.58559 -2.06260    0.23282  \n##   Hazard Ratio        4   3   NA     0.400550      NA  0.12712    1.26220\n\n可以用方差分析看看各个系数的显著性：\n\nanova(crr)\n##                 Wald Statistics          Response: Surv(ftime, Status == 1) \n## \n##  Factor     Chi-Square d.f. P     \n##  Sex         0.01      1    0.9381\n##  Age         2.25      2    0.3238\n##   Nonlinear  0.04      1    0.8510\n##  D           1.51      1    0.2191\n##  Phase      14.70      3    0.0021\n##  TOTAL      19.86      7    0.0059",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>竞争风险模型的校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-qhscrnomo.html#内部验证",
    "href": "calibration-qhscrnomo.html#内部验证",
    "title": "32  竞争风险模型的校准曲线",
    "section": "32.4 内部验证",
    "text": "32.4 内部验证\n建立好模型之后，可以用tenf.crr对验证集进行交叉验证，查看感兴趣时间点的预测结果(死亡概率)，就相当于内部验证。\n\n# 默认10折交叉验证\nset.seed(123)\n#可以计算线性预测值，可查看帮助文档\nbmtcrr$preds.tenf &lt;- tenf.crr(crr, time = 36, trace = FALSE)\nstr(bmtcrr$preds.tenf)\n##  num [1:177] 0.485 0.171 0.284 0.299 0.206 ...\n\n结果是第36个月的时候，各个病人的死亡风险，而且是考虑到了竞争风险事件的。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>竞争风险模型的校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-qhscrnomo.html#计算c-index",
    "href": "calibration-qhscrnomo.html#计算c-index",
    "title": "32  竞争风险模型的校准曲线",
    "section": "32.5 计算C-index",
    "text": "32.5 计算C-index\n基于上面计算出的概率，计算cindex：\n\ncindex(prob = bmtcrr$preds.tenf,\n       fstatus = bmtcrr$Status,\n       ftime = bmtcrr$ftime,\n       type = \"crr\",\n       failcode = 1, cencode = 0\n       )\n##            N            n       usable   concordant       cindex \n##  177.0000000  177.0000000 8249.0000000 5092.0000000    0.6172869\n\ncindex=0.617，说明模型一般。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>竞争风险模型的校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-qhscrnomo.html#校准曲线",
    "href": "calibration-qhscrnomo.html#校准曲线",
    "title": "32  竞争风险模型的校准曲线",
    "section": "32.6 校准曲线",
    "text": "32.6 校准曲线\n也是基于上面计算出的cindex。\n\ngroupci(x = bmtcrr$preds.tenf,\n        ftime = bmtcrr$ftime,\n        fstatus = bmtcrr$Status,\n        g = 5, # 分成几组\n        u = 36, # 时间点\n        failcode = 1,\n        xlab = \"Predicted 3-year mortality\",\n        ylab = \"Actual 3-year mortality\"\n        )\n\n\n\n\n\n\n\n##              x  n events        ci    std.err\n## [1,] 0.1408630 36      8 0.2286706 0.07313371\n## [2,] 0.2021363 35      7 0.2114286 0.07429595\n## [3,] 0.2841367 36     10 0.2822421 0.07775400\n## [4,] 0.3876848 35     14 0.3714286 0.08458920\n## [5,] 0.5899486 35     17 0.4857143 0.08757744\n\n这个其实就是内部验证的校准曲线了，看起来还不错，因为是在训练集中，训练集的校准曲线其实说明不了任何问题。\n如果你觉得不好看可以使用给出的数据自己画，或者直接自己计算也可。可信区间是95%CI，可以通过pred.ci计算的。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>竞争风险模型的校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-qhscrnomo.html#列线图",
    "href": "calibration-qhscrnomo.html#列线图",
    "title": "32  竞争风险模型的校准曲线",
    "section": "32.7 列线图",
    "text": "32.7 列线图\n建立列线图，和rms包的使用一模一样：\n\nnomogram.crr(\n  fit = crr,\n  failtime = 36,\n  lp = T,\n  xfrac = 0.65,\n  fun.at = seq(0.2, 0.45, 0.05),\n  funlabel = \"Predicted 3-year risk\"\n)",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>竞争风险模型的校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-qhscrnomo.html#生成模型方程",
    "href": "calibration-qhscrnomo.html#生成模型方程",
    "title": "32  竞争风险模型的校准曲线",
    "section": "32.8 生成模型方程",
    "text": "32.8 生成模型方程\n可以直接给出某个时间点的线性预测值的计算方程：\n\nsas.cmprsk(crr,time = 36)\n## Base failure probability by time = 36 is 0.3308 \n## - 0.022279144 * (Sex = \"M\") - 0.012796928 * Age - \n##     6.6881995e-06 * max(Age - 15.6, 0)**3 + 1.140514e-05 * max(Age - \n##     29, 0)**3 - 4.7169407e-06 * max(Age - 48, 0)**3 - 0.36310183 * \n##     (D = \"AML\") + 0.10164664 * (Phase = \"CR2\") + 0.22089946 * \n##     (Phase = \"CR3\") + 1.1358137 * (Phase = \"Relapse\")",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>竞争风险模型的校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-qhscrnomo.html#外部验证测试集",
    "href": "calibration-qhscrnomo.html#外部验证测试集",
    "title": "32  竞争风险模型的校准曲线",
    "section": "32.9 外部验证（测试集）",
    "text": "32.9 外部验证（测试集）\n直接predict即可：\n\ntest_df &lt;- head(bmtcrr,50)#取前50个作为测试集\nprob &lt;- predict(crr, time = 36, newdata = test_df)\nhead(prob)\n## [1] 0.4344841 0.2052952 0.3610625 0.2712397 0.2336076 0.6261795\n\n有了概率又可以计算cindex了：\n\ncindex(prob = prob,\n       fstatus = test_df$Status,\n       ftime = test_df$ftime\n       )\n##           N           n      usable  concordant      cindex \n##  50.0000000  50.0000000 630.0000000 454.0000000   0.7206349\n\n还可以绘制校准曲线：\n\ngroupci(x = prob,\n        ftime = test_df$ftime,\n        fstatus = test_df$Status,\n        u = 36,\n        g = 5\n        )\n\n\n\n\n\n\n\n##              x  n events  ci   std.err\n## [1,] 0.1619231 10      1 0.1 0.1013889\n## [2,] 0.2478567 10      2 0.2 0.1545392\n## [3,] 0.3141252 10      4 0.4 0.1683094\n## [4,] 0.4561951 10      1 0.1 0.1023904\n## [5,] 0.6326698 10      7 0.7 0.1702254\n\n是不是很easy呢。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>竞争风险模型的校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-qhscrnomo.html#参考资料",
    "href": "calibration-qhscrnomo.html#参考资料",
    "title": "32  竞争风险模型的校准曲线",
    "section": "32.10 参考资料",
    "text": "32.10 参考资料\n\nhttps://github.com/ClevelandClinicQHS/QHScrnomo\nvignette(“QHScrnomo”)",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>竞争风险模型的校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-lasso.html",
    "href": "calibration-lasso.html",
    "title": "33  lasso回归校准曲线",
    "section": "",
    "text": "33.1 安装\n# 2选1\ninstall.packages(\"hdnom\")\nremotes::install_github(\"nanxstats/hdnom\")",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>lasso回归校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-lasso.html#加载r包和数据",
    "href": "calibration-lasso.html#加载r包和数据",
    "title": "33  lasso回归校准曲线",
    "section": "33.2 加载R包和数据",
    "text": "33.2 加载R包和数据\n使用smart数据集进行演示，这是一个生存数据。该数据是经过缺失值插补的，所以没有缺失值。包含3873行，27个预测变量，TEVENT是时间变量，EVENT是结局变量。\n\nlibrary(hdnom)\n\ndata(\"smart\")\nx &lt;- as.matrix(smart[, -c(1, 2)])\ntime &lt;- smart$TEVENT\nevent &lt;- smart$EVENT\ny &lt;- survival::Surv(time, event)",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>lasso回归校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-lasso.html#拟合模型",
    "href": "calibration-lasso.html#拟合模型",
    "title": "33  lasso回归校准曲线",
    "section": "33.3 拟合模型",
    "text": "33.3 拟合模型\n拟合一个最简单的正则化COX回归，它会自动执行超参数调优的过程：\n\n#suppressMessages(library(\"doParallel\"))\n#registerDoParallel(detectCores())\n\nfit &lt;- fit_lasso(x, y, nfolds = 10, rule = \"lambda.1se\", seed = 1001)\nfit\n## High-Dimensional Cox Model Object\n## Random seed: 1001 \n## Model type: lasso\n## Best lambda: 0.02351754\nnames(fit)\n## [1] \"model\"  \"lambda\" \"type\"   \"seed\"   \"call\"\n\n我们选择的最佳超参数的方法是\"lambda.1se\"，此时选中的最佳lambda是0.02351754。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>lasso回归校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-lasso.html#列线图",
    "href": "calibration-lasso.html#列线图",
    "title": "33  lasso回归校准曲线",
    "section": "33.4 列线图",
    "text": "33.4 列线图\n首先要提取模型对象和超参数，不同的正则化模型有不同的超参数，不要搞错了：\n\nmodel &lt;- fit$model\n#alpha &lt;- fit$alpha\nlambda &lt;- fit$lambda\n#adapen &lt;- fit$pen_factor\n\n使用as_nomogram转换一下，就可以绘制列线图了：\n\nnom &lt;- as_nomogram(\n  fit, x, time, event,\n  pred.at = 365 * 2,\n  funlabel = \"2-Year Overall Survival Probability\"\n)\n\nplot(nom)",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>lasso回归校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-lasso.html#模型验证",
    "href": "calibration-lasso.html#模型验证",
    "title": "33  lasso回归校准曲线",
    "section": "33.5 模型验证",
    "text": "33.5 模型验证\n\n33.5.1 内部验证\n通过validate函数可以实现内部验证，和rms包如出一辙！支持bootstrap、交叉验证、重复交叉验证3种重抽样方法。\n注意这个函数对不同的正则化方法有不同的要求，注意看帮助文档，下面是10次bootstrap的内部验证，时间截点选择的是第一年到第5年，每半年一次（也就是第1，1.5，2，2.5，3，3.5，4，4.5，5年这几个截点）。\n\nval_int &lt;- validate(\n  x, time, event,\n  model.type = \"lasso\",\n  alpha = 1, # lasso的alpha是1\n  lambda = lambda,\n  method = \"bootstrap\", boot.times = 10,\n  tauc.type = \"UNO\", tauc.time = seq(1, 5, 0.5) * 365,\n  seed = 42, trace = FALSE\n)\n\n# 最后一行给出了不同时间截点的time-dependent AUC\nprint(val_int)\n## High-Dimensional Cox Model Validation Object\n## Random seed: 42 \n## Validation method: bootstrap\n## Bootstrap samples: 10 \n## Model type: lasso \n## glmnet model alpha: 1 \n## glmnet model lambda: 0.02351754 \n## glmnet model penalty factor: not specified\n## Time-dependent AUC type: UNO \n## Evaluation time points for tAUC: 365 547.5 730 912.5 1095 1277.5 1460 1642.5 1825\n\n# 给出time-dependent AUC的均值、最大值、最小值等信息\nsummary(val_int)\n## Time-Dependent AUC Summary at Evaluation Time Points\n##                365     547.5       730     912.5      1095    1277.5      1460\n## Mean     0.6621581 0.6954059 0.6790755 0.6735408 0.7087387 0.7318520 0.6849760\n## Min      0.6520262 0.6885520 0.6695303 0.6673154 0.6925704 0.7075978 0.6730413\n## 0.25 Qt. 0.6613887 0.6924443 0.6774962 0.6704223 0.7077576 0.7275127 0.6802230\n## Median   0.6624251 0.6959672 0.6793223 0.6742531 0.7099186 0.7333807 0.6862219\n## 0.75 Qt. 0.6639822 0.6986393 0.6818983 0.6757052 0.7126817 0.7381664 0.6904942\n## Max      0.6682398 0.6998708 0.6895636 0.6792039 0.7194969 0.7481341 0.6951763\n##             1642.5      1825\n## Mean     0.6809777 0.6993722\n## Min      0.6698759 0.6892602\n## 0.25 Qt. 0.6779836 0.6961173\n## Median   0.6810805 0.7018242\n## 0.75 Qt. 0.6852553 0.7026699\n## Max      0.6908602 0.7058832\n\n其中的均值和中位数可以当做矫正过误差的模型表现。\n把time-dependent AUC画出来：\n\nplot(val_int)\n##                365     547.5       730     912.5      1095    1277.5      1460\n## Mean     0.6621581 0.6954059 0.6790755 0.6735408 0.7087387 0.7318520 0.6849760\n## Min      0.6520262 0.6885520 0.6695303 0.6673154 0.6925704 0.7075978 0.6730413\n## 0.25 Qt. 0.6613887 0.6924443 0.6774962 0.6704223 0.7077576 0.7275127 0.6802230\n## Median   0.6624251 0.6959672 0.6793223 0.6742531 0.7099186 0.7333807 0.6862219\n## 0.75 Qt. 0.6639822 0.6986393 0.6818983 0.6757052 0.7126817 0.7381664 0.6904942\n## Max      0.6682398 0.6998708 0.6895636 0.6792039 0.7194969 0.7481341 0.6951763\n##             1642.5      1825\n## Mean     0.6809777 0.6993722\n## Min      0.6698759 0.6892602\n## 0.25 Qt. 0.6779836 0.6961173\n## Median   0.6810805 0.7018242\n## 0.75 Qt. 0.6852553 0.7026699\n## Max      0.6908602 0.7058832\n\n\n\n\n\n\n\n\n上图中实线表示AUC的平均值，虚线表示AUC的中位数。图中较暗的区间显示AUC的25%和75%分位数，较浅的区间显示AUC的最小值和最大值。\n\n\n33.5.2 外部验证\n也就是用一个新的数据集进行验证，这里我们从smart中随机抽取1000个样本作为外部验证集。\n外部验证使用validate_external，使用方法和validate一模一样，但是没有重抽样了，因为外部验证就是检查模型的，就是要最真实的结果，不需要重抽样：\n\nx_new &lt;- as.matrix(smart[, -c(1, 2)])[1001:2000, ]\ntime_new &lt;- smart$TEVENT[1001:2000]\nevent_new &lt;- smart$EVENT[1001:2000]\n\nval_ext &lt;- validate_external(\n  fit, x, time, event,\n  x_new, time_new, event_new,\n  tauc.type = \"UNO\",\n  tauc.time = seq(0.25, 2, 0.25) * 365 # 时间截点和内部验证不同了\n)\n\n# 3个查看结果的方法，也是内部验证一样的\nprint(val_ext)\n## High-Dimensional Cox Model External Validation Object\n## Model type: lasso \n## Time-dependent AUC type: UNO \n## Evaluation time points for tAUC: 91.25 182.5 273.75 365 456.25 547.5 638.75 730\nsummary(val_ext)\n## Time-Dependent AUC Summary at Evaluation Time Points\n##         91.25     182.5   273.75       365    456.25     547.5    638.75\n## AUC 0.4794879 0.6008266 0.662017 0.6523222 0.6732534 0.6963037 0.7013534\n##           730\n## AUC 0.7042923\nplot(val_ext)\n##         91.25     182.5   273.75       365    456.25     547.5    638.75\n## AUC 0.4794879 0.6008266 0.662017 0.6523222 0.6732534 0.6963037 0.7013534\n##           730\n## AUC 0.7042923",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>lasso回归校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-lasso.html#模型校准",
    "href": "calibration-lasso.html#模型校准",
    "title": "33  lasso回归校准曲线",
    "section": "33.6 模型校准",
    "text": "33.6 模型校准\n也就是绘制校准曲线，同样是支持内部校准和外部校准。\n\n33.6.1 内部校准曲线\n内部校准通过calibrate实现，也是支持bootstrap、交叉验证、重复交叉验证3种重抽样方法，和rms包类似的。\n下面是10次bootstrap的内部校准，时间截点选择的是第5年：\n\ncal_int &lt;- calibrate(\n  x, time, event,\n  model.type = \"aenet\",\n  alpha = 1, \n  lambda = lambda, \n  #pen.factor = adapen,\n  method = \"bootstrap\", boot.times = 10,\n  pred.at = 365 * 5, ngroup = 3, # 分几组\n  seed = 42, trace = FALSE\n)\n\n# 查看结果\nprint(cal_int)\n## High-Dimensional Cox Model Calibration Object\n## Random seed: 42 \n## Calibration method: bootstrap\n## Bootstrap samples: 10 \n## Model type: aenet \n## glmnet model alpha: 1 \n## glmnet model lambda: 0.02351754 \n## glmnet model penalty factor: not specified\n## Calibration time point: 1825 \n## Number of groups formed for calibration: 3\n\n# 真实值、预测值、可信区间\nsummary(cal_int)\n##   Calibration Summary Table\n##   Predicted  Observed Lower 95% Upper 95%\n## 1 0.8214255 0.7508803 0.7216191 0.7813280\n## 2 0.8696257 0.9021791 0.8812135 0.9236435\n## 3 0.8978577 0.9307660 0.9136491 0.9482034\n\n这个结果的预测值是预测概率的中位数（因为使用了bootstrap，所以会有多个预测值，所以可以计算中位数），真实值是K-M法计算的，这些我们在之前的推文中都详细介绍过的，后台回复校准曲线即可获取相关推文合集了。\n绘制校准曲线：\n\nplot(cal_int, xlim = c(0.7, 1), ylim = c(0.7, 1))\n\n\n\n\n\n\n\n\n可以多个时间点的画在一起。\n\n\n33.6.2 外部校准\n通过calibrate_external实现：\n\ncal_ext &lt;- calibrate_external(\n  fit, x, time, event,\n  x_new, time_new, event_new,\n  pred.at = 365 * 5, ngroup = 3\n)\n\nprint(cal_ext)\n## High-Dimensional Cox Model External Calibration Object\n## Model type: lasso \n## Calibration time point: 1825 \n## Number of groups formed for calibration: 3\nsummary(cal_ext)\n##   External Calibration Summary Table\n##   Predicted  Observed Lower 95% Upper 95%\n## 1 0.8132618 0.7376980 0.6892529 0.7895482\n## 2 0.8721412 0.8829179 0.8478426 0.9194443\n## 3 0.9021290 0.9381784 0.9113542 0.9657922\nplot(cal_ext, xlim = c(0.5, 1), ylim = c(0.5, 1))",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>lasso回归校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-lasso.html#risk-group的k-m生存曲线",
    "href": "calibration-lasso.html#risk-group的k-m生存曲线",
    "title": "33  lasso回归校准曲线",
    "section": "33.7 risk group的K-M生存曲线",
    "text": "33.7 risk group的K-M生存曲线\n在进行模型校准时我们是分成了3组，所以这里可以对这3组进行K-M生存分析，log-tank检验的P值也会展示出来。\n内部验证的3个组别：\n\nkmplot(\n  cal_int,\n  group.name = c(\"High risk\", \"Medium risk\", \"Low risk\"),\n  time.at = 1:6 * 365\n)\n\n\n\n\n\n\n\n\n外部验证的3个组别：\n\nkmplot(\n  cal_ext,\n  group.name = c(\"High risk\", \"Medium risk\", \"Low risk\"),\n  time.at = 1:6 * 365\n)",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>lasso回归校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-lasso.html#risk-group的log-rank检验",
    "href": "calibration-lasso.html#risk-group的log-rank检验",
    "title": "33  lasso回归校准曲线",
    "section": "33.8 risk group的log-rank检验",
    "text": "33.8 risk group的log-rank检验\n也可以直接进行log-rank检验：\n\n# 内部验证3个组的log-rank检验\ncal_int_logrank &lt;- logrank_test(cal_int)\ncal_int_logrank\n## Call:\n## survdiff(formula = formula(\"Surv(time, event) ~ grp\"))\n## \n## n=3872, 1 observation deleted due to missingness.\n## \n##          N Observed Expected (O-E)^2/E (O-E)^2/V\n## grp=1 1290      279      148     116.1     171.5\n## grp=2 1291      104      155      16.6      25.0\n## grp=3 1291       76      156      41.4      62.8\n## \n##  Chisq= 174  on 2 degrees of freedom, p= &lt;2e-16\ncal_int_logrank$pval\n## [1] 1.511019e-38\n\n# 外部验证3个组的log-rank检验\ncal_ext_logrank &lt;- logrank_test(cal_ext)\ncal_ext_logrank\n## Call:\n## survdiff(formula = formula(\"Surv(time, event) ~ grp\"))\n## \n## n=999, 1 observation deleted due to missingness.\n## \n##         N Observed Expected (O-E)^2/E (O-E)^2/V\n## grp=1 333       86     44.8     37.95     54.76\n## grp=2 333       38     50.1      2.94      4.47\n## grp=3 333       23     52.1     16.23     25.17\n## \n##  Chisq= 57.3  on 2 degrees of freedom, p= 4e-13\ncal_ext_logrank$pval\n## [1] 3.581463e-13",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>lasso回归校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-lasso.html#模型比较",
    "href": "calibration-lasso.html#模型比较",
    "title": "33  lasso回归校准曲线",
    "section": "33.9 模型比较",
    "text": "33.9 模型比较\n\n33.9.1 通过模型验证比较\n通过validate进行比较，也就是通过计算不同模型的time-dependent AUC进行比较。\n比如这里比较一下lasso和自适应lasso的模型效果：\n\ncmp_val &lt;- compare_by_validate(\n  x, time, event,\n  model.type = c(\"lasso\", \"alasso\"),\n  method = \"cv\", nfolds = 5, tauc.type = \"UNO\",\n  tauc.time = seq(0.25, 2, 0.25) * 365,\n  seed = 42, trace = FALSE\n)\n\n#print(cmp_val)\n#summary(cmp_val)\nplot(cmp_val) #袋外数据的结果\n##              91.25     182.5    273.75       365    456.25     547.5    638.75\n## Mean     0.4862766 0.6235047 0.6554862 0.6645661 0.6709065 0.6905955 0.6859931\n## Min      0.2039134 0.5628978 0.6125746 0.6259622 0.6288554 0.6480062 0.6258751\n## 0.25 Qt. 0.4868413 0.6095040 0.6296803 0.6518906 0.6636125 0.6740643 0.6677914\n## Median   0.5470612 0.6207525 0.6669674 0.6753767 0.6780298 0.6956816 0.7034205\n## 0.75 Qt. 0.5840546 0.6536918 0.6724515 0.6765498 0.6818180 0.6959422 0.7126816\n## Max      0.6095124 0.6706775 0.6957573 0.6930510 0.7022166 0.7392832 0.7201967\n##                730\n## Mean     0.6789647\n## Min      0.6251706\n## 0.25 Qt. 0.6258098\n## Median   0.6935016\n## 0.75 Qt. 0.7180132\n## Max      0.7323283\n##              91.25     182.5    273.75       365    456.25     547.5    638.75\n## Mean     0.4814586 0.6106500 0.6475280 0.6612647 0.6675871 0.6834418 0.6813224\n## Min      0.2479919 0.5538453 0.6009056 0.6208453 0.6310650 0.6504086 0.6354844\n## 0.25 Qt. 0.4747967 0.5918396 0.6394882 0.6539436 0.6509640 0.6548892 0.6608927\n## Median   0.5320552 0.6000809 0.6534756 0.6651832 0.6601551 0.6643520 0.6634682\n## 0.75 Qt. 0.5755143 0.6290886 0.6546811 0.6665424 0.6841356 0.6999959 0.7108894\n## Max      0.5769350 0.6783959 0.6890896 0.6998091 0.7116160 0.7475634 0.7358773\n##                730\n## Mean     0.6774869\n## Min      0.6340813\n## 0.25 Qt. 0.6386258\n## Median   0.6791506\n## 0.75 Qt. 0.6995719\n## Max      0.7360047\n\n\n\n\n\n\n\n\n内部验证的结果：\n\nplot(cmp_val, interval = TRUE)\n##              91.25     182.5    273.75       365    456.25     547.5    638.75\n## Mean     0.4862766 0.6235047 0.6554862 0.6645661 0.6709065 0.6905955 0.6859931\n## Min      0.2039134 0.5628978 0.6125746 0.6259622 0.6288554 0.6480062 0.6258751\n## 0.25 Qt. 0.4868413 0.6095040 0.6296803 0.6518906 0.6636125 0.6740643 0.6677914\n## Median   0.5470612 0.6207525 0.6669674 0.6753767 0.6780298 0.6956816 0.7034205\n## 0.75 Qt. 0.5840546 0.6536918 0.6724515 0.6765498 0.6818180 0.6959422 0.7126816\n## Max      0.6095124 0.6706775 0.6957573 0.6930510 0.7022166 0.7392832 0.7201967\n##                730\n## Mean     0.6789647\n## Min      0.6251706\n## 0.25 Qt. 0.6258098\n## Median   0.6935016\n## 0.75 Qt. 0.7180132\n## Max      0.7323283\n##              91.25     182.5    273.75       365    456.25     547.5    638.75\n## Mean     0.4814586 0.6106500 0.6475280 0.6612647 0.6675871 0.6834418 0.6813224\n## Min      0.2479919 0.5538453 0.6009056 0.6208453 0.6310650 0.6504086 0.6354844\n## 0.25 Qt. 0.4747967 0.5918396 0.6394882 0.6539436 0.6509640 0.6548892 0.6608927\n## Median   0.5320552 0.6000809 0.6534756 0.6651832 0.6601551 0.6643520 0.6634682\n## 0.75 Qt. 0.5755143 0.6290886 0.6546811 0.6665424 0.6841356 0.6999959 0.7108894\n## Max      0.5769350 0.6783959 0.6890896 0.6998091 0.7116160 0.7475634 0.7358773\n##                730\n## Mean     0.6774869\n## Min      0.6340813\n## 0.25 Qt. 0.6386258\n## Median   0.6791506\n## 0.75 Qt. 0.6995719\n## Max      0.7360047\n\n\n\n\n\n\n\n\n\n\n33.9.2 通过模型校准验证\n也就是通过校准曲线进行验证。\n\ncmp_cal &lt;- compare_by_calibrate(\n  x, time, event,\n  model.type = c(\"lasso\", \"alasso\"),\n  method = \"cv\", nfolds = 5,\n  pred.at = 365 * 9, ngroup = 5,\n  seed = 42, trace = FALSE\n)\n\n#print(cmp_cal)\n#summary(cmp_cal)\nplot(cmp_cal, xlim = c(0.3, 1), ylim = c(0.3, 1))",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>lasso回归校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-lasso.html#预测新数据",
    "href": "calibration-lasso.html#预测新数据",
    "title": "33  lasso回归校准曲线",
    "section": "33.10 预测新数据",
    "text": "33.10 预测新数据\n由于在拟合模型时会自动进行超参数选择，所以得到的模型就是最终结果了。可以直接使用predict预测新数据。\n\npredict(fit, x, y, newx = x[101:105, ], pred.at = 1:10 * 365)\n##            365       730      1095      1460      1825      2190      2555\n## [1,] 0.9478345 0.9203830 0.8881359 0.8567453 0.8166540 0.7841083 0.7431914\n## [2,] 0.9605957 0.9396430 0.9148295 0.8904582 0.8590046 0.8331866 0.8003446\n## [3,] 0.9721710 0.9572351 0.9394182 0.9217779 0.8987971 0.8797459 0.8552554\n## [4,] 0.9330930 0.8983106 0.8578385 0.8188522 0.7696659 0.7302518 0.6813769\n## [5,] 0.9664734 0.9485614 0.9272704 0.9062732 0.8790447 0.8565816 0.8278538\n##           2920      3285      3650\n## [1,] 0.7039669 0.6496905 0.6496905\n## [2,] 0.7684344 0.7235347 0.7235347\n## [3,] 0.8311712 0.7967714 0.7967714\n## [4,] 0.6352566 0.5726751 0.5726751\n## [5,] 0.7997693 0.7599497 0.7599497\n\n是不是很简单呢？",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>lasso回归校准曲线</span>"
    ]
  },
  {
    "objectID": "calibration-lasso.html#shiny版",
    "href": "calibration-lasso.html#shiny版",
    "title": "33  lasso回归校准曲线",
    "section": "33.11 shiny版",
    "text": "33.11 shiny版\n该包还提供了shiny版本，可以通过点点点使用，感兴趣的可以试用一下：nanx.app/hdnom/",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>lasso回归校准曲线</span>"
    ]
  },
  {
    "objectID": "dca-logistic.html",
    "href": "dca-logistic.html",
    "title": "34  分类数据的决策曲线",
    "section": "",
    "text": "34.1 方法1：rmda\n使用rmda包。\n# 先安装R包\ninstall.packages(\"rmda\")\n使用这个包自带的一个dcaData作为演示，这个数据集一共500行，6列，其中Cancer是结果变量，1代表患病，0代表没病，其余列是预测变量。\nlibrary(rmda)\ndata(\"dcaData\")\n\ndim(dcaData) # 500,6\n## [1] 500   6\nhead(dcaData)\n## # A tibble: 6 × 6\n##     Age Female Smokes Marker1  Marker2 Cancer\n##   &lt;int&gt;  &lt;dbl&gt; &lt;lgl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;int&gt;\n## 1    33      1 FALSE    0.245  1.02         0\n## 2    29      1 FALSE    0.943 -0.256        0\n## 3    28      1 FALSE    0.774  0.332        0\n## 4    27      0 FALSE    0.406 -0.00569      0\n## 5    23      1 FALSE    0.508  0.208        0\n## 6    35      1 FALSE    0.186  1.41         0\nstr(dcaData)\n## tibble [500 × 6] (S3: tbl_df/tbl/data.frame)\n##  $ Age    : int [1:500] 33 29 28 27 23 35 34 29 35 27 ...\n##  $ Female : num [1:500] 1 1 1 0 1 1 1 1 1 1 ...\n##  $ Smokes : logi [1:500] FALSE FALSE FALSE FALSE FALSE FALSE ...\n##  $ Marker1: num [1:500] 0.245 0.943 0.774 0.406 0.508 ...\n##  $ Marker2: num [1:500] 1.02108 -0.25576 0.33184 -0.00569 0.20753 ...\n##  $ Cancer : int [1:500] 0 0 0 0 0 0 0 0 0 0 ...\n划分训练集测试集，划分比例为7：3。\nset.seed(123)\ntrain &lt;- sample(1:nrow(dcaData), nrow(dcaData)*0.7)\ntrain_df &lt;- dcaData[train,]\ntest_df &lt;- dcaData[- train,]\ndim(train_df)\n## [1] 350   6\ndim(test_df)\n## [1] 150   6",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>分类数据的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-logistic.html#方法1rmda",
    "href": "dca-logistic.html#方法1rmda",
    "title": "34  分类数据的决策曲线",
    "section": "",
    "text": "34.1.1 训练集\n使用起来非常简单，首先构建dca，然后画图：\n\nset.seed(123)\n\n# 构建DCA\nfit1 &lt;- decision_curve(Cancer ~ Age + Female + Smokes, # 自变量和因变量\n                       data = train_df, # 训练集数据\n                       study.design = \"cohort\", # 选择研究类型\n                       bootstraps = 50 # 重抽样次数\n                       )\n\n# 画图\nplot_decision_curve(fit1, curve.names = \"fit1\",\n                    cost.benefit.axis = F, # 是否需要损失：获益比 轴\n                    confidence.intervals = \"none\" # 不画可信区间\n                    )\n\n\n\n\n\n\n\n\n可以查看模型中的各个数据的值：\n\n# 数据很大，没有展示全部，大家可以自己运行看看\nsummary(fit1)\n\n给出了详细的概率阈值(展示部分)：\n\n多个模型的多条DCA曲线一起绘制也是可以的：\n\n# 新建立1个模型\nset.seed(123)\nfit2 &lt;- decision_curve(Cancer~Age + Female + Smokes + Marker1 + Marker2,\n              data = train_df, \n              bootstraps = 50\n              )\n\n# 画图只要把多个模型放在1个列表中即可，还可以进行很多自定义调整\nplot_decision_curve(list(fit1, fit2),\n                    curve.names = c(\"fit1\", \"fit2\"), \n                    xlim = c(0, 1), # 可以设置x轴范围\n                    legend.position = \"topright\", # 图例位置,\n                    col = c(\"red\",\"blue\"), # 自定义颜色\n                    confidence.intervals = \"none\",\n                    lty = c(1,2), # 线型，注意顺序\n                    lwd = c(3,2,2,1) #注意顺序,先是自己的模型,然后All,然后None\n                    )\n\n\n\n\n\n\n\n\n这个包还可以绘制临床影响曲线(这也是我目前发现的唯一能绘制临床影响曲线的包)：\n\n# 1次只能绘制1个模型\nplot_clinical_impact(fit1,\n                     population.size= 1000,\n                     cost.benefit.axis = T,\n                     n.cost.benefits= 8,\n                     col=c('red','blue'),\n                     confidence.intervals= T,\n                     ylim=c(0,1000),\n                     legend.position=\"topright\")\n\n\n\n\n\n\n\n\n这就是这个包画DCA的例子，效果还是不错的，自定义设置也很多，方便大家画出更好看的图。这个包还有很多其他功能，我们就不演示了，感兴趣的小伙伴可以自己探索哦。美中不足的是不能画生存资料的DCA。\n\n\n34.1.2 测试集\n只需要提供测试集数据即可：\n\nset.seed(123)\n\n# 构建DCA\nfit1 &lt;- decision_curve(Cancer ~ Age + Female + Smokes, # 自变量和因变量\n                       data = test_df, # 测试集数据\n                       study.design = \"cohort\", # 选择研究类型\n                       bootstraps = 50 # 重抽样次数\n                       )\n\n# 画图\nplot_decision_curve(fit1, curve.names = \"fit1\",\n                    cost.benefit.axis = F, # 是否需要损失：获益比 轴\n                    confidence.intervals = \"none\" # 不画可信区间\n                    )\n\n\n\n\n\n\n\n\n测试集的临床影响曲线：\n\n# 1次只能绘制1个模型\nplot_clinical_impact(fit1,\n                     population.size= 1000,\n                     cost.benefit.axis = T,\n                     n.cost.benefits= 8,\n                     col=c('red','blue'),\n                     confidence.intervals= T,\n                     ylim=c(0,1000),\n                     legend.position=\"topright\")",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>分类数据的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-logistic.html#方法2dca.r",
    "href": "dca-logistic.html#方法2dca.r",
    "title": "34  分类数据的决策曲线",
    "section": "34.2 方法2：dca.r",
    "text": "34.2 方法2：dca.r\n这个方法是纪念斯隆·凯特林癌症中心给出的方法，非常正规，目前绝大多数其他实现DCA的方法都是基于此方法实现的。\n曾经，纪念斯隆·凯特林癌症中心的官网网站会让你免费下载dca.r/stdca.r这两段脚本，可分别用于二分类数据和生存数据的决策曲线分析，但是非常遗憾的是，目前该网站已不再提供代码下载了。\n\n\n\n\n\n\n注意\n\n\n\n这个网站（https://www.mskcc.org/departments/epidemiology-biostatistics/biostatistics/decision-curve-analysis）已经不再提供该代码的下载，我在多年前就下载好了，我把dca.r/stdca.r这两段代码已经放在粉丝QQ群文件，需要的加群下载即可。\n\n\n\n34.2.1 训练集\n还是使用rmda包的数据，首先我们画一个简单的DCA，结果变量是Cancer，预测变量我们只用一个Smokes。使用起来非常简单，一句代码即可：\n\nsource(\"./datasets/dca.r\")\n\n# 变为数据框类型\ntrain_df &lt;- as.data.frame(train_df)\n\ndd &lt;- dca(data = train_df, # 指定数据集,必须是data.frame类型\n    outcome=\"Cancer\", # 指定结果变量\n    predictors=\"Smokes\", # 指定预测变量\n    probability = F, # Smokes这一列是0,1组成的二分类变量，不是概率，所以是F\n    xstop = 0.3 # x轴范围\n    )\n\n\n\n\n\n\n\n\n但是如果你的预测变量不是0,1这种，或者有多个的话，这时候需要你先把预测概率算出来，才能使用这个函数。\n\n# 建立包含多个自变量的logistic模型\nmodel &lt;- glm(Cancer ~ Age + Female + Smokes, \n            family=binomial(),\n            data = train_df\n            )\n\n# 算出概率\ntrain_df$prob &lt;- predict(model, type=\"response\")\n\n# 绘制多个预测变量的DCA\ndd &lt;- dca(data=train_df, outcome=\"Cancer\", predictors=\"prob\", \n    probability = T\n    )\n\n\n\n\n\n\n\n\n把多个模型画在一起的方式需要注意，比如我们下面演示下3个模型画在一起，其中prob代表的是上面的model模型，Marker2代表的是只有一个预测变量Marker2的模型，Smokes代表只有一个预测变量Smokes的模型！\nprob是概率，所以是T，Smokes和Marker2不是概率，所以是F。\n\ndd &lt;- dca(data = train_df, outcome=\"Cancer\", \n    predictors=c(\"prob\",\"Smokes\",\"Marker2\"), # 这是3个模型！\n    probability = c(T,F,F) # 和上面是对应的！\n    )\n## [1] \"Smokes converted to a probability with logistic regression. Due to linearity assumption, miscalibration may occur.\"\n## [1] \"Marker2 converted to a probability with logistic regression. Due to linearity assumption, miscalibration may occur.\"\n\n\n\n\n\n\n\n\n\n\n34.2.2 测试集\n如果只有1个预测变量，直接用即可：\n\n# 变为数据框类型\ntest_df &lt;- as.data.frame(test_df)\n\ndd &lt;- dca(data = test_df, # 指定数据集,必须是data.frame类型\n    outcome=\"Cancer\", # 指定结果变量\n    predictors=\"Smokes\", # 指定预测变量\n    probability = F, # Smokes这一列是0,1组成的二分类变量，不是概率，所以是F\n    xstop = 0.3 # x轴范围\n    )\n## [1] \"Smokes converted to a probability with logistic regression. Due to linearity assumption, miscalibration may occur.\"\n\n\n\n\n\n\n\n\n如果有多个预测变量，需要自己计算出概率，再画图：\n\n# 在训练集建立包含多个自变量的logistic模型\nmodel &lt;- glm(Cancer ~ Age + Female + Smokes, \n            family=binomial(),\n            data = train_df\n            )\n\n# 算出测试集的概率\ntest_df$prob &lt;- predict(model, type=\"response\", newdata = test_df)\n\n# 绘制多个预测变量的DCA\ndd &lt;- dca(data=test_df, outcome=\"Cancer\", predictors=\"prob\", \n          probability = T)\n\n\n\n\n\n\n\n\n其他的就不再重复说了。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>分类数据的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-logistic.html#方法3diy",
    "href": "dca-logistic.html#方法3diy",
    "title": "34  分类数据的决策曲线",
    "section": "34.3 方法3：DIY",
    "text": "34.3 方法3：DIY\n上面的方法自定义选项也很少，不利于美化图形。但是呢，有一个优点就是可以直接返回画图数据，我们只要稍加修改，就能使用ggplot2画图了！而且由于直接给出了源码，我们可以试着自己修改，这样可发挥的地方就太多了！\n下面几个将要介绍的方法，都是可以返回数据的，都支持使用ggplot2画图！\n下面我们返回2个模型的画图数据，自己稍加整理，然后使用ggplot2画DCA，大家如果只有1个模型或者更多的模型，道理都是一样的哦，就是整成ggplot2需要的格式就行了！\n\n34.3.1 训练集\n\n# 返回模型1的画图数据\nsource(\"./datasets/dca.r\")\n\n# 建立包含多个自变量的logistic模型\nmodel &lt;- glm(Cancer ~ Age + Female + Smokes, \n            family=binomial(),\n            data = train_df\n            )\n\n# 算出概率\ntrain_df$prob &lt;- predict(model, type=\"response\")\n\n# 绘制多个预测变量的DCA,返回画图数据\ndca_data1 &lt;- dca(data=train_df, outcome=\"Cancer\", predictors=\"prob\", \n          probability = T, graph = F)\n\n然后提取数据，数据转换：\n\n# 转换数据\nlibrary(tidyr)\n\ndca_df1 &lt;- dca_data1$net.benefit %&gt;% # 画图数据就藏在这里！\n  # 变成长数据,还不懂长宽数据转换这个超强操作的快去翻一下历史文章！\n  pivot_longer(cols = -threshold, names_to = \"type\", values_to = \"net_benefit\") \n\n# 看下数据结构\nstr(dca_df1)\n## tibble [297 × 3] (S3: tbl_df/tbl/data.frame)\n##  $ threshold  : num [1:297] 0.01 0.01 0.01 0.02 0.02 0.02 0.03 0.03 0.03 0.04 ...\n##  $ type       : chr [1:297] \"all\" \"none\" \"prob\" \"all\" ...\n##  $ net_benefit: num [1:297] 0.12 0 0.12 0.111 0 ...\n\n画图就是非常简单了，先给大家看看只画1个模型的例子：\n\nlibrary(ggplot2)\nlibrary(ggsci)\n\n# 以prob这个模型为例\n\nggplot(dca_df1, aes(threshold, net_benefit, color = type))+\n  geom_line(linewidth = 1.2)+\n  scale_color_jama(name = \"Model Type\")+ # c(\"steelblue\",\"firebrick\",\"green4\")\n  scale_y_continuous(limits = c(-0.03,0.12),name = \"Net Benefit\")+\n  #限定y轴范围是重点，你可以去掉这句看看\n  scale_x_continuous(limits = c(0,1),name = \"Threshold Probility\")+\n  theme_bw(base_size = 16)+\n  theme(legend.position.inside = c(0.8,0.8),\n        legend.background = element_blank()\n        )\n\n\n\n\n\n\n\n\n看着是不是比上面的颜值都高些？是不是已经有了JAMA杂志的味道？\n下面是2个模型画在一起的例子，和上面的思路一模一样！\n\n# 构建模型2\nmod2 &lt;- glm(Cancer ~ Marker1 + Age + Smokes, train_df, family = binomial)\ntrain_df$model2 &lt;- predict(mod2, type=\"response\")\n\n# 返回两个模型的画图数据\ndca12 &lt;- dca(data = train_df, \n             outcome=\"Cancer\", \n             predictors=c(\"prob\",\"model2\") ,\n             probability = c(T,T),\n             graph = F\n             )\n\n\n# 合并数据，大家可以打开这2个数据看下，可以直接合并\nlibrary(dplyr)\n\ndca_df_all &lt;- dca12$net.benefit %&gt;% \n  pivot_longer(cols = -threshold,names_to = \"models\",values_to = \"net_benefit\")\n\nglimpse(dca_df_all)\n## Rows: 396\n## Columns: 3\n## $ threshold   &lt;dbl&gt; 0.01, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.03, 0.03…\n## $ models      &lt;chr&gt; \"all\", \"none\", \"prob\", \"model2\", \"all\", \"none\", \"prob\", \"m…\n## $ net_benefit &lt;dbl&gt; 0.11976912, 0.00000000, 0.11976912, 0.11976912, 0.11078717…\n\n画图也是一样的简单：\n\nggplot(dca_df_all, aes(threshold, net_benefit, color = models))+\n  #geom_line(size = 1.2)+\n  stat_smooth(method = \"loess\", se = FALSE, formula = \"y ~ x\", span = 0.2)+ \n  # 灵感来自于方法5！\n  scale_color_jama(name = \"Model Type\")+\n  scale_y_continuous(limits = c(-0.03,0.12),name = \"Net Benefit\")+\n  scale_x_continuous(limits = c(0,1),name = \"Threshold Probility\")+\n  theme_bw(base_size = 16)+\n  theme(legend.position.inside = c(0.8,0.75),\n        legend.background = element_blank()\n        )\n\n\n\n\n\n\n\n\n挺好，还是不错的，能直接返回数据的都是可以高度自定义的，配合ggplot2，你可以尽情发挥。\n在今天推荐的所有方法中，这个方法我是最喜欢的，虽然只有一段代码，连个正经的R包都没有，但是很明显这个方法的潜力最大！只要你会自己修改，那这个方法就是万能的，适合很多模型的DCA绘制！\n\n\n34.3.2 测试集\n还是首先获取测试集的预测概率：\n\n# 建立包含多个自变量的logistic模型\nmodel &lt;- glm(Cancer ~ Age + Female + Smokes, \n            family=binomial(),\n            data = train_df\n            )\n\n# 算出测试集的概率\ntest_df$prob &lt;- predict(model, type=\"response\", newdata = test_df)\n\n# 绘制多个预测变量的DCA\ndca_data1 &lt;- dca(data=test_df, outcome=\"Cancer\", predictors=\"prob\", \n          probability = T, graph = F)\n\n然后提取数据，数据转换：\n\n# 转换数据\nlibrary(tidyr)\n\ndca_df1 &lt;- dca_data1$net.benefit %&gt;% # 画图数据就藏在这里！\n  # 变成长数据,还不懂长宽数据转换这个超强操作的快去翻一下历史文章！\n  pivot_longer(cols = -threshold, names_to = \"type\", values_to = \"net_benefit\") \n\n# 看下数据结构\nstr(dca_df1)\n## tibble [297 × 3] (S3: tbl_df/tbl/data.frame)\n##  $ threshold  : num [1:297] 0.01 0.01 0.01 0.02 0.02 0.02 0.03 0.03 0.03 0.04 ...\n##  $ type       : chr [1:297] \"all\" \"none\" \"prob\" \"all\" ...\n##  $ net_benefit: num [1:297] 0.0909 0 0.0909 0.0816 0 ...\n\n画图即可：\n\nlibrary(ggplot2)\nlibrary(ggsci)\n\n# 以prob这个模型为例\n\nggplot(dca_df1, aes(threshold, net_benefit, color = type))+\n  geom_line(linewidth = 1.2)+\n  scale_color_jama(name = \"Model Type\")+ # c(\"steelblue\",\"firebrick\",\"green4\")\n  scale_y_continuous(limits = c(-0.03,0.12),name = \"Net Benefit\")+\n  #限定y轴范围是重点，你可以去掉这句看看\n  scale_x_continuous(limits = c(0,1),name = \"Threshold Probility\")+\n  theme_bw(base_size = 16)+\n  theme(legend.position.inside = c(0.8,0.8),\n        legend.background = element_blank()\n        )",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>分类数据的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-logistic.html#方法4ggdca",
    "href": "dca-logistic.html#方法4ggdca",
    "title": "34  分类数据的决策曲线",
    "section": "34.4 方法4：ggDCA",
    "text": "34.4 方法4：ggDCA\n使用ggDCA包，和上面的提取数据再画图有点像，不过它给你简化了，一句代码即可，省事儿！\n\n# 安装R包，建议安装github版本，不然会出问题\nremotes::install_github('yikeshu0611/ggDCA')\n\n\n34.4.1 训练集\n还是使用rmda包里面自带的dcaData演示。\n\nlibrary(ggDCA)\nlibrary(rmda)\n#options(datadist= dd )\n# 构建模型\nfit1 &lt;- glm(Cancer ~ Age + Female + Smokes, \n            data = train_df, family = binomial())\n\nfit2 &lt;- glm(Cancer~Age + Female + Smokes + Marker1 + Marker2,\n            data = train_df,family = binomial())\n\n画图，非常简洁！\n\nlibrary(ggplot2)\n\ndca1 &lt;- ggDCA::dca(fit1)\n\nggplot(dca1)\n\n\n\n\n\n\n\n\n大家可以使用ggplot2语法继续修改细节，在此之前先给大家看看这个dca1的数据结构。\n\nstr(dca1)\n## Classes 'dca.lrm' and 'data.frame':  182 obs. of  5 variables:\n##  $ thresholds: num  0.0242 0.0245 0.0289 0.0291 0.0344 ...\n##  $ TPR       : num  0.129 0.129 0.129 0.129 0.126 ...\n##  $ FPR       : num  0.871 0.857 0.831 0.814 0.794 ...\n##  $ NB        : num  0.1069 0.1071 0.1039 0.1041 0.0974 ...\n##  $ model     : Factor w/ 3 levels \"fit1\",\"All\",\"None\": 1 1 1 1 1 1 1 1 1 1 ...\n\n还自动算出了TPR和FPR，如果你想画ROC的话也是一句代码的事，咱就不演示了！就给大家演示下怎么自定义细节。\n\nggplot(dca1,linetype = 1,color = c(\"firebrick\",\"steelblue\",\"green4\"))+\n  theme(legend.position = c(0.8,0.75))\n\n\n\n\n\n\n\n\n多个模型画在一起也是非常简单！\n\n# 2个模型画在一起\ndca12 &lt;- ggDCA::dca(fit1,fit2)\n\nggplot(dca12, linetype = 1,\n       color = c(\"firebrick\",\"steelblue\",\"green4\",\"tomato\"))+\n  theme(legend.position = c(0.8,0.75))\n\n\n\n\n\n\n\n\n简洁强大！\n\n\n34.4.2 测试集\n也是只要1行代码即可：\n\naa &lt;- ggDCA::dca(fit1,new.data=test_df)\n\nggplot(aa)\n\n\n\n\n\n\n\n\n但是这个包画出的测试集的决策曲线和其他R包差别较大，有人建议大家慎用该方法：二分类logistic回归模型决策曲线的绘制与解读",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>分类数据的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-logistic.html#方法5dcurves",
    "href": "dca-logistic.html#方法5dcurves",
    "title": "34  分类数据的决策曲线",
    "section": "34.5 方法5：dcurves",
    "text": "34.5 方法5：dcurves\n使用dcurves包，这个包是官方基于方法2的代码写的，所以也算是一个官方的方法，虽然你没有dca.r/stdca.r，但是你可以直接使用dcurves包。\n\n# 安装,2选1\ninstall.packages(\"dcurves\")\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"ddsjoberg/dcurves\")\n\n还是使用rmda包的dcaData数据进行演示。\n\n34.5.1 训练集\n和dca.r的使用很像。废话不多说了，直接上 画2个模型DCA 的代码。\n\nlibrary(dcurves)\nlibrary(rmda)\ndata(\"dcaData\")\n\n# 建立2个模型，算出概率\nmod1 &lt;- glm(Cancer ~ Marker1 + Age + Smokes, train_df, family = binomial)\ntrain_df$model1 &lt;- predict(mod1, type=\"response\")\n\nmod2 &lt;- glm(Cancer ~ Marker1 + Marker2 + Age + Smokes + Female, \n            train_df, family = binomial)\ntrain_df$model2 &lt;- predict(mod2, type=\"response\")\n  \ndcurves::dca(Cancer ~ model1 + model2,\n             data = train_df\n             ) %&gt;% \n  plot(smooth = T,\n       show_ggplot_code = T # 显示ggplot2代码，方便大家自己调整\n       )\n## # ggplot2 code to create DCA figure -------------------------------\n## as_tibble(x) %&gt;%\n##   dplyr::filter(!is.na(net_benefit)) %&gt;%\n##   ggplot(aes(x = threshold, y = net_benefit, color = label)) +\n##   stat_smooth(method = \"loess\", se = FALSE, formula = \"y ~ x\", \n##     span = 0.2) +\n##   coord_cartesian(ylim = c(-0.0128571428571429, 0.128571428571429\n## )) +\n##   scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n##   labs(x = \"Threshold Probability\", y = \"Net Benefit\", color = \"\") +\n##   theme_bw()\n\n\n\n\n\n\n\n\n大家看到ggplot2的代码了吧？自己调整就可以了。\n\n\n34.5.2 测试集\n也是展示同时画两个曲线，只需要提前计算出预测概率即可：\n\ntest_df$model1 &lt;- predict(mod1, type=\"response\",newdata = test_df)\ntest_df$model2 &lt;- predict(mod2, type=\"response\",newdata = test_df)\n\ndcurves::dca(Cancer ~ model1 + model2,\n             data = test_df\n             ) %&gt;% \n  plot(smooth = T,\n       show_ggplot_code = T # 显示ggplot2代码，方便大家自己调整\n       )\n## # ggplot2 code to create DCA figure -------------------------------\n## as_tibble(x) %&gt;%\n##   dplyr::filter(!is.na(net_benefit)) %&gt;%\n##   ggplot(aes(x = threshold, y = net_benefit, color = label)) +\n##   stat_smooth(method = \"loess\", se = FALSE, formula = \"y ~ x\", \n##     span = 0.2) +\n##   coord_cartesian(ylim = c(-0.01, 0.1)) +\n##   scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n##   labs(x = \"Threshold Probability\", y = \"Net Benefit\", color = \"\") +\n##   theme_bw()\n\n\n\n\n\n\n\n\n今天就给大家简单介绍下logistic回归DCA的5种画法，其实还有很多，留着以后再介绍吧，实在是写不动了。。除了常见的logistic、cox，其实随机森林、决策树、lasso、xgboost、SVM等很多模型都是可以绘制DCA的，更多进阶内容可以关注公众号查看。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>分类数据的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-cox.html",
    "href": "dca-cox.html",
    "title": "35  生存数据的决策曲线",
    "section": "",
    "text": "35.1 方法1：dcurves\n使用dcurves包,使用的数据集是包自带的df_surv数据集，一共有750行，9列，其中ttcancer是时间，cancer是结局事件，TRUE代表有癌症，FALSE代表没有癌症。\n这个包是官方基于方法3的代码写的，所以也算是一个官方的方法，虽然你没有dca.r/stdca.r，但是你可以直接使用dcurves包。\n并不是只有结局事件是生存或者死亡的才叫生存资料哦！只要是time-event类型的，都可以。\nrm(list = ls())\n# 加载R包和数据\nlibrary(dcurves)\nlibrary(survival)\ndata(\"df_surv\")\n\n# 查看数据结构\ndim(df_surv)\n## [1] 750   9\nstr(df_surv)\n## tibble [750 × 9] (S3: tbl_df/tbl/data.frame)\n##  $ patientid       : num [1:750] 1 2 3 4 5 6 7 8 9 10 ...\n##  $ cancer          : logi [1:750] FALSE FALSE FALSE FALSE FALSE FALSE ...\n##  $ ttcancer        : num [1:750] 3.009 0.249 1.59 3.457 3.329 ...\n##  $ risk_group      : chr [1:750] \"low\" \"high\" \"low\" \"low\" ...\n##  $ age             : num [1:750] 64 78.5 64.1 58.5 64 ...\n##  $ famhistory      : num [1:750] 0 0 0 0 0 0 0 0 0 0 ...\n##  $ marker          : num [1:750] 0.7763 0.2671 0.1696 0.024 0.0709 ...\n##  $ cancerpredmarker: num [1:750] 0.0372 0.57891 0.02155 0.00391 0.01879 ...\n##  $ cancer_cr       : Factor w/ 3 levels \"censor\",\"diagnosed with cancer\",..: 1 1 1 1 1 1 1 2 1 1 ...\n划分训练集测试集：\nset.seed(123)\ntrain &lt;- sample(1:nrow(df_surv),nrow(df_surv) * 0.7)\ntrain_df &lt;- df_surv[train,]\ntest_df &lt;- df_surv[- train,]\n\ndim(train_df)\n## [1] 525   9\ndim(test_df)\n## [1] 225   9",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>生存数据的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-cox.html#方法1dcurves",
    "href": "dca-cox.html#方法1dcurves",
    "title": "35  生存数据的决策曲线",
    "section": "",
    "text": "35.1.1 训练集\n这个包使用起来很别扭，但是可以说它很灵活！\n如果预测变量只有1个，且是0,1表示的，那就很简单，直接用就行；如果有多个预测变量，就需要先计算出预测概率，然后才能使用。\n预测变量是famhistory，这是0,1表示的二分类变量：\n\nlibrary(ggplot2)\n\ndcurves::dca(Surv(ttcancer, cancer) ~ famhistory,\n             data = train_df,\n             time = 1 # 时间选1年\n             ) %&gt;% \n  plot(smooth = T)\n\n\n\n\n\n\n\n\n下面展示一个把多个模型的DCA画在一起的例子，和之前介绍的dca.r的用法有点类似。\ncancerpredmarker这一列已经是概率了，marker是数值型的连续性变量，famhistory是0,1表示的二分类变量。\n\ndcurves::dca(Surv(ttcancer, cancer) ~ cancerpredmarker + marker + famhistory,\n    data = train_df,\n    as_probability = \"marker\", # 只有marker需要转换成概率\n    time = 1,\n    label = list(cancerpredmarker = \"Prediction Model\", \n                 marker = \"Biomarker\")) %&gt;%\n  plot(smooth = TRUE,show_ggplot_code = T) +\n  ggplot2::labs(x = \"Treatment Threshold Probability\")\n## # ggplot2 code to create DCA figure -------------------------------\n## as_tibble(x) %&gt;%\n##   dplyr::filter(!is.na(net_benefit)) %&gt;%\n##   ggplot(aes(x = threshold, y = net_benefit, color = label)) +\n##   stat_smooth(method = \"loess\", se = FALSE, formula = \"y ~ x\", \n##     span = 0.2) +\n##   coord_cartesian(ylim = c(-0.0142882170725106, 0.142882170725106\n## )) +\n##   scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +\n##   labs(x = \"Threshold Probability\", y = \"Net Benefit\", color = \"\") +\n##   theme_bw()\n\n\n\n\n\n\n\n\n可以看到marker这个曲线有点过分了。。结果也给出了ggplot2的代码，大家可以自己修改。\n上面是多个模型在同一个时间点的DCA曲线，如果是同一个模型在不同时间点的DCA，这个包不能直接画出，需要自己整理数据，因为不同时间点进行治疗的风险和获益都是不一样的，所以会出现同一个阈值概率对应多个净获益的情况，所以none和all每个概率阈值下都有1套数据。\n如果你的预测变量是多个，就需要先计算预测概率。\n\n# 构建一个多元cox回归\ncox_model &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory + marker, \n                   data = train_df)\n\n# 计算1.5年的概率\ntrain_df$prob1 &lt;- c(1-(summary(survfit(cox_model,newdata=train_df), \n                               times=1.5)$surv))\n\n# 我们分2步，先获取数据，再用ggplot2画图\nx1 &lt;- dcurves::dca(Surv(ttcancer, cancer) ~ prob1,\n    data = train_df,\n    time = 1.5\n    )%&gt;% \n  dcurves::as_tibble()\n\n# 使用自带的画图代码\nggplot(x1, aes(x=threshold, y=net_benefit,color=variable))+\n  stat_smooth(method = \"loess\", se = FALSE, formula = \"y ~ x\", span = 0.2) +\n  coord_cartesian(ylim = c(-0.03, 0.25)) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +\n  labs(x = \"Threshold Probability\", y = \"Net Benefit\", color = \"\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n大家还可以根据自己的喜好继续调整细节。\n\n\n35.1.2 测试集\n使用思路和分类数据是一样的，也是先计算预测概率，再画图：\n\n# 在训练集构建一个多元cox回归\ncox_model &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory + marker, \n                   data = train_df)\n\n# 计算测试集1.5年的概率\ntest_df$prob1 &lt;- c(1-(summary(survfit(cox_model,newdata=test_df), \n                               times=1.5)$surv))\n\n# 先获取数据，再用ggplot2画图\nx1 &lt;- dcurves::dca(Surv(ttcancer, cancer) ~ prob1,\n    data = test_df,\n    time = 1.5\n    )%&gt;% \n  dcurves::as_tibble()\n\n# 使用自带的画图代码\nggplot(x1, aes(x=threshold, y=net_benefit,color=variable))+\n  stat_smooth(method = \"loess\", se = FALSE, formula = \"y ~ x\", span = 0.2) +\n  coord_cartesian(ylim = c(-0.03, 0.25)) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +\n  labs(x = \"Threshold Probability\", y = \"Net Benefit\", color = \"\") +\n  theme_bw()",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>生存数据的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-cox.html#方法2ggdca",
    "href": "dca-cox.html#方法2ggdca",
    "title": "35  生存数据的决策曲线",
    "section": "35.2 方法2：ggDCA",
    "text": "35.2 方法2：ggDCA\n使用ggDCA包。是这么多方法里面最简单的一个。对于同一个模型多个时间点、同一个时间点多个模型，都可以非常简单的画出来。\n如果遇到报错：no points selected for one or more curves, consider using …，请安装GitHub版本的ggDCA包，且不要同时加载其它可以做DCA的R包。\n还是使用dcurves里面的df_surv数据集作为演示。\n\n35.2.1 训练集\n直接展示多个模型的绘制方法。\n首先建立多个模型：\n\nlibrary(ggDCA)\n\n# 建立多个模型\ncox_fit1 &lt;- coxph(Surv(ttcancer, cancer) ~ famhistory+marker, \n                  data = train_df)\ncox_fit2 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory + marker, \n                  data = train_df)\ncox_fit3 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory, \n                  data = df_surv)\n\n多个模型同一时间点的DCA：\n\ndf1 &lt;- ggDCA::dca(cox_fit1, cox_fit2, cox_fit3,\n                  times = 1.5 # 1.5年，默认值是中位数\n                  )\n\nlibrary(ggsci)\n\nggplot(df1,linetype = F)+\n  scale_color_jama(name=\"Model Type\",\n                   labels=c(\"Cox 1\",\"Cox 2\",\"Cox 3\",\"All\",\"None\"))+\n  theme_bw(base_size = 14)+\n  theme(legend.position.inside = c(0.8,0.75),\n        legend.background = element_blank()\n        )\n\n\n\n\n\n\n\n\n同一个模型多个时间的DCA：\n\ndf2 &lt;- ggDCA::dca(cox_fit2,\n                  times = c(1,2,3)\n                  )\n\nggplot(df2,linetype = F)+\n  scale_color_jama(name=\"Model Type\")+\n  theme_bw()+\n  facet_wrap(~time) # 分面展示，因为不同时间点净获益是不一样的\n\n\n\n\n\n\n\n\n多个模型多个时间点：\n\ndf3 &lt;- ggDCA::dca(cox_fit1,cox_fit2,cox_fit3,\n                  times = c(1,2,3)\n                  )\n\nggplot(df3,linetype = F)+\n  scale_color_jama(name=\"Model Type\")+\n  theme_bw()+\n  facet_wrap(~time)\n\n\n\n\n\n\n\n\n非常强！如果你不会自己搞数据，就用这个！\n\n\n35.2.2 测试集\n这里直接展示多个模型多个时间点的决策曲线：\n\ndf3 &lt;- ggDCA::dca(cox_fit1,cox_fit2,cox_fit3,\n                  times = c(1,2,3),\n                  new.data = test_df # 这里提供测试集即可\n                  )\n\nggplot(df3,linetype = F)+\n  scale_color_jama(name=\"Model Type\")+\n  theme_bw()+\n  facet_wrap(~time)",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>生存数据的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-cox.html#方法3stdca.r",
    "href": "dca-cox.html#方法3stdca.r",
    "title": "35  生存数据的决策曲线",
    "section": "35.3 方法3：stdca.R",
    "text": "35.3 方法3：stdca.R\n这个方法是纪念斯隆·凯特林癌症中心给出的方法，非常正规，目前绝大多数其他实现DCA的方法都是基于此方法实现的。\n曾经，纪念斯隆·凯特林癌症中心的官网网站会让你免费下载dca.r/stdca.r这两段脚本，可分别用于二分类数据和生存数据的决策曲线分析，但是非常遗憾的是，目前该网站已不再提供代码下载了。\n\n\n\n\n\n\n注意\n\n\n\n这个网站已经不再提供该代码的下载，我很早之前就下载过了，所以我把dca.r/stdca.r这两段代码放在粉丝QQ群文件，需要的加群下载即可（免费的，别问我怎么加群）。\n但是原网站下载的stdca.r脚本在某些数据中会遇到以下报错：Error in findrow(fit,times,extend):no points selected for one or more curves, consider using the extend argument，所以我对这段脚本进行了修改，可以解决这个报错，也只能解决这个报错。但是需要付费获取，获取链接：适用于一切模型的DCA，没有任何答疑服务，介意勿扰。\n\n\n数据还是用df_surv数据集。\n\n35.3.1 训练集\n\n#rm(list = ls())\nlibrary(survival)\n#library(dcurves)\n#data(\"df_surv\")\n\n# 加载函数,这个是我修改过的\n# 原函数有时会报错:no points selected for one or more curves...\n# 获取方式：https://mp.weixin.qq.com/s/TZ7MSaPZZ0Pwomyp_7wqFw\nsource(\"E:/R/r-clinical-model/000files/stdca.R\") \n\n# 格式准备好\ntrain_df$cancer &lt;- as.numeric(train_df$cancer) # stdca函数需要结果变量是0,1\ntrain_df &lt;- as.data.frame(train_df) # stdca函数只接受data.frame\n\n# 构建一个多元cox回归\ncox_model &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory + marker, \n                   data = train_df)\n\n# 计算1.5年的概率\ntrain_df$prob1 &lt;- c(1-(summary(survfit(cox_model,newdata=train_df),\n                               times=1.5)$surv))\n\n# 这个函数我修改过，如果你遇到报错，可以通过添加参数 xstop=0.5 解决\ndd &lt;- stdca(data=train_df, outcome=\"cancer\", ttoutcome=\"ttcancer\", \n      timepoint=1.5, \n      predictors=\"prob1\",\n      smooth=TRUE\n    )\n\n\n\n\n\n\n\n\n多个模型在同一个时间点的DCA画法，和第一种方法很类似，也是要分别计算出每个模型的概率。\n\n# 建立多个模型\ncox_fit1 &lt;- coxph(Surv(ttcancer, cancer) ~ famhistory+marker, \n                  data = train_df)\ncox_fit2 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory + marker, \n                  data = train_df)\ncox_fit3 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory, \n                  data = train_df)\n\n# 计算每个模型的概率\ntrain_df$prob1 &lt;- c(1-(summary(survfit(cox_fit1, newdata=train_df), \n                              times=1.5)$surv))\ntrain_df$prob2 &lt;- c(1-(summary(survfit(cox_fit2, newdata=train_df), \n                              times=1.5)$surv))\ntrain_df$prob3 &lt;- c(1-(summary(survfit(cox_fit3, newdata=train_df), \n                              times=1.5)$surv))\n\n# 画图\ndd &lt;- stdca(data=train_df, outcome=\"cancer\", ttoutcome=\"ttcancer\", \n      timepoint=1.5, \n      predictors=c(\"prob1\",\"prob2\",\"prob3\"),  \n      smooth=TRUE\n    )\n## [1] \"prob3: No observations with risk greater than 94%, and therefore net benefit not calculable in this range.\"\n\n\n\n\n\n\n\n\n\n\n35.3.2 测试集\n思路依然是先计算概率，再画图，下面直接给大家展示多条曲线的画法。\n\n# 格式准备好\ntest_df$cancer &lt;- as.numeric(test_df$cancer) # stdca函数需要结果变量是0,1\ntest_df &lt;- as.data.frame(test_df) # stdca函数只接受data.frame\n\n# 计算每个模型的概率\ntest_df$prob1 &lt;- c(1-(summary(survfit(cox_fit1, newdata=test_df), \n                              times=1.5)$surv))\ntest_df$prob2 &lt;- c(1-(summary(survfit(cox_fit2, newdata=test_df), \n                              times=1.5)$surv))\ntest_df$prob3 &lt;- c(1-(summary(survfit(cox_fit3, newdata=test_df), \n                              times=1.5)$surv))\n\n# 画图\ndd &lt;- stdca(data=test_df, outcome=\"cancer\", ttoutcome=\"ttcancer\", \n      timepoint=1.5, \n      predictors=c(\"prob1\",\"prob2\",\"prob3\"),  \n      smooth=TRUE\n    )\n## [1] \"prob1: No observations with risk greater than 95%, and therefore net benefit not calculable in this range.\"",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>生存数据的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-cox.html#方法4diy",
    "href": "dca-cox.html#方法4diy",
    "title": "35  生存数据的决策曲线",
    "section": "35.4 方法4：DIY",
    "text": "35.4 方法4：DIY\n\n35.4.1 训练集\n返回画图数据，再用ggplot2画图：\n\ncox_dca &lt;- stdca(data = train_df, outcome = \"cancer\", ttoutcome = \"ttcancer\", \n      timepoint = 1.5, \n      predictors = c(\"prob1\",\"prob2\",\"prob3\"),\n      smooth=TRUE,\n      graph = FALSE\n    )\n## [1] \"prob3: No observations with risk greater than 94%, and therefore net benefit not calculable in this range.\"\n\nlibrary(tidyr)\n\ncox_dca_df &lt;- cox_dca$net.benefit %&gt;% \n  pivot_longer(cols = c(all,none,contains(\"sm\")),names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n\n使用ggplot2画图：\n\nlibrary(ggplot2)\nlibrary(ggsci)\n\nggplot(cox_dca_df, aes(x=threshold,y=net_benefit))+\n  geom_line(aes(color=models),linewidth=1.2)+\n  scale_color_jama(name=\"Models Types\",\n                   labels=c(\"All\",\"None\",\"Model1\",\"Model2\",\"Model3\"))+\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1),\n                     name=\"Threshold Probility\")+\n  scale_y_continuous(limits = c(-0.05,0.2),name=\"Net Benefit\")+\n  theme_bw(base_size = 14)+\n  theme(legend.background = element_blank(),\n        legend.position.inside = c(0.85,0.75)\n        )\n\n\n\n\n\n\n\n\n\n\n35.4.2 测试集\n先获取画图数据：\n\n# 格式准备好\ntest_df$cancer &lt;- as.numeric(test_df$cancer) # stdca函数需要结果变量是0,1\ntest_df &lt;- as.data.frame(test_df) # stdca函数只接受data.frame\n\n# 计算每个模型的概率\ntest_df$prob1 &lt;- c(1-(summary(survfit(cox_fit1, newdata=test_df), \n                              times=1.5)$surv))\ntest_df$prob2 &lt;- c(1-(summary(survfit(cox_fit2, newdata=test_df), \n                              times=1.5)$surv))\ntest_df$prob3 &lt;- c(1-(summary(survfit(cox_fit3, newdata=test_df), \n                              times=1.5)$surv))\n\n# 返回画图数据\ndd &lt;- stdca(data=test_df, outcome=\"cancer\", ttoutcome=\"ttcancer\", \n      timepoint=1.5, \n      predictors=c(\"prob1\",\"prob2\",\"prob3\"),  \n      smooth=TRUE, graph = F\n    )\n## [1] \"prob1: No observations with risk greater than 95%, and therefore net benefit not calculable in this range.\"\n\n# 格式整理\ncox_dca_df &lt;- dd$net.benefit %&gt;% \n  pivot_longer(cols = c(all,none,contains(\"sm\")),names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n\n使用ggplot2画图：\n\nlibrary(ggplot2)\nlibrary(ggsci)\n\nggplot(cox_dca_df, aes(x=threshold,y=net_benefit))+\n  geom_line(aes(color=models),linewidth=1.2)+\n  scale_color_jama(name=\"Models Types\",\n                   labels=c(\"All\",\"None\",\"Model1\",\"Model2\",\"Model3\"))+\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1),\n                     name=\"Threshold Probility\")+\n  scale_y_continuous(limits = c(-0.05,0.2),name=\"Net Benefit\")+\n  theme_bw(base_size = 14)+\n  theme(legend.background = element_blank(),\n        legend.position.inside = c(0.85,0.75)\n        )\n\n\n\n\n\n\n\n\n常见的DCA方法都展示了，大家自己选择使用哪个就好。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>生存数据的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-diy.html",
    "href": "dca-diy.html",
    "title": "36  适用一切模型的决策曲线",
    "section": "",
    "text": "36.1 多个时间点多个cox模型的数据提取\n其实ggDCA包完全可以做到，只要1行代码就搞定了，而且功能还很丰富。\n我给大家演示一遍基于stdca.r的方法，给大家开阔思路，代码可能不够简洁，但是思路没问题，无非就是各种数据整理与转换。\n而且很定会有人对默认结果不满意，想要各种修改，下面介绍的这个方法非常适合自己进行各种自定义！\nrm(list = ls())\nlibrary(survival)\nlibrary(dcurves)\ndata(\"df_surv\")\n\n# 加载函数\n# 原函数有问题，这个是我修改过的\n# 获取方式：https://mp.weixin.qq.com/s/TZ7MSaPZZ0Pwomyp_7wqFw\nsource(\"E:/R/r-clinical-model/000files/stdca.R\") # 原函数有问题\n\n# 构建一个多元cox回归\ndf_surv$cancer &lt;- as.numeric(df_surv$cancer) # stdca函数需要结果变量是0,1\ndf_surv &lt;- as.data.frame(df_surv) # stdca函数只接受data.frame\n建立多个模型，计算每个模型在不同时间点的概率：\n# 建立多个模型\ncox_fit1 &lt;- coxph(Surv(ttcancer, cancer) ~ famhistory+marker, \n                  data = df_surv)\ncox_fit2 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory + marker, \n                  data = df_surv)\ncox_fit3 &lt;- coxph(Surv(ttcancer, cancer) ~ age + famhistory, \n                  data = df_surv)\n\n# 计算每个模型在不同时间点的死亡概率\ndf_surv$prob11 &lt;- c(1-(summary(survfit(cox_fit1, newdata=df_surv), \n                               times=1)$surv))\ndf_surv$prob21 &lt;- c(1-(summary(survfit(cox_fit2, newdata=df_surv), \n                               times=1)$surv))\ndf_surv$prob31 &lt;- c(1-(summary(survfit(cox_fit3, newdata=df_surv), \n                               times=1)$surv))\n\ndf_surv$prob12 &lt;- c(1-(summary(survfit(cox_fit1, newdata=df_surv), \n                               times=2)$surv))\ndf_surv$prob22 &lt;- c(1-(summary(survfit(cox_fit2, newdata=df_surv), \n                               times=2)$surv))\ndf_surv$prob32 &lt;- c(1-(summary(survfit(cox_fit3, newdata=df_surv), \n                               times=2)$surv))\n\ndf_surv$prob13 &lt;- c(1-(summary(survfit(cox_fit1, newdata=df_surv), \n                               times=3)$surv))\ndf_surv$prob23 &lt;- c(1-(summary(survfit(cox_fit2, newdata=df_surv), \n                               times=3)$surv))\ndf_surv$prob33 &lt;- c(1-(summary(survfit(cox_fit3, newdata=df_surv), \n                               times=3)$surv))\n计算threshold和net benefit：\ncox_dca1 &lt;- stdca(data = df_surv, \n      outcome = \"cancer\", \n      ttoutcome = \"ttcancer\", \n      timepoint = 1, \n      predictors = c(\"prob11\",\"prob21\",\"prob31\"),\n      smooth=TRUE,\n      graph = FALSE\n    )\n## [1] \"prob31: No observations with risk greater than 99%, and therefore net benefit not calculable in this range.\"\n\ncox_dca2 &lt;- stdca(data = df_surv, \n      outcome = \"cancer\", \n      ttoutcome = \"ttcancer\", \n      timepoint = 2, \n      predictors = c(\"prob12\",\"prob22\",\"prob32\"),\n      smooth=TRUE,\n      graph = FALSE\n    )\n\ncox_dca3 &lt;- stdca(data = df_surv, \n      outcome = \"cancer\", \n      ttoutcome = \"ttcancer\", \n      timepoint = 3, \n      predictors = c(\"prob13\",\"prob23\",\"prob33\"),\n      smooth=TRUE,\n      graph = FALSE\n    )\n\n\nlibrary(tidyr)\nlibrary(dplyr)",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>适用一切模型的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-diy.html#多个时间点多个cox模型的数据提取",
    "href": "dca-diy.html#多个时间点多个cox模型的数据提取",
    "title": "36  适用一切模型的决策曲线",
    "section": "",
    "text": "36.1.1 第一种数据整理方法\n\ncox_dca_df1 &lt;- cox_dca1$net.benefit\ncox_dca_df2 &lt;- cox_dca2$net.benefit\ncox_dca_df3 &lt;- cox_dca3$net.benefit\n\nnames(cox_dca_df1)[2] &lt;- \"all1\"\nnames(cox_dca_df2)[2] &lt;- \"all2\"\nnames(cox_dca_df3)[2] &lt;- \"all3\"\n\ntmp &lt;- cox_dca_df1 %&gt;% \n  left_join(cox_dca_df2) %&gt;% \n  left_join(cox_dca_df3) %&gt;% \n  pivot_longer(cols = contains(c(\"all\",\"sm\",\"none\")),\n               names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n\n画图：\n\nlibrary(ggplot2)\nlibrary(ggsci)\n\nggplot(tmp, aes(x=threshold,y=net_benefit))+\n  geom_line(aes(color=models),linewidth=1.2)+\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1),\n                     name=\"Threshold Probility\")+\n  scale_y_continuous(limits = c(-0.05,0.3),name=\"Net Benefit\")+\n  theme_bw(base_size = 14)\n\n\n\n\n\n\n\n\n\n\n36.1.2 第二种数据整理方法\n\ncox_dca_df1 &lt;- cox_dca1$net.benefit\ncox_dca_df2 &lt;- cox_dca2$net.benefit\ncox_dca_df3 &lt;- cox_dca3$net.benefit\n\ncox_dca_long_df1 &lt;- cox_dca_df1 %&gt;% \n  rename(mod1 = prob11_sm,\n         mod2 = prob21_sm,\n         mod3 = prob31_sm\n         ) %&gt;% \n  select(-4:-6) %&gt;% \n  mutate(time = \"1\") %&gt;% \n  pivot_longer(cols = c(all,none,contains(\"mod\")),names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n\ncox_dca_long_df2 &lt;- cox_dca_df2 %&gt;% \n  rename(mod1 = prob12_sm,\n         mod2 = prob22_sm,\n         mod3 = prob32_sm\n         ) %&gt;% \n  select(-4:-6) %&gt;% \n  mutate(time = \"2\") %&gt;% \n  pivot_longer(cols = c(all,none,contains(\"mod\")),names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n\n\ncox_dca_long_df3 &lt;- cox_dca_df3 %&gt;% \n  rename(mod1 = prob13_sm,\n         mod2 = prob23_sm,\n         mod3 = prob33_sm\n         ) %&gt;% \n  select(-4:-6) %&gt;% \n  mutate(time = \"3\") %&gt;% \n  pivot_longer(cols = c(all,none,contains(\"mod\")),names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n\ntes &lt;- bind_rows(cox_dca_long_df1,cox_dca_long_df2,cox_dca_long_df3)\n\n画图：\n\nggplot(tes,aes(x=threshold,y=net_benefit))+\n  geom_line(aes(color=models,linetype=time),linewidth=1.2)+\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1),\n                     name=\"Threshold Probility\")+\n  scale_y_continuous(limits = c(-0.05,0.3),name=\"Net Benefit\")+\n  theme_bw(base_size = 14)\n\n\n\n\n\n\n\n\n这种方法可以分面。\n\nggplot(tes,aes(x=threshold,y=net_benefit))+\n  geom_line(aes(color=models),linewidth=1.2)+\n  scale_y_continuous(limits = c(-0.05,0.3),name=\"Net Benefit\")+\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1),\n                     name=\"Threshold Probility\")+\n  scale_y_continuous(limits = c(-0.05,0.3),name=\"Net Benefit\")+\n  theme_bw(base_size = 14)+\n  facet_wrap(~time)\n\n\n\n\n\n\n\n\n接下来演示其他模型的DCA实现方法，这里就以二分类变量为例，生存资料的DCA也是一样的，就是需要一个概率而已！",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>适用一切模型的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-diy.html#lasso回归",
    "href": "dca-diy.html#lasso回归",
    "title": "36  适用一切模型的决策曲线",
    "section": "36.2 lasso回归",
    "text": "36.2 lasso回归\n\nrm(list = ls())\nlibrary(glmnet)\nlibrary(tidyverse)\n\n准备数据，这是从TCGA下载的一部分数据，其中sample_type是样本类型，1代表tumor，0代表normal，我们首先把因变量变为0,1。然后划分训练集和测试集。\n\ndf &lt;- readRDS(file = \"./datasets/df_example.rds\")\n\ndf &lt;- df %&gt;% \n  select(-c(2:3)) %&gt;% \n  mutate(sample_type = ifelse(sample_type==\"Tumor\",1,0))\n\nset.seed(123)\nind &lt;- sample(1:nrow(df),nrow(df)*0.6)\n\ntrain_df &lt;- df[ind,]\ntest_df &lt;- df[-ind,]\n\n构建lasso回归需要的参数值。\n\nx &lt;- as.matrix(train_df[,-1])\ny &lt;- train_df$sample_type\n\n在训练集建立lasso回归模型：\n\ncvfit = cv.glmnet(x, y, family = \"binomial\")\nplot(cvfit)\n\n\n\n\n\n\n\n\n在测试集上查看模型表现：\n\nprob_lasso &lt;- predict(cvfit,\n                      newx = as.matrix(test_df[,-1]),\n                      s=\"lambda.1se\",\n                      type=\"response\") #返回概率\n\n然后进行DCA，也是基于测试集的：\n\nsource(\"./datasets/dca.r\")\n\ntest_df$lasso &lt;- prob_lasso\n\ndf_lasso &lt;- dca(data = test_df, # 指定数据集,必须是data.frame类型\n    outcome=\"sample_type\", # 指定结果变量\n    predictors=\"lasso\", # 指定预测变量\n    probability = T\n    )\n\n\n\n\n\n\n\n\n这就是lasso的DCA，由于数据和模型原因，这个DCA看起来很诡异，大家千万要理解实现方法！\n\nlibrary(ggplot2)\nlibrary(ggsci)\nlibrary(tidyr)\n\ndf_lasso$net.benefit %&gt;% \n  pivot_longer(cols = -threshold, \n               names_to = \"type\", \n               values_to = \"net_benefit\") %&gt;% \n  ggplot(aes(threshold, net_benefit, color = type))+\n  geom_line(linewidth = 1.2)+\n  scale_color_jama(name = \"Model Type\")+ \n  scale_y_continuous(limits = c(-0.02,1),name = \"Net Benefit\")+ \n  scale_x_continuous(limits = c(0,1),name = \"Threshold Probility\")+\n  theme_bw(base_size = 16)+\n  theme(legend.position.inside = c(0.2,0.3),\n        legend.background = element_blank()\n        )",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>适用一切模型的决策曲线</span>"
    ]
  },
  {
    "objectID": "dca-diy.html#随机森林",
    "href": "dca-diy.html#随机森林",
    "title": "36  适用一切模型的决策曲线",
    "section": "36.3 随机森林",
    "text": "36.3 随机森林\n思路完全一样，首先建立随机森林模型，然后计算预测概率（训练集或者测试集都是可以计算的），然后画图即可。\n\nlibrary(ranger)\n\nrf &lt;- ranger(sample_type ~ ., data = train_df)\n\n# 获取测试集的概率\nprob_rf &lt;- predict(rf,test_df[,-1],type = \"response\")$predictions\n\ntest_df$rf &lt;- prob_rf\n\ndf_rf &lt;- dca(data = test_df, # 指定数据集,必须是data.frame类型\n    outcome=\"sample_type\", # 指定结果变量\n    predictors=\"rf\", # 指定预测变量\n    probability = T,\n    graph = F\n    )\n\n画图即可：\n\ndf_rf$net.benefit %&gt;% \n  pivot_longer(cols = -threshold, \n               names_to = \"type\", \n               values_to = \"net_benefit\") %&gt;% \n  ggplot(aes(threshold, net_benefit, color = type))+\n  geom_line(linewidth = 1.2)+\n  scale_color_jama(name = \"Model Type\")+ \n  scale_y_continuous(limits = c(-0.02,1),name = \"Net Benefit\")+ \n  scale_x_continuous(limits = c(0,1),name = \"Threshold Probility\")+\n  theme_bw(base_size = 16)+\n  theme(legend.position = c(0.2,0.3),\n        legend.background = element_blank()\n        )\n\n\n\n\n\n\n\n\n还有其他比如支持向量机等，就不一一介绍了，实现原理都是一样的，就是需要一个概率而已。\n如果是生存分析的话，会比较复杂一点，因为真实概率不好计算，需要指定一个时间点。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>适用一切模型的决策曲线</span>"
    ]
  },
  {
    "objectID": "DCA彩色条带.html",
    "href": "DCA彩色条带.html",
    "title": "37  决策曲线添加彩色条带",
    "section": "",
    "text": "前面给大家介绍了如何给列线图增加彩色的危险分层条带，详情请见：列线图增加彩色风险分层\n\n并且还介绍了如何根据列线图计算每个患者的得分，并根据得分进行最佳危险分层，请见：根据列线图计算分数并进行危险分层\n今天介绍如何为决策曲线添加彩色条带，实现类似于下图的效果：\n\n这张列线图来自于这篇文章：Nomograms in oncology: more than meets the eye，DOI：10.1016/S1470-2045(14)71116-7\n这张图在底部增加了两种颜色的条带，分别是Nomogram relevant和Nomogram not relevant。\n通常在解读列线图时，我们需要汇报到底在哪个阈值区间内，我们的模型是更有临床意义的，在这个区间内也就是上图中的Nomogram relevant，不在这个区间内就是Nomogram not relevant。\n理解这点之后，画图就很简单了。\n首先我们看看常规的决策曲线画法。先看看默认的出图：\n\nrm(list = ls())\nlibrary(survival)\nlibrary(dcurves)\ndata(\"df_surv\")\n\n# 加载函数\nsource(\"E:/R/r-clinical-model/000files/stdca.R\") \n\n# 构建一个多元cox回归\ndf_surv$cancer &lt;- as.numeric(df_surv$cancer) # stdca函数需要结果变量是0,1\ndf_surv &lt;- as.data.frame(df_surv) # stdca函数只接受data.frame\n\ncox_model &lt;- coxph(Surv(ttcancer, cancer) ~ famhistory + marker, \n                   data = df_surv)\n\n# 计算1.5年的概率\ndf_surv$prob1 &lt;- c(1-(summary(survfit(cox_model, newdata=df_surv), \n                              times=1.5)$surv))\n\n# 这个函数我修改过，如果你遇到报错，可以通过添加参数 xstop=0.5 解决\ncox_dca &lt;- stdca(data=df_surv, \n      outcome=\"cancer\", \n      ttoutcome=\"ttcancer\", \n      timepoint=1.5, \n      predictors=\"prob1\",\n      smooth=TRUE,\n      xby = 0.001,\n      ymin = -0.1\n    )\n\n\n\n\n\n\n\n\n这个默认的出图不是很好看，我们可以自己提取数据，然后使用ggplot2画：\n\nlibrary(tidyr)\n\ncox_dca_df &lt;- cox_dca$net.benefit %&gt;% \n  pivot_longer(cols = c(all,none,prob1_sm),names_to = \"models\",\n               values_to = \"net_benefit\"\n               )\n\n使用ggplot2画图：\n\nlibrary(ggplot2)\nlibrary(ggsci)\n\np1 &lt;- ggplot(cox_dca_df)+\n  geom_line(aes(x=threshold,y=net_benefit,color=models),linewidth=1.2)+\n  scale_color_jama(name=\"Models Types\",\n                   labels=c(\"All\",\"None\",\"Model1\"))+\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1),\n                     name=\"Threshold Probility\")+\n  scale_y_continuous(limits = c(-0.1,0.2),name=\"Net Benefit\")+\n  theme_bw(base_size = 14)+\n  theme(legend.background = element_blank(),\n        legend.position.inside = c(0.85,0.75)\n        )\np1\n\n\n\n\n\n\n\n\n添加彩色条带的思路也很简单，就是在合适的位置添加矩形色块即可。\n首先我们查看下这个合适的阈值区间是多少。左侧的阈值应该就是在相同的横坐标下，Model1的net-benefit开始大于All的位置，右侧阈值应该是Model1的net-benefit开始小于0的位置。\n我们直接查看下数据即可，最简单的方法，肉眼看一下。前面在使用ggplot2画图时已经把数据都提取好了，就是cox_dca_df这个数据。\n左侧的阈值大概在0.1左右，右侧的阈值大概在0.7左右。因为没有恰好相等的情况，所以只能取个大概的阈值。\n左侧阈值：\n\n右侧阈值，0.707的净获益还是正数，0.708的净获益就是负数了，所以这个阈值应该是在0.707~0.708之间，我们就取个大约的数字，0.7。\n\n有了这两个阈值就是有了矩形的坐标，所以下面再准备3个矩形的坐标即可，如果是ggplot2画的图，就用geom_rect()添加矩形。\n\n# 准备3个矩形的坐标\nrect_df1 &lt;- data.frame(xmin = 0,\n                      xmax = 0.1,\n                      ymin = -0.05,\n                      ymax = -0.1\n                      )\nrect_df2 &lt;- data.frame(xmin = 0.1,\n                      xmax = 0.7,\n                      ymin = -0.05,\n                      ymax = -0.1\n                      )\nrect_df3 &lt;- data.frame(xmin = 0.7,\n                      xmax = 1,\n                      ymin = -0.05,\n                      ymax = -0.1\n                      )\n\n解释说明的文字直接使用annotate()函数添加即可：\n\np2 &lt;- p1+\n  geom_rect(data = rect_df1, \n            mapping = aes(xmin = xmin, xmax=xmax,ymin=ymin,ymax=ymax),\n            fill = \"#0151a2\")+\n  geom_rect(data = rect_df2, \n            mapping = aes(xmin = xmin, xmax=xmax,ymin=ymin,ymax=ymax),\n            fill = \"#c01e35\")+\n  geom_rect(data = rect_df3, \n            mapping = aes(xmin = xmin, xmax=xmax,ymin=ymin,ymax=ymax),\n            fill = \"#0151a2\")+\n  annotate(geom = \"text\", label = \"Nomogram relevant\", \n           x = 0.4, y = -0.075,\n           size = 4.5, color = \"white\")+\n  annotate(geom = \"text\", label = \"Nomogram irrelevant\", \n           x = 0.85, y = -0.075,\n           size = 4.5, color = \"white\")\np2\n\n\n\n\n\n\n\n\n是不是很easy呢？\n还可以再添加2条竖线，使图形更容易理解：\n\n# 准备2条竖线坐标\nline_df &lt;- data.frame(x = c(0.1,0.7),\n                      ymin = c(-0.05,-0.05),\n                      ymax = c(0.13,0)\n                      )\n\n添加竖线：\n\np2+geom_linerange(data = line_df, mapping = aes(x=x,ymin=ymin,ymax=ymax),\n                  linetype = 2, linewidth = 1.2\n                  )\n\n\n\n\n\n\n\n\n如果是默认的出图，那就更简单了，因为都是R语言默认的画图引擎，支持所有base r画图语法，和之前列线图添加彩色条带的方法一模一样：\n\ncox_dca &lt;- stdca(data=df_surv, \n      outcome=\"cancer\", \n      ttoutcome=\"ttcancer\", \n      timepoint=1.5, \n      predictors=\"prob1\",\n      smooth=TRUE,\n      xby = 0.001,\n      ymin = -0.1\n    )\n# 添加条带\nrect(xleft = 0,xright = 0.1,ybottom = -0.05,ytop = -0.1,\n     col = \"#0151a2\",border = NA)\nrect(xleft = 0.1,xright = 0.7,ybottom = -0.05,ytop = -0.1,\n     col = \"#c01e35\",border = NA)\nrect(xleft = 0.7,xright = 1,ybottom = -0.05,ytop = -0.1,\n     col = \"#0151a2\",border = NA)\n\n# 添加文字\ntext(x = 0.4, y = -0.075, labels=\"Nomogram relevant\",col=\"white\")\ntext(x = 0.85, y = -0.075, labels=\"Nomogram relevant\",col=\"white\")\n\n\n\n\n\n\n\n\n搞定！",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>决策曲线添加彩色条带</span>"
    ]
  },
  {
    "objectID": "bootstrap一切指标.html",
    "href": "bootstrap一切指标.html",
    "title": "38  bootstrap一切指标",
    "section": "",
    "text": "38.1 加载数据和R包\n演示数据为印第安人糖尿病数据集，这个数据一共有768行，9列，其中diabetes是结果变量，为二分类，其余列是预测变量。\nrm(list = ls())\n\nload(file = \"datasets/pimadiabetes.rdata\")\n\ndim(pimadiabetes)\n## [1] 768   9\nstr(pimadiabetes)\n## 'data.frame':    768 obs. of  9 variables:\n##  $ pregnant: num  6 1 8 1 0 5 3 10 2 8 ...\n##  $ glucose : num  148 85 183 89 137 116 78 115 197 125 ...\n##  $ pressure: num  72 66 64 66 40 ...\n##  $ triceps : num  35 29 22.9 23 35 ...\n##  $ insulin : num  202.2 64.6 217.1 94 168 ...\n##  $ mass    : num  33.6 26.6 23.3 28.1 43.1 ...\n##  $ pedigree: num  0.627 0.351 0.672 0.167 2.288 ...\n##  $ age     : num  50 31 32 21 33 30 26 29 53 54 ...\n##  $ diabetes: Factor w/ 2 levels \"pos\",\"neg\": 2 1 2 1 2 1 2 1 2 2 ...\n各个变量的含义：\nlibrary(tidymodels)",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>bootstrap一切指标</span>"
    ]
  },
  {
    "objectID": "bootstrap一切指标.html#加载数据和r包",
    "href": "bootstrap一切指标.html#加载数据和r包",
    "title": "38  bootstrap一切指标",
    "section": "",
    "text": "pregnant：怀孕次数\nglucose：血浆葡萄糖浓度（葡萄糖耐量试验）\npressure：舒张压（毫米汞柱）\ntriceps：三头肌皮褶厚度（mm）\ninsulin：2小时血清胰岛素（mu U/ml）\nmass：BMI\npedigree：糖尿病谱系功能，是一种用于预测糖尿病发病风险的指标，该指标是基于家族史的糖尿病遗传风险因素的计算得出的。它计算了患者的家族成员是否患有糖尿病以及他们与患者的亲缘关系，从而得出一个综合评分，用于预测患糖尿病的概率。\nage：年龄\ndiabetes：是否有糖尿病",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>bootstrap一切指标</span>"
    ]
  },
  {
    "objectID": "bootstrap一切指标.html#数据划分和模型选择",
    "href": "bootstrap一切指标.html#数据划分和模型选择",
    "title": "38  bootstrap一切指标",
    "section": "38.2 数据划分和模型选择",
    "text": "38.2 数据划分和模型选择\n划分训练集、测试集。\n\nset.seed(123)\nsplit &lt;- initial_split(pimadiabetes, prop = 0.7, strata = diabetes)\n\ntrain &lt;- training(split)\ntest &lt;- testing(split)\n\ndim(train)\n## [1] 537   9\ndim(test)\n## [1] 231   9\n\n模型选择随机森林模型，如果你想用其他模型，就换其他模型就好了：\n\nrf_spec &lt;- rand_forest(engine = \"ranger\",mode = \"classification\",trees = 200)\n\n下面就是建立工作流：\n\nrf_rec &lt;- recipe(diabetes ~ ., data = pimadiabetes)\n\nrf_wf &lt;- workflow(preprocessor = rf_rec, spec = rf_spec)",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>bootstrap一切指标</span>"
    ]
  },
  {
    "objectID": "bootstrap一切指标.html#内部重抽样和建模",
    "href": "bootstrap一切指标.html#内部重抽样和建模",
    "title": "38  bootstrap一切指标",
    "section": "38.3 内部重抽样和建模",
    "text": "38.3 内部重抽样和建模\n选择内部重抽样方法，这里就选大家最常问的bootstrap法，bootstrap的次数为1000次！\n\nset.seed(1223)\nresampling &lt;- bootstraps(train, times = 1000)\n\n建立模型，评价指标把能选的都选上，主打一个大而全：\n\nctrl &lt;- control_resamples(verbose = F, save_pred = T)\n\nset.seed(123)\nres &lt;- fit_resamples(rf_wf,\n                     resamples = resampling,\n                     # 常见的指标都选上！\n                     metrics = metric_set(roc_auc, sens, spec, mcc, f_meas, \n                                          j_index, brier_class, precision,\n                                          accuracy, pr_auc, mn_log_loss,\n                                          brier_class),\n                     control = ctrl)\n\n由于版本不同，有些人复制粘贴这段代码可能会报错，没关系，看下帮助文档即可（或者直接不写metrics这个参数，它有默认值的），小问题！",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>bootstrap一切指标</span>"
    ]
  },
  {
    "objectID": "bootstrap一切指标.html#查看结果",
    "href": "bootstrap一切指标.html#查看结果",
    "title": "38  bootstrap一切指标",
    "section": "38.4 查看结果",
    "text": "38.4 查看结果\n查看各个指标的结果：\n\ncollect_metrics(res)\n## # A tibble: 11 × 6\n##    .metric     .estimator  mean     n  std_err .config             \n##    &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n##  1 accuracy    binary     0.762  1000 0.000778 Preprocessor1_Model1\n##  2 brier_class binary     0.154  2000 0.000258 Preprocessor1_Model1\n##  3 f_meas      binary     0.821  1000 0.000654 Preprocessor1_Model1\n##  4 j_index     binary     0.459  1000 0.00181  Preprocessor1_Model1\n##  5 mcc         binary     0.469  1000 0.00169  Preprocessor1_Model1\n##  6 mn_log_loss binary     0.463  1000 0.000944 Preprocessor1_Model1\n##  7 pr_auc      binary     0.914  1000 0.000518 Preprocessor1_Model1\n##  8 precision   binary     0.805  1000 0.00109  Preprocessor1_Model1\n##  9 roc_auc     binary     0.843  1000 0.000702 Preprocessor1_Model1\n## 10 sens        binary     0.841  1000 0.00116  Preprocessor1_Model1\n## 11 spec        binary     0.618  1000 0.00208  Preprocessor1_Model1\n\n这个就是内部重抽样（重抽样方法选择的是1000次的bootstrap）得到的各种指标。\n通过统计学中学过的点估计和区间估计法计算置信区间：置信区间=均值±z*标准误\n95%置信区间是的z=1.96，是不是很熟悉的数字？\n\n# 计算95%的置信区间\ncollect_metrics(res) %&gt;% \n  dplyr::select(c(1,3,5)) %&gt;% \n  mutate(lower = mean - 1.96*std_err,\n         upper = mean + 1.96*std_err)\n## # A tibble: 11 × 5\n##    .metric      mean  std_err lower upper\n##    &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n##  1 accuracy    0.762 0.000778 0.761 0.764\n##  2 brier_class 0.154 0.000258 0.154 0.155\n##  3 f_meas      0.821 0.000654 0.820 0.823\n##  4 j_index     0.459 0.00181  0.455 0.462\n##  5 mcc         0.469 0.00169  0.466 0.473\n##  6 mn_log_loss 0.463 0.000944 0.461 0.465\n##  7 pr_auc      0.914 0.000518 0.913 0.915\n##  8 precision   0.805 0.00109  0.803 0.807\n##  9 roc_auc     0.843 0.000702 0.842 0.845\n## 10 sens        0.841 0.00116  0.839 0.843\n## 11 spec        0.618 0.00208  0.614 0.622\n\n但是使用这种方法计算置信区间说明“你默认这个数据是符合t分布的”，但实际上很多数据是不符合的，但是也没关系，这个方法也是正确的。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>bootstrap一切指标</span>"
    ]
  },
  {
    "objectID": "bootstrap一切指标.html#bootstrap分位数法",
    "href": "bootstrap一切指标.html#bootstrap分位数法",
    "title": "38  bootstrap一切指标",
    "section": "38.5 bootstrap分位数法",
    "text": "38.5 bootstrap分位数法\n由于我们选择了1000次的bootstrap法，所以对于每个指标，都会得到1000个值，上面的计算置信区间的方法就是默认：对于每个指标的1000个值，符合t分布。\n除此之外，我们还可以使用分位数法计算每个指标的95%置信区间。比如对于AUC这个指标，我们先提取出这1000个值，然后给大家画个图看看它们的分布：\n\nres2 &lt;- collect_metrics(res, summarize = F) # 获取每个指标的1000个值\nres2 %&gt;% filter(.metric == \"roc_auc\") %&gt;% # 只选择auc这个指标\n  ggplot(aes(x = .estimate))+ # 画个图看看分布\n  geom_histogram(fill=\"grey\",color=\"blue\")+\n  labs(x=\"AUC\")\n\n\n\n\n\n\n\n\n上面这个图就是1000个AUC的分布，我们可以基于这1000个值，计算它的2.5%和97.5%分位数，这样就得到AUC的95%置信区间了：\n\nci_95 &lt;- res2 %&gt;% filter(.metric == \"roc_auc\") %&gt;%\n  pull(.estimate) %&gt;% \n  quantile(probs = c(0.025,0.975))\nci_95\n##      2.5%     97.5% \n## 0.7993783 0.8877514\n\n分位数法是最常见的计算置信区间的方法。我们把置信区间画在图中：\n\nres2 %&gt;% filter(.metric == \"roc_auc\") %&gt;% # 只选择auc这个指标\n  ggplot(aes(x = .estimate))+ # 画个图看看分布\n  geom_histogram(fill=\"grey\",color=\"blue\")+\n  geom_vline(xintercept = ci_95,color=\"red\")+\n  labs(x=\"AUC\")\n\n\n\n\n\n\n\n\n通过同样的方法就可以很方便的计算出所有指标的置信区间了：\n\nci_95_all &lt;- res2 %&gt;% group_nest(.metric) %&gt;% \n  mutate(me = map(data, ~ pull(.x, .estimate)),\n         ci95 = map_df(me, quantile, probs=c(0.025,0.975))\n         ) %&gt;% \n  dplyr::select(.metric, ci95) %&gt;% \n  unnest(ci95)\nci_95_all\n## # A tibble: 11 × 3\n##    .metric     `2.5%` `97.5%`\n##    &lt;chr&gt;        &lt;dbl&gt;   &lt;dbl&gt;\n##  1 accuracy     0.712   0.812\n##  2 brier_class  0.132   0.177\n##  3 f_meas       0.780   0.862\n##  4 j_index      0.344   0.567\n##  5 mcc          0.363   0.575\n##  6 mn_log_loss  0.407   0.522\n##  7 pr_auc       0.879   0.946\n##  8 precision    0.734   0.868\n##  9 roc_auc      0.799   0.888\n## 10 sens         0.766   0.913\n## 11 spec         0.492   0.742\n\n这种方法非常正宗，得到的结果绝对可靠而且易于解释和理解。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>bootstrap一切指标</span>"
    ]
  },
  {
    "objectID": "bootstrap一切指标.html#bootstrap各种曲线",
    "href": "bootstrap一切指标.html#bootstrap各种曲线",
    "title": "38  bootstrap一切指标",
    "section": "38.6 bootstrap各种曲线",
    "text": "38.6 bootstrap各种曲线\n顺便再画个bootstrap-ROC曲线在，真的是像探囊取物一般简单！\n\ncollect_predictions(res) %&gt;% \n  #filter(id == \"Bootstrap002\") %&gt;% \n  group_by(id) %&gt;% \n  roc_curve(truth = diabetes, .pred_pos) %&gt;% \n  ggplot(aes(1-specificity, sensitivity))+\n  geom_path(alpha=0.2,aes(group=id))+\n  geom_abline(slope = 1,intercept = 0,linetype=2)+\n  coord_fixed()+\n  theme_bw()\n\n\n\n\n\n\n\n\n顺手再来个1000次bootstrap的PR曲线：\n\ncollect_predictions(res) %&gt;% \n  #filter(id == \"Bootstrap002\") %&gt;% \n  group_by(id) %&gt;% \n  pr_curve(truth = diabetes, .pred_pos) %&gt;% \n  ggplot(aes(recall, precision))+\n  geom_path(alpha=0.2,aes(group=id))+\n  geom_abline(slope = 1,intercept = 0,linetype=2)+\n  coord_fixed()+\n  theme_bw()\n\n\n\n\n\n\n\n\n你还想要lift-curve和gain-curve吗？我就不再重复了，因为太简单了！\n顺手再画个校准曲线，也是1行代码搞定：\n\nlibrary(probably)\nlibrary(ggplot2)\n\n# 带95%置信区间的校准曲线，这个不是bootstrap法\ncal_plot_breaks(res,conf_level = 0.95)\n\n\n\n\n\n\n\n\n这些指标和各种曲线，都是内部验证集的，且都使用了1000次bootstrap的内部重抽样方法，是不是非常easy呢？",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>bootstrap一切指标</span>"
    ]
  },
  {
    "objectID": "bootstrap一切指标.html#更通用的方法",
    "href": "bootstrap一切指标.html#更通用的方法",
    "title": "38  bootstrap一切指标",
    "section": "38.7 更通用的方法",
    "text": "38.7 更通用的方法\n但是如果我们一开始采用的重抽样方法是交叉验证法或者单个验证集法，没有使用bootstrap法，那么这种方法就不能用了。\n所以这里会给大家介绍一种更为通用的方法，用于计算bootstrap法的置信区间，你即使没有使用bootstrap法进行内部重抽样，依然可以计算出bootstrap的置信区间。\n我们可以直接使用int_pctl()函数计算bootstrap分位数法的置信区间：\n\n# 通过bootstrap分位数法计算置信区间\nset.seed(123)\nres_boot &lt;- int_pctl(res, alpha = 0.05, times = 1000)\nres_boot\n## # A tibble: 11 × 6\n##    .metric     .estimator .lower .estimate .upper .config             \n##    &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;               \n##  1 accuracy    bootstrap   0.728     0.767  0.803 Preprocessor1_Model1\n##  2 brier_class bootstrap   0.133     0.148  0.165 Preprocessor1_Model1\n##  3 f_meas      bootstrap   0.790     0.826  0.854 Preprocessor1_Model1\n##  4 j_index     bootstrap   0.379     0.463  0.540 Preprocessor1_Model1\n##  5 mcc         bootstrap   0.394     0.476  0.553 Preprocessor1_Model1\n##  6 mn_log_loss bootstrap   0.411     0.448  0.490 Preprocessor1_Model1\n##  7 pr_auc      bootstrap   0.894     0.919  0.940 Preprocessor1_Model1\n##  8 precision   bootstrap   0.760     0.804  0.844 Preprocessor1_Model1\n##  9 roc_auc     bootstrap   0.820     0.853  0.883 Preprocessor1_Model1\n## 10 sens        bootstrap   0.813     0.849  0.886 Preprocessor1_Model1\n## 11 spec        bootstrap   0.541     0.614  0.682 Preprocessor1_Model1\n\n这样就直接得到了所有指标的95%置信区间（.lower和.upper），虽然结果和上面计算的不太一样（计算过程不一样），但是都是对的，而且也是bootstrap分位数法。\n就像我们上面说的，如果你一开始采用的内部重抽样方法不是bootstrap法，这种方法依然适用。\n比如我们使用5折交叉验证法：\n\n# 5折交叉验证法\nset.seed(123)\nres_fold &lt;- fit_resamples(rf_wf,\n                     resamples = vfold_cv(train,5),\n                     #metrics = \"roc_auc\",\n                     control = ctrl)\n# 依然适用\nset.seed(123)\nbootresfold &lt;- int_pctl(res_fold, times = 1000,alpha = 0.05)\nbootresfold\n## # A tibble: 3 × 6\n##   .metric     .estimator .lower .estimate .upper .config             \n##   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;               \n## 1 accuracy    bootstrap   0.723     0.761  0.797 Preprocessor1_Model1\n## 2 brier_class bootstrap   0.137     0.153  0.171 Preprocessor1_Model1\n## 3 roc_auc     bootstrap   0.810     0.843  0.875 Preprocessor1_Model1\n\n结果也给出了3个指标各自的95%置信区间！",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>bootstrap一切指标</span>"
    ]
  },
  {
    "objectID": "bootstrap一切指标.html#外部验证集的置信区间",
    "href": "bootstrap一切指标.html#外部验证集的置信区间",
    "title": "38  bootstrap一切指标",
    "section": "38.8 外部验证集的置信区间",
    "text": "38.8 外部验证集的置信区间\n如果你想获得外部验证集的bootstrap法置信区间，也是非常简单，tidymodels的作者作为生物统计专业的博士，早就为我们想好了。\n首先是按照平常的步骤获取测试集（也就是外部验证集，也就是拟合模型时没用过的数据集）的性能指标：\n\n# 在训练集建模，在测试集（即外部验证集）预测\ntest_res &lt;- rf_wf %&gt;% \n  last_fit(split)\n\n# 获取测试集（即外部验证集）的性能指标\ncollect_metrics(test_res)\n## # A tibble: 3 × 4\n##   .metric     .estimator .estimate .config             \n##   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n## 1 accuracy    binary         0.771 Preprocessor1_Model1\n## 2 roc_auc     binary         0.842 Preprocessor1_Model1\n## 3 brier_class binary         0.155 Preprocessor1_Model1\n\n对于这个结果，int_pctl()函数依然适用：\n\nset.seed(123)\nint_pctl(test_res, alpha = 0.05, times = 1000)\n## # A tibble: 3 × 6\n##   .metric     .estimator .lower .estimate .upper .config             \n##   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;               \n## 1 accuracy    bootstrap   0.719     0.772  0.831 Preprocessor1_Model1\n## 2 brier_class bootstrap   0.129     0.154  0.181 Preprocessor1_Model1\n## 3 roc_auc     bootstrap   0.786     0.843  0.896 Preprocessor1_Model1\n\n搞定，大功告成！\n\n数据如何获取？老规矩，粉丝qq群文件自取。",
    "crumbs": [
      "临床预测模型的评价",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>bootstrap一切指标</span>"
    ]
  },
  {
    "objectID": "model-compare_workflow.html",
    "href": "model-compare_workflow.html",
    "title": "39  tidymodels实现多模型比较",
    "section": "",
    "text": "39.1 加载数据和R包\n今天用的这份数据，结果变量是一个二分类的。一共有91976行，26列，其中play_type是结果变量，因子型，其余列都是预测变量。\nrm(list = ls())\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(kknn)\ntidymodels_prefer()\n\n# 加载数据\nall_plays &lt;- read_rds(\"./datasets/all_plays.rds\")\nglimpse(all_plays)\n## Rows: 91,976\n## Columns: 26\n## $ game_id                    &lt;dbl&gt; 2017090700, 2017090700, 2017090700, 2017090…\n## $ posteam                    &lt;chr&gt; \"NE\", \"NE\", \"NE\", \"NE\", \"NE\", \"NE\", \"NE\", \"…\n## $ play_type                  &lt;fct&gt; pass, pass, run, run, pass, run, pass, pass…\n## $ yards_gained               &lt;dbl&gt; 0, 8, 8, 3, 19, 5, 16, 0, 2, 7, 0, 3, 10, 0…\n## $ ydstogo                    &lt;dbl&gt; 10, 10, 2, 10, 7, 10, 5, 2, 2, 10, 10, 10, …\n## $ down                       &lt;ord&gt; 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 1, 2, 3, 1, 2…\n## $ game_seconds_remaining     &lt;dbl&gt; 3595, 3589, 3554, 3532, 3506, 3482, 3455, 3…\n## $ yardline_100               &lt;dbl&gt; 73, 73, 65, 57, 54, 35, 30, 2, 2, 75, 32, 3…\n## $ qtr                        &lt;ord&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n## $ posteam_score              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7…\n## $ defteam                    &lt;chr&gt; \"KC\", \"KC\", \"KC\", \"KC\", \"KC\", \"KC\", \"KC\", \"…\n## $ defteam_score              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0…\n## $ score_differential         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, -7, 7, 7, 7, 7, …\n## $ shotgun                    &lt;fct&gt; 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0…\n## $ no_huddle                  &lt;fct&gt; 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n## $ posteam_timeouts_remaining &lt;fct&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n## $ defteam_timeouts_remaining &lt;fct&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n## $ wp                         &lt;dbl&gt; 0.5060180, 0.4840546, 0.5100098, 0.5529816,…\n## $ goal_to_go                 &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n## $ half_seconds_remaining     &lt;dbl&gt; 1795, 1789, 1754, 1732, 1706, 1682, 1655, 1…\n## $ total_runs                 &lt;dbl&gt; 0, 0, 0, 1, 2, 2, 3, 3, 3, 0, 4, 4, 4, 5, 5…\n## $ total_pass                 &lt;dbl&gt; 0, 1, 2, 2, 2, 3, 3, 4, 5, 0, 5, 6, 7, 7, 8…\n## $ previous_play              &lt;fct&gt; First play of Drive, pass, pass, run, run, …\n## $ in_red_zone                &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1…\n## $ in_fg_range                &lt;fct&gt; 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1…\n## $ two_min_drill              &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>tidymodels实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_workflow.html#数据划分",
    "href": "model-compare_workflow.html#数据划分",
    "title": "39  tidymodels实现多模型比较",
    "section": "39.2 数据划分",
    "text": "39.2 数据划分\n把75%的数据用于训练集，剩下的做测试集。\n\nset.seed(20220520)\n\n# 数据划分，根据play_type分层\nsplit_pbp &lt;- initial_split(all_plays, 0.75, strata = play_type)\n\ntrain_data &lt;- training(split_pbp) # 训练集\ntest_data &lt;- testing(split_pbp) # 测试集\n\ndim(train_data)\n## [1] 68981    26\ndim(test_data)\n## [1] 22995    26",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>tidymodels实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_workflow.html#数据预处理",
    "href": "model-compare_workflow.html#数据预处理",
    "title": "39  tidymodels实现多模型比较",
    "section": "39.3 数据预处理",
    "text": "39.3 数据预处理\n我们对这个数据进行一些简单的预处理：\n\n去掉一些没用的变量\n把一些变量从字符型变成因子型\n去掉高度相关的变量\n数值型变量进行中心化\n去掉零方差变量\n\n\npbp_rec &lt;- recipe(play_type ~ ., data = train_data)  %&gt;%\n  step_rm(half_seconds_remaining,yards_gained, game_id) %&gt;% \n  step_string2factor(posteam, defteam) %&gt;%  \n  step_corr(all_numeric(), threshold = 0.7) %&gt;% \n  step_center(all_numeric()) %&gt;%  \n  step_zv(all_predictors())",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>tidymodels实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_workflow.html#选择模型",
    "href": "model-compare_workflow.html#选择模型",
    "title": "39  tidymodels实现多模型比较",
    "section": "39.4 选择模型",
    "text": "39.4 选择模型\n直接选择4个模型，你想选几个都是可以的。\n\n# 逻辑回归模型\nlm_mod &lt;- logistic_reg(mode = \"classification\",engine = \"glm\")\n# K最近邻模型\nknn_mod &lt;- nearest_neighbor(mode = \"classification\", engine = \"kknn\")\n# 随机森林模型\nrf_mod &lt;- rand_forest(mode = \"classification\", engine = \"ranger\")\n# 决策树模型\ntree_mod &lt;- decision_tree(mode = \"classification\",engine = \"rpart\")",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>tidymodels实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_workflow.html#选择重抽样方法",
    "href": "model-compare_workflow.html#选择重抽样方法",
    "title": "39  tidymodels实现多模型比较",
    "section": "39.5 选择重抽样方法",
    "text": "39.5 选择重抽样方法\n我们选择内部重抽样方法为10折交叉验证：\n\nset.seed(20220520)\n\nfolds &lt;- vfold_cv(train_data, v = 10)\nfolds\n## #  10-fold cross-validation \n## # A tibble: 10 × 2\n##    splits               id    \n##    &lt;list&gt;               &lt;chr&gt; \n##  1 &lt;split [62082/6899]&gt; Fold01\n##  2 &lt;split [62083/6898]&gt; Fold02\n##  3 &lt;split [62083/6898]&gt; Fold03\n##  4 &lt;split [62083/6898]&gt; Fold04\n##  5 &lt;split [62083/6898]&gt; Fold05\n##  6 &lt;split [62083/6898]&gt; Fold06\n##  7 &lt;split [62083/6898]&gt; Fold07\n##  8 &lt;split [62083/6898]&gt; Fold08\n##  9 &lt;split [62083/6898]&gt; Fold09\n## 10 &lt;split [62083/6898]&gt; Fold10",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>tidymodels实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_workflow.html#构建workflow",
    "href": "model-compare_workflow.html#构建workflow",
    "title": "39  tidymodels实现多模型比较",
    "section": "39.6 构建workflow",
    "text": "39.6 构建workflow\n这一步就是不用重复写代码的关键，把所有模型和数据预处理步骤自动连接起来。\n\nlibrary(workflowsets)\n\nfour_mods &lt;- workflow_set(list(rec = pbp_rec), # 预处理\n                          list(lm = lm_mod,    # 模型\n                               knn = knn_mod,\n                               rf = rf_mod,\n                               tree = tree_mod\n                               ),\n                          cross = T\n                          )\nfour_mods\n## # A workflow set/tibble: 4 × 4\n##   wflow_id info             option    result    \n##   &lt;chr&gt;    &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n## 1 rec_lm   &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n## 2 rec_knn  &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n## 3 rec_rf   &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n## 4 rec_tree &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n\n而且你会发现我们虽然设置了预处理步骤，但是并没有进行预处理，展示因为当我们建立工作流之后，它会自动进行这一步，不需要我们提前处理好。这个概念一定要理解。",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>tidymodels实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_workflow.html#同时拟合多个模型",
    "href": "model-compare_workflow.html#同时拟合多个模型",
    "title": "39  tidymodels实现多模型比较",
    "section": "39.7 同时拟合多个模型",
    "text": "39.7 同时拟合多个模型\n首先是一些运行过程中的参数设置：\n\n# 保存中间的结果\nkeep_pred &lt;- control_resamples(save_pred = T, verbose = T)\n\n然后就是同时运行4个模型（目前一直是在训练集中），我们给它加速一下：\n\nlibrary(doParallel) \n\ncl &lt;- makePSOCKcluster(12) # 加速，用12个线程\nregisterDoParallel(cl)\n\nfour_fits &lt;- four_mods %&gt;% \n  workflow_map(\"fit_resamples\",\n               seed = 0520,\n               verbose = T,\n               resamples = folds,\n               control = keep_pred\n               )\n\ni 1 of 4 resampling: rec_lm\n✔ 1 of 4 resampling: rec_lm (26.6s)\ni 2 of 4 resampling: rec_knn\n✔ 2 of 4 resampling: rec_knn (3m 44.1s)\ni 3 of 4 resampling: rec_rf\n✔ 3 of 4 resampling: rec_rf (1m 10.9s)\ni 4 of 4 resampling: rec_tree\n✔ 4 of 4 resampling: rec_tree (4.5s)\n\n#saveRDS(four_fits,file=\"datasets/four_fits.rds\")\nstopCluster(cl)\n\nfour_fits\n\n需要很长时间！大家笔记本如果内存不够可能会失败哦，而且运行完之后R会变得非常卡！",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>tidymodels实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_workflow.html#查看结果",
    "href": "model-compare_workflow.html#查看结果",
    "title": "39  tidymodels实现多模型比较",
    "section": "39.8 查看结果",
    "text": "39.8 查看结果\n查看模型在训练集中的表现（也就是看各种指标）：\n\ncollect_metrics(four_fits)\n## # A tibble: 8 × 9\n##   wflow_id .config          preproc model .metric .estimator  mean     n std_err\n##   &lt;chr&gt;    &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n## 1 rec_lm   Preprocessor1_M… recipe  logi… accura… binary     0.724    10 1.91e-3\n## 2 rec_lm   Preprocessor1_M… recipe  logi… roc_auc binary     0.781    10 1.88e-3\n## 3 rec_knn  Preprocessor1_M… recipe  near… accura… binary     0.671    10 7.31e-4\n## 4 rec_knn  Preprocessor1_M… recipe  near… roc_auc binary     0.716    10 1.28e-3\n## 5 rec_rf   Preprocessor1_M… recipe  rand… accura… binary     0.732    10 1.48e-3\n## 6 rec_rf   Preprocessor1_M… recipe  rand… roc_auc binary     0.799    10 1.90e-3\n## 7 rec_tree Preprocessor1_M… recipe  deci… accura… binary     0.720    10 1.97e-3\n## 8 rec_tree Preprocessor1_M… recipe  deci… roc_auc binary     0.704    10 2.01e-3\n\n结果中给出了每个模型的AUC值和准确率，哪个大就说明哪个好。\n查看每一个预测结果，这个就不运行了，毕竟好几万行，太多了。。。\n\ncollect_predictions(four_fits)",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>tidymodels实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_workflow.html#可视化结果",
    "href": "model-compare_workflow.html#可视化结果",
    "title": "39  tidymodels实现多模型比较",
    "section": "39.9 可视化结果",
    "text": "39.9 可视化结果\n直接可视化4个模型的结果，感觉比ROC曲线更好看，还给出了可信区间。\n这个图可以自己用ggplot2语法修改。\n\nfour_fits %&gt;% autoplot(metric = \"roc_auc\")+theme_bw()\n\n\n\n\n\n\n\n\n从这个图中来看，随机森林模型是最好的，决策树最差。",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>tidymodels实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_workflow.html#显著性检验",
    "href": "model-compare_workflow.html#显著性检验",
    "title": "39  tidymodels实现多模型比较",
    "section": "39.10 显著性检验",
    "text": "39.10 显著性检验\n只看大小的话肯定是随机森林最好，但是这种差异有没有统计学意义呢？这就需要专门的统计检验方法了，比如t检验。\n在此之前，我们先看看4个模型的AUC之间的相关性如何，也就是计算相关系数：\n\nauc_indiv_estimates &lt;- \n  collect_metrics(four_fits, summarize = FALSE) %&gt;% \n  filter(.metric == \"roc_auc\") \n\nauc_wider &lt;- \n  auc_indiv_estimates %&gt;% \n  select(wflow_id, .estimate, id) %&gt;% \n  pivot_wider(id_cols = \"id\", names_from = \"wflow_id\", values_from = \".estimate\")\n\ncorrr::correlate(auc_wider %&gt;% select(-id), quiet = TRUE)\n## # A tibble: 4 × 5\n##   term     rec_lm rec_knn rec_rf rec_tree\n##   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n## 1 rec_lm   NA       0.505  0.933    0.940\n## 2 rec_knn   0.505  NA      0.577    0.298\n## 3 rec_rf    0.933   0.577 NA        0.860\n## 4 rec_tree  0.940   0.298  0.860   NA\n\n上面是一个相关系数矩阵，可以看出线性模型和随机森林以及决策树的AUC相关性很高，随机森林和决策树的AUC相关性也很高，其他模型之间的相关性很低。\n下面给大家使用t检验计算一下线性模型和随机森林模型的p值，看看是否有统计学显著性。\n\n# 配对t检验\nauc_wider %&gt;% \n  with(t.test(rec_lm, rec_rf, paired = TRUE) ) %&gt;%\n  tidy() %&gt;% \n  select(estimate, p.value, starts_with(\"conf\"))\n## # A tibble: 1 × 4\n##   estimate  p.value conf.low conf.high\n##      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n## 1  -0.0186 6.74e-10  -0.0202   -0.0170\n\n结果表明p值是小于0.0001的，具有统计学显著性，说明随机森林模型确实比线性回归好。",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>tidymodels实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_workflow.html#选择最好的模型用于测试集",
    "href": "model-compare_workflow.html#选择最好的模型用于测试集",
    "title": "39  tidymodels实现多模型比较",
    "section": "39.11 选择最好的模型用于测试集",
    "text": "39.11 选择最好的模型用于测试集\n选择表现最好的模型（随机森林）应用于测试集：\n\nrand_res &lt;- last_fit(rf_mod,pbp_rec,split_pbp)\n#saveRDS(rand_res,file = \"./datasets/rand_res.rds\")\n\n查看模型在测试集的模型表现：\n\ncollect_metrics(rand_res) # test 中的模型表现\n## # A tibble: 2 × 4\n##   .metric  .estimator .estimate .config             \n##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n## 1 accuracy binary         0.731 Preprocessor1_Model1\n## 2 roc_auc  binary         0.799 Preprocessor1_Model1\n\n使用其他指标查看模型表现：\n\nmetricsets &lt;- metric_set(accuracy, mcc, f_meas, j_index)\n\ncollect_predictions(rand_res) %&gt;% \n  metricsets(truth = play_type, estimate = .pred_class)\n## # A tibble: 4 × 3\n##   .metric  .estimator .estimate\n##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n## 1 accuracy binary         0.731\n## 2 mcc      binary         0.440\n## 3 f_meas   binary         0.774\n## 4 j_index  binary         0.438\n\n可视化结果，喜闻乐见的混淆矩阵：\n\ncollect_predictions(rand_res) %&gt;% \n  conf_mat(play_type,.pred_class) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n喜闻乐见的ROC曲线：\n\ncollect_predictions(rand_res) %&gt;% \n  roc_curve(play_type,.pred_pass) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n还有非常多曲线和评价指标可选，大家可以看我之前的介绍推文。\n这里介绍的tidymodels的内容比较简单，大家如果想认真学习这个R包的话肯定是要下一番功夫的，我在公众号写了非常多相关的推文，可以在公众号后台回复tidymodels获取合集。",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>tidymodels实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_mlr3.html",
    "href": "model-compare_mlr3.html",
    "title": "40  mlr3实现多模型比较",
    "section": "",
    "text": "40.1 加载R包\n首先还是加载数据和R包，和之前的数据一样的。\nrm(list = ls())\nlibrary(mlr3verse)\nlibrary(mlr3pipelines)\nlibrary(mlr3filters)",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>mlr3实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_mlr3.html#建立任务",
    "href": "model-compare_mlr3.html#建立任务",
    "title": "40  mlr3实现多模型比较",
    "section": "40.2 建立任务",
    "text": "40.2 建立任务\n然后是对数据进行划分训练集和测试集，对数据进行预处理，为了和之前的tidymodels进行比较，这里使用的数据和预处理步骤都是和之前一样的。\n\n# 读取数据\nall_plays &lt;- readRDS(\"./datasets/all_plays.rds\")\n\n# 建立任务\npbp_task &lt;- as_task_classif(all_plays, target=\"play_type\")\n\n# 数据划分\nsplit_task &lt;- partition(pbp_task, ratio=0.75)\n\ntask_train &lt;- pbp_task$clone()$filter(split_task$train)\ntask_test &lt;- pbp_task$clone()$filter(split_task$test)",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>mlr3实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_mlr3.html#数据预处理",
    "href": "model-compare_mlr3.html#数据预处理",
    "title": "40  mlr3实现多模型比较",
    "section": "40.3 数据预处理",
    "text": "40.3 数据预处理\n建立任务后就是建立数据预处理步骤，这里采用和上篇推文tidymodels中一样的预处理步骤：\n\n# 数据预处理\npbp_prep &lt;- po(\"select\", # 去掉3列\n               selector = selector_invert(\n                 selector_name(c(\"half_seconds_remaining\",\"yards_gained\",\"game_id\")))\n               ) %&gt;&gt;%\n  po(\"colapply\", # 把这两列变成因子类型\n     affect_columns = selector_name(c(\"posteam\",\"defteam\")),\n     applicator = as.factor) %&gt;&gt;% \n  po(\"filter\", # 去除高度相关的列\n     filter = mlr3filters::flt(\"find_correlation\"), filter.cutoff=0.3) %&gt;&gt;%\n  po(\"scale\", scale = F) %&gt;&gt;% # 中心化\n  po(\"removeconstants\") # 去掉零方差变量\n\n可以看到mlr3的数据预处理与tidymodels相比，在语法上确实是有些复杂了，而且由于使用的R6，很多语法看起来很别扭，文档也说的不清楚，对于新手来说还是tidymodels更好些。\n如果你想把预处理步骤应用于数据，得到预处理之后的数据，可以用以下代码：\n\ntask_prep &lt;- pbp_prep$clone()$train(task_train)[[1]]\ndim(task_train$data())\n## [1] 68982    26\n\ntask_prep$feature_types\n## Key: &lt;id&gt;\n##                             id    type\n##                         &lt;char&gt;  &lt;char&gt;\n##  1:                    defteam  factor\n##  2:              defteam_score numeric\n##  3: defteam_timeouts_remaining  factor\n##  4:                       down ordered\n##  5:                 goal_to_go  factor\n##  6:                in_fg_range  factor\n##  7:                in_red_zone  factor\n##  8:                  no_huddle  factor\n##  9:                    posteam  factor\n## 10:              posteam_score numeric\n## 11: posteam_timeouts_remaining  factor\n## 12:              previous_play  factor\n## 13:                        qtr ordered\n## 14:         score_differential numeric\n## 15:                    shotgun  factor\n## 16:                 total_pass numeric\n## 17:              two_min_drill  factor\n## 18:               yardline_100 numeric\n## 19:                    ydstogo numeric\n\n这样就得到了处理好的数据，但是对于mlr3pipelines来说，这一步做不做都可以。",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>mlr3实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_mlr3.html#选择多个模型",
    "href": "model-compare_mlr3.html#选择多个模型",
    "title": "40  mlr3实现多模型比较",
    "section": "40.4 选择多个模型",
    "text": "40.4 选择多个模型\n还是选择和之前一样的4个模型：逻辑回归、随机森林、决策树、k最近邻：\n\n# 随机森林\nrf_glr &lt;- as_learner(pbp_prep %&gt;&gt;% lrn(\"classif.ranger\", predict_type=\"prob\")) \nrf_glr$id &lt;- \"randomForest\"\n\n# 逻辑回归\nlog_glr &lt;-as_learner(pbp_prep %&gt;&gt;% lrn(\"classif.log_reg\", predict_type=\"prob\")) \nlog_glr$id &lt;- \"logistic\"\n\n# 决策树\ntree_glr &lt;- as_learner(pbp_prep %&gt;&gt;% lrn(\"classif.rpart\", predict_type=\"prob\")) \ntree_glr$id &lt;- \"decisionTree\"\n\n# k近邻\nkknn_glr &lt;- as_learner(pbp_prep %&gt;&gt;% lrn(\"classif.kknn\", predict_type=\"prob\")) \nkknn_glr$id &lt;- \"kknn\"",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>mlr3实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_mlr3.html#建立benchmark_grid",
    "href": "model-compare_mlr3.html#建立benchmark_grid",
    "title": "40  mlr3实现多模型比较",
    "section": "40.5 建立benchmark_grid",
    "text": "40.5 建立benchmark_grid\n类似于tidymodels中的workflow_set。\n选择10折交叉验证，建立多个模型，语法也是很简单了。\n\nset.seed(0520)\n\n# 10折交叉验证\ncv &lt;- rsmp(\"cv\",folds=10)\n\nset.seed(0520)\n\n# 建立多个模型\ndesign &lt;- benchmark_grid(\n  tasks = task_train,\n  learners = list(rf_glr,log_glr,tree_glr,kknn_glr),\n  resampling = cv\n)\n\n在训练集中，使用10折交叉验证，运行4个模型，看这语法是不是也很简单清晰？",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>mlr3实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_mlr3.html#开始计算",
    "href": "model-compare_mlr3.html#开始计算",
    "title": "40  mlr3实现多模型比较",
    "section": "40.6 开始计算",
    "text": "40.6 开始计算\n下面就是开始计算，和tidymodels相比，这一块语法更加简单一点，就是建立benchmark_grid，然后使用benchmark()函数即可。\n\n# 加速\nlibrary(future)\nplan(\"multisession\",workers=12)\n\n# 减少屏幕输出\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\nlgr::get_logger(\"bbotk\")$set_threshold(\"warn\")\n\n# 开始运行\nbmr &lt;- benchmark(design,store_models = T) # 速度比tidymodels快很多\n\n#saveRDS(bmr,file = \"datasets/bmr.rds\")\nbmr",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>mlr3实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_mlr3.html#查看模型表现",
    "href": "model-compare_mlr3.html#查看模型表现",
    "title": "40  mlr3实现多模型比较",
    "section": "40.7 查看模型表现",
    "text": "40.7 查看模型表现\n查看结果，也是支持同时查看多个指标的：\n\n# 默认结果\nbmr$aggregate()\n##       nr   task_id   learner_id resampling_id iters classif.ce\n##    &lt;int&gt;    &lt;char&gt;       &lt;char&gt;        &lt;char&gt; &lt;int&gt;      &lt;num&gt;\n## 1:     1 all_plays randomForest            cv    10  0.2658084\n## 2:     2 all_plays     logistic            cv    10  0.2744774\n## 3:     3 all_plays decisionTree            cv    10  0.2784204\n## 4:     4 all_plays         kknn            cv    10  0.3192138\n## Hidden columns: resample_result\n\n\n# 查看多个指标\nmeasures &lt;- msrs(c(\"classif.auc\",\"classif.acc\",\"classif.bbrier\"))\n\nbmr_res &lt;- bmr$aggregate(measures)\nbmr_res[,c(4,7:9)]\n##      learner_id classif.auc classif.acc classif.bbrier\n##          &lt;char&gt;       &lt;num&gt;       &lt;num&gt;          &lt;num&gt;\n## 1: randomForest   0.8002649   0.7341916      0.1779652\n## 2:     logistic   0.7826407   0.7255226      0.1853956\n## 3: decisionTree   0.7055902   0.7215796      0.1995955\n## 4:         kknn   0.7349490   0.6807862      0.2193700",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>mlr3实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_mlr3.html#结果可视化",
    "href": "model-compare_mlr3.html#结果可视化",
    "title": "40  mlr3实现多模型比较",
    "section": "40.8 结果可视化",
    "text": "40.8 结果可视化\n支持ggplot2语法，使用起来和tidymodels差不多，也是对结果直接autoplot()即可。\n\nlibrary(ggplot2)\nautoplot(bmr)+theme(axis.text.x = element_text(angle = 45))\n\n\n\n\n\n\n\n\n喜闻乐见的ROC曲线：\n\nautoplot(bmr,type = \"roc\")",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>mlr3实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_mlr3.html#选择最好的模型用于测试集",
    "href": "model-compare_mlr3.html#选择最好的模型用于测试集",
    "title": "40  mlr3实现多模型比较",
    "section": "40.9 选择最好的模型用于测试集",
    "text": "40.9 选择最好的模型用于测试集\n通过比较结果可以发现还是随机森林效果最好，下面选择随机森林，在训练集上训练，在测试集上测试结果。\n这一步并没有使用10折交叉验证，如果你想用，也是可以的~\n\n# 训练\nrf_glr$train(task_train)\n\n训练好之后就是在测试集上测试并查看结果：\n\n# 测试\nprediction &lt;- rf_glr$predict(task_test)\nhead(as.data.table(prediction))\n##    row_ids  truth response prob.pass   prob.run\n##      &lt;int&gt; &lt;fctr&gt;   &lt;fctr&gt;     &lt;num&gt;      &lt;num&gt;\n## 1:       1   pass      run 0.2689853 0.73101473\n## 2:       5   pass     pass 0.8206669 0.17933307\n## 3:       6    run      run 0.3900934 0.60990661\n## 4:      11   pass     pass 0.6096455 0.39035449\n## 5:      13    run     pass 0.9583785 0.04162154\n## 6:      14   pass     pass 0.7942447 0.20575526\n\n混淆矩阵：\n\nprediction$confusion\n##         truth\n## response  pass   run\n##     pass 10671  3239\n##     run   2913  6171\n\n混淆矩阵可视化：\n\nautoplot(prediction)\n\n\n\n\n\n\n\n\n查看其他结果：\n\nprediction$score(msrs(c(\"classif.auc\",\"classif.acc\",\"classif.bbrier\")))\n##    classif.auc    classif.acc classif.bbrier \n##      0.8013743      0.7324519      0.1774763\n\n喜闻乐见ROC曲线：\n\nautoplot(prediction,type = \"roc\")\n\n\n\n\n\n\n\n\n简单吗？\n这里介绍的mlr3的内容比较简单，大家如果想认真学习这个R包的话肯定是要下一番功夫的，我在公众号写了非常多相关的推文，可以在公众号后台回复mlr3获取合集。",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>mlr3实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_caret.html",
    "href": "model-compare_caret.html",
    "title": "41  caret实现多模型比较",
    "section": "",
    "text": "41.1 数据划分\n下面是一个分类数据的演示。这个数据一共208行，61列，其中Class是结果变量，二分类，因子型，其余变量都是预测变量。\n# 使用的数据集\nlibrary(mlbench)\ndata(Sonar)\n\ndim(Sonar)\n## [1] 208  61\nstr(Sonar[, 1:10])# 展示前10列\n## 'data.frame':    208 obs. of  10 variables:\n##  $ V1 : num  0.02 0.0453 0.0262 0.01 0.0762 0.0286 0.0317 0.0519 0.0223 0.0164 ...\n##  $ V2 : num  0.0371 0.0523 0.0582 0.0171 0.0666 0.0453 0.0956 0.0548 0.0375 0.0173 ...\n##  $ V3 : num  0.0428 0.0843 0.1099 0.0623 0.0481 ...\n##  $ V4 : num  0.0207 0.0689 0.1083 0.0205 0.0394 ...\n##  $ V5 : num  0.0954 0.1183 0.0974 0.0205 0.059 ...\n##  $ V6 : num  0.0986 0.2583 0.228 0.0368 0.0649 ...\n##  $ V7 : num  0.154 0.216 0.243 0.11 0.121 ...\n##  $ V8 : num  0.16 0.348 0.377 0.128 0.247 ...\n##  $ V9 : num  0.3109 0.3337 0.5598 0.0598 0.3564 ...\n##  $ V10: num  0.211 0.287 0.619 0.126 0.446 ...\n划分训练集、测试集：\n# 加载R包，划分数据集\nlibrary(caret)\n\n# 训练集、测试集划分，比例为0.75\nset.seed(998)\ninTraining &lt;- createDataPartition(Sonar$Class, p = .75, list = FALSE)\ntraining &lt;- Sonar[inTraining,]\ntesting  &lt;- Sonar[-inTraining,]",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>caret实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_caret.html#建立多个模型",
    "href": "model-compare_caret.html#建立多个模型",
    "title": "41  caret实现多模型比较",
    "section": "41.2 建立多个模型",
    "text": "41.2 建立多个模型\n首先建立一个boosted tree模型，并设置好它的超参数范围以及重抽样方法：\n\n# 网格搜索，首先设定超参数范围\ngbmGrid &lt;-  expand.grid(interaction.depth = c(1, 5, 9), \n                        n.trees = (1:30)*50, \n                        shrinkage = 0.1,\n                        n.minobsinnode = 20)\n\nnrow(gbmGrid)\n## [1] 90\nhead(gbmGrid)\n##   interaction.depth n.trees shrinkage n.minobsinnode\n## 1                 1      50       0.1             20\n## 2                 5      50       0.1             20\n## 3                 9      50       0.1             20\n## 4                 1     100       0.1             20\n## 5                 5     100       0.1             20\n## 6                 9     100       0.1             20\n\n设置boosted tree模型的重抽样方法：\n\n# trainControl函数用来设置非常多的东西，重复10次的10折交叉验证\nfitControl &lt;- trainControl(method = \"repeatedcv\",\n                           number = 10,\n                           repeats = 10,\n                           classProbs = TRUE, # 计算概率\n                           summaryFunction = twoClassSummary # 二分类指标\n                           )\n\n选择好之后开始拟合模型（及超参数调优）：\n\n# 选择好之后开始调优\nset.seed(825)\ngbmFit3 &lt;- train(Class ~ ., \n                 data = training, \n                 method = \"gbm\", \n                 trControl = fitControl, \n                 verbose = FALSE, \n                 tuneGrid = gbmGrid,\n                 metric = \"ROC\" # 选择指标\n                 )\ngbmFit3\n#saveRDS(gbmFit3,file = \"./datasets/gbmFit3.rds\")\n\n上面的例子展示了caret包建模的基本语法，就是一个train()就可以了，method参数选择模型，trControl选择重抽样方法，preProcess选择数据预处理方法（上面这个例子没有进行数据预处理）。\ntrain()函数中的metric参数可以指定调优的指标，默认分类模型是accuracy和Kappa，回归模型是RMSE/R2/MAE。\ntrainControl()中的summaryFunction参数还提供了额外的调优指标选项，比如上面这个twoClassSummary，内含3种指标：敏感度、特异度、ROC。\n然后再建立一个支持向量机模型和正则化的判别分析模型。\n\n# 选择重抽样方法，重复10次的10折交叉验证\nfitControl &lt;- trainControl(method = \"repeatedcv\", #默认是simple boost\n                           number = 10,\n                           repeats = 10,\n                           classProbs = T # 计算概率\n                           )\n\n开始拟合模型：\n\n# 支持向量机，高斯径向基核\nset.seed(825)\nsvmFit &lt;- train(Class ~ ., \n                data = training, \n                method = \"svmRadial\", \n                trControl = fitControl, \n                preProc = c(\"center\", \"scale\"),\n                tuneLength = 8,\n                metric = \"ROC\")\n\n# 正则化的判别分析\nset.seed(825)\nrdaFit &lt;- train(Class ~ ., \n                data = training, \n                method = \"rda\", \n                trControl = fitControl, \n                tuneLength = 4,\n                metric = \"ROC\")\n#save(svmFit, rdaFit,file = \"./datasets/svm_rda_fit.rdata\")\n\n这样我们就建立好了3个模型。",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>caret实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_caret.html#结果查看",
    "href": "model-compare_caret.html#结果查看",
    "title": "41  caret实现多模型比较",
    "section": "41.3 结果查看",
    "text": "41.3 结果查看\n可以单独查看每个模型的结果，直击打印即可：\n\n# 比如查看gbm模型\ngbmFit3\n\nStochastic Gradient Boosting \n\n157 samples\n 60 predictor\n  2 classes: 'M', 'R' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 10 times) \nSummary of sample sizes: 141, 142, 141, 142, 141, 142, ... \nResampling results across tuning parameters:\n\n  interaction.depth  n.trees  ROC        Sens       Spec     \n  1                    50     0.8634003  0.8631944  0.6905357\n  1                   100     0.8844097  0.8486111  0.7544643\n##省略一部分，太长了\n  9                  1500     0.9181721  0.8805556  0.8039286\n\nTuning parameter 'shrinkage' was held constant at a value of 0.1\n\nTuning parameter 'n.minobsinnode' was held constant at a value of 20\nROC was used to select the optimal model using the largest value.\nThe final values used for the model were n.trees =\n 1450, interaction.depth = 5, shrinkage = 0.1 and n.minobsinnode = 20.\n\n结果没什么难度，我就不帮大家翻译了。\n也可以一起放入resamples()函数里面，可以得到每个模型的指标的统计值，比如ROC的最大值、最小值、均值、中位数等：\n\nresamps &lt;- resamples(list(GBM = gbmFit3,\n                          SVM = svmFit,\n                          RDA = rdaFit))\n#resamps\nsummary(resamps)\n## \n## Call:\n## summary.resamples(object = resamps)\n## \n## Models: GBM, SVM, RDA \n## Number of resamples: 100 \n## \n## ROC \n##          Min.  1st Qu.    Median      Mean   3rd Qu. Max. NA's\n## GBM 0.6964286 0.874504 0.9454365 0.9216468 0.9821429    1    0\n## SVM 0.7321429 0.905878 0.9464286 0.9339658 0.9821429    1    0\n## RDA 0.5625000 0.812500 0.8750000 0.8698115 0.9392361    1    0\n## \n## Sens \n##          Min.   1st Qu.    Median      Mean 3rd Qu. Max. NA's\n## GBM 0.5555556 0.7777778 0.8750000 0.8787500       1    1    0\n## SVM 0.5000000 0.7777778 0.8888889 0.8730556       1    1    0\n## RDA 0.4444444 0.7777778 0.8750000 0.8604167       1    1    0\n## \n## Spec \n##          Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA's\n## GBM 0.4285714 0.7142857 0.8571429 0.8119643 1.0000000    1    0\n## SVM 0.4285714 0.7142857 0.8571429 0.8205357 0.9062500    1    0\n## RDA 0.1428571 0.5714286 0.7142857 0.6941071 0.8571429    1    0\n\n结果就很强！分别给出了3种指标下的每种模型的统计值。",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>caret实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_caret.html#结果可视化",
    "href": "model-compare_caret.html#结果可视化",
    "title": "41  caret实现多模型比较",
    "section": "41.4 结果可视化",
    "text": "41.4 结果可视化\n喜闻乐见的结果可视化也是必不可少的。主要包括以下几种(都是基于lattice的)：\n\ndensity plots,\nbox-whisker plots,\nscatterplot matrices,\nscatterplots\n\n箱线图:\n\n# 设主题\ntheme1 &lt;- trellis.par.get()\ntheme1$plot.symbol$col = rgb(.2, .2, .2, .4)\ntheme1$plot.symbol$pch = 16\ntheme1$plot.line$col = rgb(1, 0, 0, .7)\ntheme1$plot.line$lwd &lt;- 2\n\n# 画图，箱线图\ntrellis.par.set(theme1)\nbwplot(resamps, layout = c(3, 1))\n\n\n\n\n\n\n\n\n密度图:\n\n# 密度图\ntrellis.par.set(theme1)\ndensityplot(resamps)\n\n\n\n\n\n\n\n\n换个指标，点线图:\n\n# 换个指标，点线图\ntrellis.par.set(caretTheme())\ndotplot(resamps, metric = \"ROC\")\n\n\n\n\n\n\n\n\n散点图:\n\n# 散点图\ntrellis.par.set(theme1)\nxyplot(resamps, what = \"BlandAltman\")\n\n\n\n\n\n\n\n\n散点图矩阵:\n\n# 散点图矩阵\nsplom(resamps)",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>caret实现多模型比较</span>"
    ]
  },
  {
    "objectID": "model-compare_caret.html#显著性检验",
    "href": "model-compare_caret.html#显著性检验",
    "title": "41  caret实现多模型比较",
    "section": "41.5 显著性检验",
    "text": "41.5 显著性检验\n除此之外，我们还可以对不同模型之间的差异进行显著性检验，比如t检验，结果会给出多重校正检验（bonferroni法）的p值，非常高大上：\n\ndifValues &lt;- diff(resamps)\ndifValues\n## \n## Call:\n## diff.resamples(x = resamps)\n## \n## Models: GBM, SVM, RDA \n## Metrics: ROC, Sens, Spec \n## Number of differences: 3 \n## p-value adjustment: bonferroni\nsummary(difValues)\n## \n## Call:\n## summary.diff.resamples(object = difValues)\n## \n## p-value adjustment: bonferroni \n## Upper diagonal: estimates of the difference\n## Lower diagonal: p-value for H0: difference = 0\n## \n## ROC \n##     GBM       SVM       RDA     \n## GBM           -0.01232   0.05184\n## SVM 0.3408               0.06415\n## RDA 5.356e-07 2.638e-10         \n## \n## Sens \n##     GBM    SVM      RDA     \n## GBM        0.005694 0.018333\n## SVM 1.0000          0.012639\n## RDA 0.4253 1.0000           \n## \n## Spec \n##     GBM       SVM       RDA      \n## GBM           -0.008571  0.117857\n## SVM 1                    0.126429\n## RDA 8.230e-07 1.921e-10\n\n这个结果展示的是不同模型之间的差异和t检验的p值。比如第一个矩阵（ROC的这个），先横着看，GBM和GBM是一个，不用比，GBM和SVM比，平均ROC的差异是-0.01232，GBM和RDA比，平均ROC的差异是0.05184；再顺着看，GBM和SVM的t检验的p值是0.3408，说明无统计学差异，GBM和RDA的t检验的p值是5.356e-07，有统计学差异。\n结果的可视化，使用箱线图，同时展示3种指标，这个图展示的是不同模型之间性能指标的差异分布情况：\n\ntrellis.par.set(theme1)\nbwplot(difValues, layout = c(3, 1))\n\n\n\n\n\n\n\n\n下面这个图展示的是不同模型性能指标差异的95%可信区间，如果通过了0，说明没差异，这个图的结果和上面统计检验的结果是相同的：\n\ntrellis.par.set(caretTheme())\ndotplot(difValues)\n\n\n\n\n\n\n\n\n是不是很强！\n这里介绍的caret的内容比较简单，大家如果想认真学习这个R包的话肯定是要下一番功夫的，我在公众号写了非常多相关的推文，可以在公众号后台回复caret获取合集。",
    "crumbs": [
      "多模型比较",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>caret实现多模型比较</span>"
    ]
  },
  {
    "objectID": "BMJ预测模型样本量计算.html",
    "href": "BMJ预测模型样本量计算.html",
    "title": "42  开发预测模型样本量计算",
    "section": "",
    "text": "42.1 经典方法\nHarrell老爷子在他的书《Regression Modeling Strategies》中介绍的开发模型的样本量计算方法是：\n在开发数据集(也就是训练集)中，连续型结果的有效样本量由研究参与者的总数决定(有多少用多少)。对于二分类结果，有效样本量通常被认为大约等于事件（有结果的事件）和非事件（没有结果的事件）的最小值; time-to-event数据中，样本量可以粗略等于阳性事件的数量。\n在为二分类或time-to-event数据开发预测模型时，所需要的样本量常用的计算方法是10EPV法，即阳性事件的数量至少是预测变量个数的10倍（10 events per variable，10EPV）。\n但是“variable”一词具有误导性，因为在模型中一个预测变量可能有多个β（即回归系数），例如，具有三个类别的分类型预测变量就会有两个β（例如肿瘤等级1、2、3，那么就会有β(2和1比)、β(3和1比)，因为分类变量在回归分析中需要进行哑变量编码）。还有就是在建模过程中使用了多项式转换和样条变换等也会使得同一个变量有多个β，如果变量之间有交互项也会产生同样的结果。\n由于预测模型的参数（也就是回归系数β）通常多于实际的预测变量个数，所以最好使用10EPP（10 events per candidate predictor parameter）法，即阳性事件的数量至少是“候选预测变量的参数”的10倍。“候选”一词很重要，因为模型过拟合的程度与预测变量参数的数量有关，而不是最终模型方程中的参数数量。\n但是10EPP原则目前也有一些争议，也有大佬建议5EPP或者15、20、50EPP。这些数量的使用都是和具体的情况有关的，也没个金标准，不仅取决于相对于候选预测变量参数数量的事件数量，还取决于参与者总数、研究人群中的结果比例（发生率）以及模型的预期预测性能等。",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>开发预测模型样本量计算</span>"
    ]
  },
  {
    "objectID": "BMJ预测模型样本量计算.html#步法",
    "href": "BMJ预测模型样本量计算.html#步法",
    "title": "42  开发预测模型样本量计算",
    "section": "42.2 4步法",
    "text": "42.2 4步法\nVan Smeden等和Riley等人最近的工作描述了如何计算预测模型开发所需的样本量，使用条件是用户指定目标人群中的总体结果风险或平均结果值、候选预测变量参数的数量以及总体模型拟合方面的预期模型性能。具体实施起来总结为4个步骤：\n\n第一步是确定需要多少样本才能准确估计平均风险（也就是平均概率，对应二分类或者生存数据）或者平均值（对应连续型数据）；\n第二步是确定需要多少样本才能让模型的预测值和真实值之间的误差更小；\n第三步是确定有足够的的样本量以防止过拟合；\n第四步是确定有足够的的样本量使模型的表面性能和真实性能的误差更小。\n\n\n42.2.1 第一步\n样本大小必须让预测模型的截距能被精确估计，以确保开发的模型可以准确预测平均结果值(对应连续型数据)或总体结果比例(对应二分类或者生存数据)。一个简单的方法是计算：能够准确估计“没有预测变量的空模型(null model)的截距”所需要的样本量。\n这里涉及一个简单的数学知识，就是线性模型的截距反映了模型预测的平均值。\n这个“准确估计”一般要求误差在0.05以内，也就是说预测值最好不要超过均值的95%可信区间。\n下图是计算公式和一个例子。假如一个二分类数据，它的阳性事件比例是0.5，为了控制误差在0.05以内，根据以下公式计算，需要的样本量最少是385个。\n\n\n\n42.2.2 第二步\n预测值和真实值之间的误差可以用很多指标衡量，比如平均绝对百分比误差（Mean Absolute Percentage Error，MAPE），这个指标其实是衡量回归模型的常用指标，对于二分类数据如果使用的是概率的话也能用这个指标衡量。\n下面是计算公式和一个例子。假如一个二分类数据，它的阳性事件比例是0.3，预测变量有10个，为了控制误差（MAPE）在0.05以内，根据以下公式计算，需要的样本量最少是461个。\n\n\n\n42.2.3 第三步\n样本量越少且预测变量数量越多，则越容易过拟合，因此需要足够的样本量防止过拟合。\n建模过程中通常会使用收缩法（Shrinkage，或者被称为惩罚(penalisation)或正则化(regularisation)）来降低过拟合的风险。Riley等人建议使用一个较小的收缩值（≤10%），并计算此时所需要的样本量。并且还需要指定候选预测变量参数的个数以及一个模型性能指标，比如Cox-Snell R2(记为CS-R方，属于伪R方的一种)。CS-R方可以反应信噪比（signal:noise），从而反应模型是否过拟合。\n对于连续型数据来说，CS-R方就是决定系数，反应模型所能解释的方差（或者叫变异）百分比，范围是0到1之间，越接近1越好，说明模型能够准确识别数据内部的模式，不会被噪声（误差）干扰，如果CS-R方接近0则说明模型很有可能过拟合。\n对于二分类数据和生存数据来说，CS-R方的范围是0到max(CS-R方)。对于逻辑回归模型来说，如果阳性事件发生率为0.5，0.4，0.3，0.2，0.1，0.05，0.01，那么对应的max(CS-R方)分别是0.75，0.74，0.71，0.63，0.48，0.33，0.11。所以即使模型的预期性能非常好，这个CS-R方的值也一般会选择比较小的值。\n以下是二分类和生存数据的样本量计算公式和一个示例。对于一个逻辑回归模型，如果有20个候选预测变量参数（EPP），CS-R方选择0.1，那么为了使收缩值保持在10%，最少的样本量是1698。\n\nCox-Snell R2(也就是CS-R方)的选择有多种方法，以下是作者比较推荐的几种：\n\n直接使用别人文献里报道的值\n使用其他指标近似，比如使用C指数、AUC值、其他伪R方等\n根据max(CS-R方)计算\n\n\n\n\nCS-R方的确定方法\n\n\n本文献的附件5提供了详细的公式用于计算max(CS-R方)，感兴趣的自己查看一下吧。\n\n\n42.2.4 第四步\n应该有足够多的样本量保证模型的表面指标和真实指标之间的差异足够小。\n表面指标（apparent values），假如我们用训练集开发了一个模型，然后让这个模型对训练集进行预测，这样得到的指标就是表面指标，这种计算模型指标的方法叫做重代入法（resubstitution）。真实指标是指模型在其他数据中（就是模型开发时没用过的数据）得到的更真实、更接近模型真实性能的指标。\n本篇文献中采用的指标是另外一种调整的R方，即：Nagelkerke-R方（也是伪R方的一种），Nagelkerke-R方=CS-R方/max(CS-R方)。\n下面是二分类和生存数据的样本量计算公式。对于一个逻辑回归模型，假设阳性事件的比例是0.05（此时对应的max(CS-R方)是0.33），指定CS-R方为0.2，那么为了使真实的Nagelkerke-R方和表面Nagelkerke-R方的差异保持在0.05，至少需要的样本量是1079。",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>开发预测模型样本量计算</span>"
    ]
  },
  {
    "objectID": "BMJ预测模型样本量计算.html#总结",
    "href": "BMJ预测模型样本量计算.html#总结",
    "title": "42  开发预测模型样本量计算",
    "section": "42.3 总结",
    "text": "42.3 总结\n下面是一个总结，对于连续型数据，推荐使用4步法(C1-C4)，对于二分类数据推荐使用4步法(B1-B4)，对于生存数据推荐使用3步法(T1-T4)。\n\n除此之外作者专门写了一个R包用于计算临床预测模型的样本量：pmsampsize，这个R包可以计算以上每一个步骤（除了B2这个步骤不行，这一步是通过网页计算的，网址是：https://mvansmeden.shinyapps.io/BeyondEPV/）所需要的样本量，并选择最大的一个作为开发模型所需要的最少样本量。",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>开发预测模型样本量计算</span>"
    ]
  },
  {
    "objectID": "BMJ预测模型样本量计算.html#r包使用方法",
    "href": "BMJ预测模型样本量计算.html#r包使用方法",
    "title": "42  开发预测模型样本量计算",
    "section": "42.4 R包使用方法",
    "text": "42.4 R包使用方法\n下面用3个实例演示这个R包的使用方法。\n\nlibrary(pmsampsize)\n\n\n42.4.1 二分类数据\n假如我们要根据妊娠15周时测定的各种指标预测孕妇发生子痫前期的风险，这是一个二分类数据，结果变量是发生子痫/不发生子痫。\n假设该数据中，发生子痫的比例是0.05（阳性事件的比例），候选预测变量的参数数量是30（EPP是30），max(CS-R方)是0.33。如果我们预期模型能够解释15%的变异，根据第3步中介绍的CS-R方的计算方法，可以得到CS-R方=0.15*0.33=0.05。\n有了这几个数据，就可以计算样本量了：\n\npmsampsize(\n  type = \"b\",         # 二分类数据\n  csrsquared = 0.05,  # CS-R方\n  parameters = 30,    # EPP的数量\n  prevalence = 0.05,  # 阳性事件发生率\n  seed = 123          # 设置随机数种子\n)\n## NB: Assuming 0.05 acceptable difference in apparent & adjusted R-squared \n## NB: Assuming 0.05 margin of error in estimation of intercept \n## NB: Events per Predictor Parameter (EPP) assumes prevalence = 0.05  \n##  \n##            Samp_size Shrinkage Parameter CS_Rsq Max_Rsq Nag_Rsq  EPP\n## Criteria 1      5249     0.900        30   0.05   0.328   0.153 8.75\n## Criteria 2      1770     0.753        30   0.05   0.328   0.153 2.95\n## Criteria 3        73     0.900        30   0.05   0.328   0.153 0.12\n## Final           5249     0.900        30   0.05   0.328   0.153 8.75\n##  \n##  Minimum sample size required for new model development based on user inputs = 5249, \n##  with 263 events (assuming an outcome prevalence = 0.05) and an EPP = 8.75 \n##  \n## \n\n对于二分类数据，使用4步法计算样本量，其中B2这一步不能通过这个包计算，所以这个包给出了其他3个步骤所需要的样本量，B2这个步骤算出来是需要544例，因为要同时满足4个步骤的要求，所以最终需要的样本量是5249例。\n\n\n42.4.2 生存数据\n假如我们要预测治疗停止一段时间后，静脉血栓栓塞复发的风险。这是一个time-to-event类型的数据，结局是复发/不复发，时间就是治疗停止后的时长。\n假设该数据中，C指数是0.69，CS-R方是0.051，EPP=30，平均随访时间是2.07年，阳性事件发生比例是0.065，需要进行预测的时间点选择2年，那么样本量计算如下：\n\npmsampsize(\n  type = \"s\",         # 生存数据\n  csrsquared = 0.051, # CS-R方\n  parameters = 30,    # EPP的数量\n  rate = 0.065,       # 阳性事件发生率\n  timepoint = 2,      # 指定要预测的时间点\n  meanfup = 2.07      # 平均随访时间\n)\n## NB: Assuming 0.05 acceptable difference in apparent & adjusted R-squared \n## NB: Assuming 0.05 margin of error in estimation of overall risk at time point = 2  \n## NB: Events per Predictor Parameter (EPP) assumes overall event rate = 0.065  \n##  \n##              Samp_size Shrinkage Parameter CS_Rsq Max_Rsq Nag_Rsq   EPP\n## Criteria 1        5143     0.900        30  0.051   0.555   0.092 23.07\n## Criteria 2        1039     0.648        30  0.051   0.555   0.092  4.66\n## Criteria 3 *      5143     0.900        30  0.051   0.555   0.092 23.07\n## Final SS          5143     0.900        30  0.051   0.555   0.092 23.07\n##  \n##  Minimum sample size required for new model development based on user inputs = 5143, \n##  corresponding to 10646 person-time** of follow-up, with 692 outcome events \n##  assuming an overall event rate = 0.065 and therefore an EPP = 23.07  \n##  \n##  * 95% CI for overall risk = (0.113, 0.13), for true value of 0.122 and sample size n = 5143 \n##  **where time is in the units mean follow-up time was specified in\n\n生存数据的样本量计算遵循4步法，所以结果中给出了4个步骤每一步骤所需要的样本量，最终需要的样本量是5143例。\n\n\n42.4.3 连续型数据\n假如我们要预测青少年的无脂肪体重，该任务很明显是一个回归任务，结果变量是数值型的。\n假设该数据中，CS-R方为0.9，EPP=20，总体的平均无脂肪体重是26.7kg（截距的值），总体的无脂肪体重的标准差是8.7kg，那么计算样本量的代码为：\n\npmsampsize(\n  type = \"c\",       # 连续型数据\n  rsquared = 0.9,   # 连续型数据的CS-R方=R方\n  parameters = 20,  # EPP的数量\n  intercept = 26.7, # 截距，也就是均值\n  sd = 8.7          # 总体的标准差\n)\n## NB: Assuming 0.05 acceptable difference in apparent & adjusted R-squared \n## NB: Assuming MMOE &lt;= 1.1 in estimation of intercept & residual standard deviation \n## SPP - Subjects per Predictor Parameter \n##  \n##             Samp_size Shrinkage Parameter Rsq   SPP\n## Criteria 1         68     0.900        20 0.9  3.40\n## Criteria 2         41     0.853        20 0.9  2.05\n## Criteria 3        254     0.970        20 0.9 12.70\n## Criteria 4*       254     0.970        20 0.9 12.70\n## Final             254     0.970        20 0.9 12.70\n##  \n##  Minimum sample size required for new model development based on user inputs = 254  \n##  \n##  * 95% CI for intercept = (26.36, 27.04), for sample size n = 254\n\n连续型数据的样本量计算也遵循4步法，最终所需要的样本量是254。",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>开发预测模型样本量计算</span>"
    ]
  },
  {
    "objectID": "mice多重插补.html",
    "href": "mice多重插补.html",
    "title": "43  mice多重插补",
    "section": "",
    "text": "43.1 加载数据和R包\n首先我们加载mice包，并使用自带的nhanes数据进行演示。\n这个数据一共25行，4个变量，除了age这个变量外都有缺失值，各个变量的类型如下所示：\nlibrary(mice)\n\nstr(nhanes)\n## 'data.frame':    25 obs. of  4 variables:\n##  $ age: num  1 2 1 3 1 3 1 1 2 2 ...\n##  $ bmi: num  NA 22.7 NA NA 20.4 NA 22.5 30.1 22 NA ...\n##  $ hyp: num  NA 1 1 NA 1 NA 1 1 1 NA ...\n##  $ chl: num  NA 187 187 NA 113 184 118 187 238 NA ...\n使用mice进行缺失值插补非常简单，如果你不考虑各种细节的话，使用起来就是3行代码而已，主要使用的函数和作用如下所示：",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>mice多重插补</span>"
    ]
  },
  {
    "objectID": "mice多重插补.html#加载数据和r包",
    "href": "mice多重插补.html#加载数据和r包",
    "title": "43  mice多重插补",
    "section": "",
    "text": "mice()：对缺失值进行插补\nwith()：对多个插补后的结果进行分析，注意这里的with()是mice包里的函数\npool()：对分析结果进行汇总\n\n\n\n\nmice使用示意图",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>mice多重插补</span>"
    ]
  },
  {
    "objectID": "mice多重插补.html#多种使用方法",
    "href": "mice多重插补.html#多种使用方法",
    "title": "43  mice多重插补",
    "section": "43.2 多种使用方法",
    "text": "43.2 多种使用方法\n假如我们的研究目的是：分析对chl这个变量有影响的因素，或者说是使用age、bmi、hyp预测chl的值，因为chl这个变量是连续型变量，此时我们可以使用lm()建立多元线性回归模型：\n\nsummary(lm(chl ~ age + bmi + hyp, data = nhanes))\n## \n## Call:\n## lm(formula = chl ~ age + bmi + hyp, data = nhanes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -31.315 -15.782   0.576   6.315  59.335 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)   \n## (Intercept)  -80.971     61.772  -1.311  0.22238   \n## age           55.210     14.290   3.864  0.00383 **\n## bmi            7.065      2.052   3.443  0.00736 **\n## hyp           -6.222     23.177  -0.268  0.79441   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 29.05 on 9 degrees of freedom\n##   (12 observations deleted due to missingness)\n## Multiple R-squared:  0.7339, Adjusted R-squared:  0.6452 \n## F-statistic: 8.274 on 3 and 9 DF,  p-value: 0.005915\n\n此时虽然也能得到结果，但是这个是删除了缺失值之后的结果(12个观察量被删除了)，lm()默认的对缺失值的默认操作就是直接删除，我们可以修改一下，但是会报错：\nlm(chl ~ age + bmi + hyp, data = nhanes, na.action = na.fail())\n\n## Error in na.fail.default() : 缺少参数\"object\",也没有缺省值\n此时我们可以使用mice对数据进行多重插补。\nmice在3.0版本以后增加了对管道符的支持，所以现在使用起来有多种语法，下面给大家介绍常见的两种使用方法。\n\n43.2.1 常规用法\n常规用法就是3行代码，分别做3件事：\n\n插补\n分析\n汇总\n\n\n# 进行插补，默认插补5次\nimp &lt;- mice(nhanes, seed = 123, print = FALSE, m=5) \n\n# 对5个结果进行分析\n# chl是连续型，所以用lm；二分类就用glm\nfit &lt;- with(imp, lm(chl ~ age + bmi + hyp)) \n\n# 汇总结果\nest1 &lt;- pool(fit)\n\n# 查看汇总结果\nsummary(est1)\n##          term  estimate std.error  statistic        df    p.value\n## 1 (Intercept) 10.312370 73.181125 0.14091571  8.137530 0.89136250\n## 2         age 27.218585 12.835482 2.12057358 10.608141 0.05841745\n## 3         bmi  4.958399  2.490281 1.99109978  7.079015 0.08629345\n## 4         hyp  1.955541 21.541135 0.09078171 14.986247 0.92886832\n\n这样我们就得到了最终的结果，可以和前面的回归分析结果对比一下，不管是变量系数还是p值、标准误等，都有很大的不同。\n以上是5次分析汇总（不是平均）后的结果，如果要单独提取某次插补后的回归分析结果，可以通过以下方式：\n\n# 提取第2次插补后的回归分析结果\nsummary(fit$analyses[[2]])\n## \n## Call:\n## lm(formula = chl ~ age + bmi + hyp)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -48.746 -24.916  -2.562   8.620  81.342 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(&gt;|t|)  \n## (Intercept)   40.313     52.734   0.764   0.4531  \n## age           18.783     10.760   1.746   0.0955 .\n## bmi            4.198      1.731   2.425   0.0244 *\n## hyp            5.211     20.693   0.252   0.8036  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 34.55 on 21 degrees of freedom\n## Multiple R-squared:  0.2957, Adjusted R-squared:  0.1951 \n## F-statistic:  2.94 on 3 and 21 DF,  p-value: 0.0568\n\n\n\n43.2.2 tidy用法\n以上代码可以使用管道符的写法，更加简洁美观，效果是一样的：\n\nest2 &lt;- nhanes |&gt;\n  mice(seed = 123, print = FALSE) |&gt;\n  with(lm(chl ~ age + bmi + hyp)) |&gt;\n  pool()\n\nsummary(est2)\n##          term  estimate std.error  statistic        df    p.value\n## 1 (Intercept) 10.312370 73.181125 0.14091571  8.137530 0.89136250\n## 2         age 27.218585 12.835482 2.12057358 10.608141 0.05841745\n## 3         bmi  4.958399  2.490281 1.99109978  7.079015 0.08629345\n## 4         hyp  1.955541 21.541135 0.09078171 14.986247 0.92886832\n\n和上面的常规写法完全一致。",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>mice多重插补</span>"
    ]
  },
  {
    "objectID": "mice多重插补.html#提取插补结果",
    "href": "mice多重插补.html#提取插补结果",
    "title": "43  mice多重插补",
    "section": "43.3 提取插补结果",
    "text": "43.3 提取插补结果\n分析多重插补数据的合适方法是在每个插补数据集中拟合模型，然后再汇总多个拟合结果，也就是mice-with-pool三部曲。所以作者并不推荐提取其中某一次插补的结果进行后续分析。如果非要提取也是可以的。\nmice默认可以插补5次，我们可以提取其中某一次插补的结果，比如提取第2次插补的结果：\n\nimputed_df &lt;- mice::complete(imp, action = 2)\nmd.pattern(imputed_df,plot = F) # 没有缺失值了\n##  /\\     /\\\n## {  `---'  }\n## {  O   O  }\n## ==&gt;  V &lt;==  No need for mice. This data set is completely observed.\n##  \\  \\|/  /\n##   `-----'\n##    age bmi hyp chl  \n## 25   1   1   1   1 0\n##      0   0   0   0 0\n\n到底选择哪一次插补的结果没有标准，可以试试选择表现更好的，比如R2更大的，AIC更小的，等等。",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>mice多重插补</span>"
    ]
  },
  {
    "objectID": "mice多重插补.html#不推荐的用法",
    "href": "mice多重插补.html#不推荐的用法",
    "title": "43  mice多重插补",
    "section": "43.4 不推荐的用法",
    "text": "43.4 不推荐的用法\n虽然作者也没说到底用哪次插补的结果，但是明确说了不推荐的用法，参考：https://stefvanbuuren.name/fimd/workflow.html\n\n43.4.1 平均多个结果\n对多个插补后的数据集计算平均值，作为最终的结果，这种做法是不推荐的。\n以下是对5次插补结果取平均值的示例代码，其中的ave就是取平均值后的插补后的数据：\n\nlibrary(magrittr)\nlibrary(dplyr)\n\n# 获取5次平均的结果\nave &lt;- nhanes %&gt;%\n  mice(seed = 123, print = FALSE) %&gt;%\n  mice::complete(\"long\") %&gt;% \n  group_by(.id) %&gt;%\n  summarise_all(.funs = mean) %&gt;%\n  select(-.id, -.imp)\n\n# 用平均结果做后续分析\nest8 &lt;- lm(formula = chl ~ age + bmi + hyp, data = ave)\n\n#summary(est8)\n\n这个结果和上面的正确用法的结果相差甚大，作者不推荐使用，因为这种方法和常规的simple-imputation的思想一样，具有常规方法的所有缺点。\n\n\n43.4.2 堆叠多个结果\n这个也很简单，就是把5次插补的结果直接按行合并起来，比如nhanes这个数据一共25行，插补5次后，再按行合并5次的插补结果，于是就有25*5=125行数据，用这个数据作为最终的结果进行后续分析。这种也是作者不推荐的。\n\nstacked &lt;- nhanes %&gt;%\n  mice(seed = 123, print = FALSE) %&gt;%\n  mice::complete(\"stacked\")\n\nest9 &lt;- lm(formula = chl ~ age + bmi + hyp, data = stacked)\n\n这种方法计算的回归系数相比平均法更加准确一点，但是t值、标准误等也是不准的。",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>mice多重插补</span>"
    ]
  },
  {
    "objectID": "mice多重插补.html#插补细节探索",
    "href": "mice多重插补.html#插补细节探索",
    "title": "43  mice多重插补",
    "section": "43.5 插补细节探索",
    "text": "43.5 插补细节探索\n如果正常使用的话就是3步即可，不需要其他操作。但是实际使用中总是需要各种DIY操作的，mice包的每一步都可以自己控制，非常强大。\n拿到一个有缺失值的数据后，首先是探索缺失值，我们可以用mice包里的函数，也可以用其他R包，比如之前介绍过的naniar。这里就不给大家演示这一步了。\n直接看一下mice的一些使用细节，并介绍一些比较重要的参数。\nmice(\n  data,\n  m = 5, # 插补次数，默认5次，不用太多，一般5次就够用了\n  method = NULL,\n  predictorMatrix,\n  ignore = NULL,\n  where = NULL,\n  blocks,\n  visitSequence = NULL,\n  formulas,\n  blots = NULL,\n  post = NULL,\n  defaultMethod = c(\"pmm\", \"logreg\", \"polyreg\", \"polr\"),\n  maxit = 5,\n  printFlag = TRUE,\n  seed = NA,\n  data.init = NULL,\n  ...\n)\n\n43.5.1 插补方法\n\nmethod：插补时使用的方法，默认方法由defaultMethod参数指定，一般是4种方法(参考上面的代码)，对应4种数据类型，分别是连续型变量、二分类、无序多分类、有序多分类。\n\nmice支持36种插补方法，可通过methods(mice)查看支持的方法：\n\nmethods(mice)\n##  [1] mice.impute.2l.bin              mice.impute.2l.lmer            \n##  [3] mice.impute.2l.norm             mice.impute.2l.pan             \n##  [5] mice.impute.2lonly.mean         mice.impute.2lonly.norm        \n##  [7] mice.impute.2lonly.pmm          mice.impute.cart               \n##  [9] mice.impute.jomoImpute          mice.impute.lasso.logreg       \n## [11] mice.impute.lasso.norm          mice.impute.lasso.select.logreg\n## [13] mice.impute.lasso.select.norm   mice.impute.lda                \n## [15] mice.impute.logreg              mice.impute.logreg.boot        \n## [17] mice.impute.mean                mice.impute.midastouch         \n## [19] mice.impute.mnar.logreg         mice.impute.mnar.norm          \n## [21] mice.impute.mpmm                mice.impute.norm               \n## [23] mice.impute.norm.boot           mice.impute.norm.nob           \n## [25] mice.impute.norm.predict        mice.impute.panImpute          \n## [27] mice.impute.passive             mice.impute.pmm                \n## [29] mice.impute.polr                mice.impute.polyreg            \n## [31] mice.impute.quadratic           mice.impute.rf                 \n## [33] mice.impute.ri                  mice.impute.sample             \n## [35] mice.mids                       mice.theme                     \n## see '?methods' for accessing help and source code\n\n# 查看每种方法的详细信息和支持的数据类型\n#?mice.impute.2l.norm \n\n在插补的过程中会自动对不同的变量选择不同的插补方法，可以通过以下方式查看每个变量使用的插补方法：\n\nimp &lt;- mice(nhanes, seed = 123, print = FALSE, m=5) \nimp\n## Class: mids\n## Number of multiple imputations:  5 \n## Imputation methods:\n##   age   bmi   hyp   chl \n##    \"\" \"pmm\" \"pmm\" \"pmm\" \n## PredictorMatrix:\n##     age bmi hyp chl\n## age   0   1   1   1\n## bmi   1   0   1   1\n## hyp   1   1   0   1\n## chl   1   1   1   0\n\n这个imp是一个mids对象，在中间部分可以看到age下面是\"\"，表示没有进行插补，因为它没有缺失值，其余3个变量都是用的pmm法。\n也可以单独查看每个变量使用的方法：\n\n# 所有变量使用的插补方法\nimp$method\n##   age   bmi   hyp   chl \n##    \"\" \"pmm\" \"pmm\" \"pmm\"\n\n# chl这个变量使用的插补方法\nimp$method[[\"chl\"]]\n## [1] \"pmm\"\n\n对于每个变量，你都可以更改方法，比如对于hyp这个变量我们想使用norm法，即贝叶斯线性回归法，可以使用以下代码更改：\n\nimpp &lt;- mice(nhanes, seed = 123, print = FALSE, m=5)\n# 更改方法\nimpp$method[[\"hyp\"]] &lt;- \"norm\"\n# 重新插补即可\nmice(nhanes, seed = 123, print = FALSE, m=5, method = impp$method)\n## Class: mids\n## Number of multiple imputations:  5 \n## Imputation methods:\n##    age    bmi    hyp    chl \n##     \"\"  \"pmm\" \"norm\"  \"pmm\" \n## PredictorMatrix:\n##     age bmi hyp chl\n## age   0   1   1   1\n## bmi   1   0   1   1\n## hyp   1   1   0   1\n## chl   1   1   1   0\n\n可以看到hyp的插补方法就变成norm了。\n\n如果变量是正态分布的，那么使用norm法可能比pmm法更好。对于大型数据集，选择norm.nob可能更有用，它不绘制回归参数，因此更简单、更快。norm.boot方法是norm的快速非贝叶斯替代方法。在pmm效果不佳的情况下，norm方法是pmm的替代方法。对于稀疏分类数据，最好使用方法pmm而不是logreg、polr或polyreg。logreg.boot是logreg的一个版本，它使用bootstrap来模拟采样方差。lda法通常不如polyreg法，并且仅应在所有其他方法均失败时用作备用方法。sample是一种无需协变量即可创建起始插补的快速方法。\n\n\n\n43.5.2 预测变量矩阵\nimp最下面的预测变量矩阵也可以单独查看：\n\nimp$predictorMatrix\n##     age bmi hyp chl\n## age   0   1   1   1\n## bmi   1   0   1   1\n## hyp   1   1   0   1\n## chl   1   1   1   0\n\n多重插补进行插补时会借助其他变量，比如插补chl时，会使用其他3个变量，插补bmi时，也会使用其他3个变量。这个矩阵中的1就表示使用，0表示未使用。比如在上面的例子中，bmi就是根据age、hyp、chl这3个变量进行插补的。\npredictorMatrix的默认设置是：每个变量都用于插补其他变量。可以自由修改使用哪些变量去插补缺失值，比如我只想用age和chl这两个变量，不想使用hyp，直接把hyp这个变量变成0即可：\n\nimpp &lt;- mice(nhanes, seed = 123, print = FALSE, m=5)\n# 修改变量\nimpp$predictorMatrix[,\"hyp\"] &lt;- 0\n\n# 重新插补即可\nimppp &lt;- mice(nhanes,seed = 123, print = FALSE, m=5, \n     predictorMatrix = impp$predictorMatrix)\n\n# 查看预测变量矩阵\nimppp$predictorMatrix\n##     age bmi hyp chl\n## age   0   1   0   1\n## bmi   1   0   0   1\n## hyp   1   1   0   1\n## chl   1   1   0   0\n\n\n对于小型数据集（最多20-30个变量），使用所有其他变量去插补缺失值是合理的，但是对于大型数据集（包含几百个或者几千个变量）不推荐这种做法，通常使用15-25个变量就足够了。\n\n在实践中有时可能会需要快速使用相关的变量对某个缺失变量进行插补（比如只使用和该变量相关系数大于0.3的变量对该变量进行插补），这时可以使用quickpred()函数快速自动确定符合条件的预测变量。\n\n# 计算预测变量矩阵\npredmatrix &lt;- quickpred(\n  data, # 数据\n  mincor = 0.1, # 最小相关系数\n  minpuc = 0, # 使用的最少样本比例\n  include = \"\", # 使用哪些变量\n  exclude = \"\", # 不使用哪些变量\n  method = \"pearson\" # 相关系数计算方法\n)\n\n# 下面使用这个矩阵进行插补即可\nmice(nhanes,seed = 123, print = FALSE, m=5, \n     predictorMatrix = predmatrix)\n\n\n\n43.5.3 共线性\nmice包在插补时会自动去除存在共线性的变量。下面我们增加一个变量chl2，这个变量是chl这个变量的两倍，是很明显的共线性，mice在插补时会显示一条warning：\n\nimp &lt;- mice(cbind(nhanes, chl2 = 2 * nhanes$chl), # 新建一个有共线性的变量\n            print = FALSE, maxit = 1, m = 3, seed = 1)\n\n这个warning表示有1个变量被排除了，通过以下代码查看被排除的变量，发现是chl2，所以此时chl会被插补，但是chl2不会被插补。\n\nimp$loggedEvents\n##   it im dep      meth  out\n## 1  0  0     collinear chl2\n\n\n\n43.5.4 插补顺序\n一个数据集中可能有多个变量都有缺失值，每个变量都需要被插补，先插补哪个变量呢？\nmice默认是从左到右依次插补。可以通过visitSequence查看插补的顺序：\n\nimp &lt;- mice(nhanes, seed = 123, print = FALSE) \nimp$visitSequence\n## [1] \"age\" \"bmi\" \"hyp\" \"chl\"\n\n这个顺序当然也是可以更改的：\n\n# 自定义顺序\nvis &lt;- c(\"bmi\",\"chl\",\"hyp\",\"age\")\n\n# 按照自定义顺序插补\nimp &lt;- mice(nhanes, seed = 123, print = FALSE, visitSequence = vis) \nimp$visitSequence\n## [1] \"bmi\" \"chl\" \"hyp\" \"age\"",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>mice多重插补</span>"
    ]
  },
  {
    "objectID": "mice多重插补.html#插补结果探索",
    "href": "mice多重插补.html#插补结果探索",
    "title": "43  mice多重插补",
    "section": "43.6 插补结果探索",
    "text": "43.6 插补结果探索\n在完成插补后，可以通过多种图形的方式查看插补后的数据集，检查插补效果等。\n\n43.6.1 收敛\n没有明确的方法来确定MICE算法何时收敛。\n我们可以根据迭代次数绘制出每个变量的均值和标准差（方差）的变化情况。\n\nimp &lt;- mice(nhanes, seed = 62006, maxit = 20, print = FALSE)\nplot(imp)\n\n\n\n\n\n\n\n\n如果算法收敛的话，那么多条线应该趋于交织、重合在一起，不应该有明显的趋势。上图可认为是已经收敛了。\n下面是一个不收敛的示例：\n\nmeth &lt;- make.method(boys)\nmeth[\"bmi\"] &lt;- \"~I(wgt / (hgt / 100)^2)\"\nimp.bmi1 &lt;- mice(boys, meth = meth, maxit = 20,\n                 print = FALSE, seed = 60109)\nplot(imp.bmi1)\n\n\n上图中的曲线一开始是明显的上升趋势，然后是平稳，这种就被认为是没有收敛。\n\n\n43.6.2 诊断图\n有多种图形可以用来检查插补后的数据质量如何，它们基于的思想是：好的插补数据应该具有和观测数据相同的分布。如果观测数据和插补数据的分布相差很大，那么缺失数据可能是非随机缺失。\n比如下面这个散点图，分别展示了4个变量的观测数据和插补数据。其中蓝色点是观测数据（age没有缺失值，所以全是蓝色），红色点是插补数据。\n在bmi、hyp、chl这3个变量中，插补的数据和观测数据的重合度非常高，说明插补质量好。\n\nimp &lt;- mice(nhanes, seed = 29981, printFlag = F)\nstripplot(imp, pch = c(21, 20), cex = c(1, 1.5))\n\n\n\n\n\n\n\n\n另一种看分布比较好的图形是箱线图，蓝色是观测数据，红色是插补数据，可以看出观测数据和插补数据分布基本一致，hyp有几个分布差的比较多，另外两个变量还可以。\n\nbwplot(imp)\n\n\n\n\n\n\n\n\n除此之外，还有密度曲线图，也是一样的解读方法，红色是插补数据的分布，蓝色是观测数据的分布。重合度越高越好。\n\ndensityplot(imp, layout = c(3, 1))",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>mice多重插补</span>"
    ]
  },
  {
    "objectID": "mice多重插补.html#参考资料",
    "href": "mice多重插补.html#参考资料",
    "title": "43  mice多重插补",
    "section": "43.7 参考资料",
    "text": "43.7 参考资料\n\nmice包帮助文档\nFlexible Imputation of Missing Data: https://stefvanbuuren.name/fimd/",
    "crumbs": [
      "其他内容",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>mice多重插补</span>"
    ]
  },
  {
    "objectID": "9999-appendix.html",
    "href": "9999-appendix.html",
    "title": "附录 A — 其他合集",
    "section": "",
    "text": "A.1 R语言零基础入门",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>其他合集</span>"
    ]
  },
  {
    "objectID": "9999-appendix.html#r语言零基础入门",
    "href": "9999-appendix.html#r语言零基础入门",
    "title": "附录 A — 其他合集",
    "section": "",
    "text": "R语言实战医学统计合集：R语言零基础入门\n在线版电子书：R语言零基础入门\ngithub地址：R语言零基础入门\n视频版教程：R语言零基础入门",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>其他合集</span>"
    ]
  },
  {
    "objectID": "9999-appendix.html#医学统计",
    "href": "9999-appendix.html#医学统计",
    "title": "附录 A — 其他合集",
    "section": "A.2 医学统计",
    "text": "A.2 医学统计\n\nR语言实战医学统计合集：R语言实战医学统计\n在线版电子书：R语言实战医学统计\nPDF版电子书：R语言实战医学统计\ngithub地址：R语言实战医学统计\n视频版教程：R语言实战医学统计",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>其他合集</span>"
    ]
  },
  {
    "objectID": "9999-appendix.html#临床预测模型",
    "href": "9999-appendix.html#临床预测模型",
    "title": "附录 A — 其他合集",
    "section": "A.3 临床预测模型",
    "text": "A.3 临床预测模型\n\n临床预测模型合集：临床预测模型\n在线版电子书：R语言实战临床预测模型\nPDF版电子书：R语言实战临床预测模型\ngithub地址：R语言实战临床预测模型",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>其他合集</span>"
    ]
  },
  {
    "objectID": "9999-appendix.html#机器学习",
    "href": "9999-appendix.html#机器学习",
    "title": "附录 A — 其他合集",
    "section": "A.4 机器学习",
    "text": "A.4 机器学习\n医学和生信笔记后台回复caret即可获取caret包的合集教程；回复tidymodels即可获取tidymodels的合集教程；回复mlr3即可获取mlr3合集教程，回复机器学习即可获取机器学习推文合集。\n\nR语言机器学习合集：R语言机器学习\n在线版电子书：R语言实战机器学习\nPDF版电子书：R语言实战机器学习\ngithub地址：R语言实战机器学习",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>其他合集</span>"
    ]
  },
  {
    "objectID": "9999-appendix.html#模型解释",
    "href": "9999-appendix.html#模型解释",
    "title": "附录 A — 其他合集",
    "section": "A.5 模型解释",
    "text": "A.5 模型解释\n包括各种黑盒模型的解释方法，如SHAP、局部代理法、分解解释等：\n\n模型解释合集：模型解释合集",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>其他合集</span>"
    ]
  },
  {
    "objectID": "9999-appendix.html#生信数据挖掘",
    "href": "9999-appendix.html#生信数据挖掘",
    "title": "附录 A — 其他合集",
    "section": "A.6 生信数据挖掘",
    "text": "A.6 生信数据挖掘\n生信数据挖掘合集：生信数据挖掘\n医学和生信笔记公众号所有关于生信数据挖掘的推文都可以免费下载使用，请看：“灌水”生信类文章会用到哪些生信下游分析？（附下载地址）\ngithub地址：R语言生信数据挖掘",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>其他合集</span>"
    ]
  },
  {
    "objectID": "9999-appendix.html#扫码关注",
    "href": "9999-appendix.html#扫码关注",
    "title": "附录 A — 其他合集",
    "section": "A.7 扫码关注",
    "text": "A.7 扫码关注\n欢迎扫码关注：医学和生信笔记",
    "crumbs": [
      "附录",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>其他合集</span>"
    ]
  },
  {
    "objectID": "模型建立和可视化.html",
    "href": "模型建立和可视化.html",
    "title": "模型建立和可视化",
    "section": "",
    "text": "这一章介绍的其实主要是列线图的绘制，这一步通常是在你选择好最后的模型之后进行的。当你经过各种步骤之后已经选好了最终的模型，那你可以把这个模型使用图形化的方式展示出来，也就是使用列线图的形式。\n除此之外，还会介绍一些常见的数据划分方法和数据预处理方法。数据划分非常重要，就是大家常见的交叉验证、bootstrap、内部验证、外部验证等。\n列线图（Alignment Diagram），又称诺莫图（Nomogram图），用来把多因素回归分析结果用图形方式表现出来，将多个预测指标进行整合，然后采用带有刻度的线段，按照一定的比例绘制在同一平面上，从而用以表达预测模型中各个变量之间的相互关系。\n列线图并不是一种模型评价方法，它只是一种把模型进行图形化展示的方法。\n根据模型中各个影响因素对结局变量的贡献程度（回归系数的大小），给每个影响因素的每个取值水平进行赋分，然后再将各个评分相加得到总评分，最后通过总评分与结局事件发生概率之间的函数转换关系，从而计算出该个体结局事件的预测值。\n简单地说，就是把你的模型用图形化的方式展示出来。实际使用时不需要在训练集、验证集各来一遍，也不需要进行各种重抽样，这种做法没有任何意义。\n目前能够绘制列线图的R包只有以下几个（如果还有欢迎大家补充）：\n\nrms\nregplot\nhdnom\n\n我会在后面的章节中详细介绍以下模型的列线图绘制（其他模型是无法绘制列线图的）：\n\n逻辑回归\ncox回归\n样条回归\n竞争风险模型\nlasso回归\n\n并且还会简单介绍下列线图的原理（也就是计算）、根据列线图计算得分、彩色条带的列线图等。\n目前对于机器学习方法，比如决策树、随机森林、支持向量机、KNN、神经网络等，都是不能绘制列线图的（理论可行，实际不可行）。",
    "crumbs": [
      "模型建立和可视化"
    ]
  },
  {
    "objectID": "feature-selection.html",
    "href": "feature-selection.html",
    "title": "常见的变量选择方法",
    "section": "",
    "text": "常见方法简介\n变量选择(又叫特征选择,feature-selection)，是机器学习和统计建模领域非常重要的问题，到底哪些变量是有用的，哪些是不重要的，可以删除的，怎么选才能提高模型表现，理论非常复杂，实在不是一个临床医生能完全掌握的，以下简单介绍下，感兴趣的自己看书。\n在传统的临床预测模型中，比较常见的变量筛选方法有：\n我会在接下来的几章里详细介绍上面这几种方法.\n除了以上方法外,在机器学习领域其实还有非常多专门用于特征选择的方法.\n下面要介绍的变量筛选方法（并没有包含在本书中，可在公众号医学和生信笔记后台回复变量筛选获取相关合集）虽然可以用在临床预测模型中，但是和大家常见的“先单因素后多因素”这种完全不是一个概念，虽然它们的目的相同，都是为了提高模型表现以及减少使用的预测变量个数。\n通常建议在机器学习为主的文章中使用以下变量选择方法，在传统的预测模型类文章中还是以上面介绍的方法为主。\n当数据的维度增加时，决定模型最终使用哪些预测变量是很关键的问题。数据的维度就是自变量(预测变量)\n特征选择是特征工程中非常重要的一部分内容，特征选择的方法非常多，主要可以分为以下3类，每个大类下又会细分为好多具体的方法，但是我基本都在公众号中介绍过了，感兴趣的可以自翻看历史推文。\n大家经常使用的逐步选择法(step/stepAIC)，也属于包装法的一种，但是并不局限于逻辑回归。\n3种方法的简单解释如下，以后单独演示时会专门再解释：",
    "crumbs": [
      "常见的变量选择方法"
    ]
  },
  {
    "objectID": "feature-selection.html#常见方法简介",
    "href": "feature-selection.html#常见方法简介",
    "title": "常见的变量选择方法",
    "section": "",
    "text": "先单因素后多因素\n最优子集（全子集回归）\n逐步选择法\nlasso回归筛选变量\n随机森林筛选变量\n…\n\n\n\n\n\n\n\n\n过滤法(filter)\n\n缺失值比例、方差、相关系数、方差分析/t检验/卡方检验、ROC等\n信息增益 information gain\n最小冗余最大相关性mrmr，Minimum Redundancy Maximum Relevance\n…\n\n包装法(wrapper)\n\n向前、向后、逐步\n递归特征消除rfe(也属于向后)\n模拟退火\n遗传算法\n…\n\n嵌入法(embeded)\n\n随机森林\nMARS\nlasso\nGBDT\n…\n\n\n\n\n\n过滤法：进行变量选择时不考虑模型表现和变量重要性等，只是通过变量自身的情况、变量间的关系进行选择。\n包装法：变量选择考虑到了模型表现和变量重要性等信息，属于是对每一个模型进行“量身定制”的变量\n嵌入法：变量选择的过程就在模型训练的过程之中",
    "crumbs": [
      "常见的变量选择方法"
    ]
  },
  {
    "objectID": "feature-selection.html#r语言中的实现",
    "href": "feature-selection.html#r语言中的实现",
    "title": "常见的变量选择方法",
    "section": "R语言中的实现",
    "text": "R语言中的实现\n主要是3个R包：caret、mlr3、tidymodels\n在caret包中主要可以实现包装法和过滤法。\ncaret包中的封装法有递归特征消除(recursive feature elimination，rfe)算法，遗传算法（genetic algorithms，ga）和模拟退火（Simulated annealing，sa）算法。\n过滤法通过sbf函数实现，但其实部分数据预处理方法属于过滤法的内容。公众号后台回复caret可以获取相关合集。\n目前mlr3已经实现了对这3种方法的支持，可以说是R语言中对变量筛选做的最好的综合性R包了。\n过滤法和嵌入法通过mlr3filters包实现，包装法通过mlr3fselect包实现，关于3两种方法的具体实现，大家可以在公众号后台回复mlr3获取相关推文。\ntidymodels中的特征选择很不完善，不如mlr3做得好，也不如caret做得好！\n部分过滤法包含在recipes中，部分包装法和嵌入法现在并不成熟，没有完整的实现，部分可通过colina包实现，但是这个包并不属于tidymodels，而是个人开发者贡献的R包。\n已经看到tidymodels的开发者有计划增加特征选择的这部分特性，但不知何时实现…",
    "crumbs": [
      "常见的变量选择方法"
    ]
  },
  {
    "objectID": "临床预测模型评价.html",
    "href": "临床预测模型评价.html",
    "title": "临床预测模型的评价",
    "section": "",
    "text": "什么样的模型是优秀的模型？\n评价一个模型的好坏可以从区分度（Discrimination）和校准度（Calibration）两个方面进行。\n区分度指的是一个模型能正确把人群分为患者/非患者，或者正确区分个体是处于低风险、还是处于高风险，或者正确预测患者是存活、还是死亡等的能力。\n但是一个模型只是有良好的区分度是不够的，因为临床问题是很复杂的，并不是只要正确分类就行了。对于不同的患者，可能他们都处于高风险组，但是对于51%的风险和90%的风险，我们的处理是不一样的！\n这就引出了校准度的概念，校准度指的是结局实际发生的概率和模型预测出的概率之间的一致性，所以校准度又叫一致性、拟合优度（goodness-of-fit），校准度体现了一个模型对绝对风险预测的准确性。\n一个具有良好区分度的模型，校准度不一定也很好。比如，A和B两个患者都是低分险组，A的风险是10%，B的风险是30%，如果一个模型把这两个患者都分到低风险组，那说明这个模型的区分度很好，因为分的很准；但是如果这个模型预测A的风险是1%，B的风险是3%，那么这个模型的校准度就是很差的，因为预测的概率和实际概率相差很大。如果使用这样的模型预测出来的结果处理病人的话，可能就会碰到很多问题。\n区分度和校准度虽然都有不足，但是一般来说，具有较差区分度的模型，其校准度也不会很好。当一个模型区分度和校准度都很差的时候，我们可以先从提高模型区分度的角度继续改进。",
    "crumbs": [
      "临床预测模型的评价"
    ]
  },
  {
    "objectID": "临床预测模型评价.html#什么样的模型是优秀的模型",
    "href": "临床预测模型评价.html#什么样的模型是优秀的模型",
    "title": "临床预测模型的评价",
    "section": "",
    "text": "一个理想的模型应该是这样的：它能正确区分所有的患者和非患者，并且能准确预测每一个个体发生危险事件的风险大小。很明显这样的模型是不存在的，我们只能朝这个方向努力。\n\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n尽管只靠区分度是不够的，但临床医生不应使用区分度较差的模型。区分度差的模型也没有必要进一步评价校准度了。\n\n\n\n\n\n区分度的评价\n说了这么多，那我们应该用哪些指标评价模型的分类能力的强弱呢？\n对于二分类模型来说，临床中常用的评价指标是ROC曲线和C-Statistic。二分类模型的AUC（ROC曲线下面积）和C-Statistic是一个东西，越接近1，说明模型的区分度越好，如果接近0.5说明模型的预测结果和乱猜差不多。一般认为，AUC或者C-Statistic在0.6以下是低区分度，在0.6~0.75之间是中区分度，高于0.75是高区分度。\n\nROC曲线的横坐标是1-特异度（横坐标是特异度也可以，此时的横坐标范围是1到0），纵坐标是灵敏度，也就是横坐标是假阳性，纵坐标是真阳性，这两个指标刚好是相反的，一个大另一个就小，所以一般我们会找一个阈值，使得曲线下面积最大。但是如果考虑到临床，这样做有时也是不妥的。比如，在患者具有某些高危疾病（比如心梗、肺梗等）的风险时，我们应该采取更加激进的措施进行预防，这时我们就需要更高的灵敏度，因为不想漏诊。\n近几年各种机器学习方法在临床预测模型中使用的越来越多，所以模型的评价指标也有了更多的选择。对于分类模型，除了ROC曲线外，还可以使用以下指标进行评价：\n\n混淆矩阵（Confusion Matrix）：混淆矩阵是分类任务中所有可能预测结果与真实结果的总结，包含了真阳性、假阳性、真阴性和假阴性的计数，是下述精确率、召回率等指标计算的基础。\n\n用一张图来总结混淆矩阵以及根据混淆矩阵计算出的各种指标（来自于维基百科）：\n\n\n\n混淆矩阵\n\n\n这面这个东西，在不同的场景有不同的叫法，在机器学习和预测模型领域，它叫混淆矩阵，但是在诊断试验中，它叫诊断试验的四格表。\n下面要介绍的所有指标，都是根据这个混淆矩阵计算出来的！\n\n准确率（Accuracy）：准确率是最直观的评价指标，定义为分类正确的样本数占总样本数的比例。但是在类别分布不均匀（即类别不平衡）的情况下，准确率可能产生误导。假如有100个人，其中只有1个人有癌症，其余99个没有癌症，如果模型此时把100个人都预测为没有癌症，那么准确率是99%，非常高，但是此时对于那个漏诊的人来说是不能接受的。此时漏诊率为100%，漏诊率=1-灵敏度。\n精确率（Precision）：也叫查准率，精确率是指被模型预测为阳性的样本中，真正是阳性的比例。\n召回率（Recall）：也叫查全率，在医学中通常被称为灵敏度（sensitivity）,真阳性率，召回率是指所有实际为阳性的样本中，被模型正确识别为阳性的比例。还是上面那个100人的例子，此时它的灵敏度就是0，这样的结果是没有意义的，因为对于临床来说，漏诊是不能被接受的。以查全率为横坐标，以查准率为纵坐标，绘制曲线，可以得到如下图所示的P-R曲线。\n\n\n\nF1分数（F1-Score）：F1分数是精确率和召回率的加权平均值，旨在同时考虑精确率和召回率，特别适用于类别不平衡问题，范围也是[0,1]之间。精准率和召回率是相互矛盾的，一个增大另一个就会减小，所以我们需要找到一个平衡点，由此引出了F1分数，F1分数越高，说明模型越稳健。\n特异度（Specificity）：指所有实际为阴性的样本中，被模型正确识别为阴性的比例。上述的100人的例子，特异度就是100%，也就是说你没有误诊的。误诊率是0，误诊率=1-特异度。\n马修斯相关系数（Matthews Correlation Coefficient，MCC）：同时考虑混淆矩阵中4个类别的结果，并综合考量，范围是[-1,1]，1表示完美预测，0表示随机预测，-1表示完全相反。尤其适用于类不平衡的二分类问题。\n均衡准确率（Balanced Accuracy）：当出现类别不平衡时，使用准确率评价可能会出现较大偏差，此时可以使用均衡准确率，它是每个类别中预测正确的比例的算术平均值。\n\n除了这些，还有阳性预测值/阴性预测值，也可以用来评价模型。\n\n\n校准度的评价\n目前校准度的评价最好的方式还是使用校准曲线（Calibration curve，或者Calibration plot)，在机器学习领域又叫可靠性曲线（reliability curve）。通过校准曲线可以非常直观地看到预测概率和真实概率的关系。\n\n校准曲线的横纵坐标分别是预测概率和真实概率（横纵坐标可以互换），完美的校准曲线应该是一条斜率为1，截距是0的直线是，说明模型的预测的概率和真实概率完全一致，模型超级准确。\n校准度的评价可以在很多水平进行，比如，从整体角度，或者从不同的组进行等。\n假如100个人有20个人发生了结局事件，那么真实概率就是20%，我们的模型会对每个人都计算出一个概率，如果大于某个值（比如说0.5），我们就认为这个人会发生结局事件，小于0.5就认为不会发生结局事件，那么这100个人每个人都会得到一个概率，把100个人的概率加起来再除以100，就得到了模型预测的平均概率，这个概率就是从整体角度评价的。\n假如把100个人按照预测概率大小排好序，然后分成10组，每组10人，在每个组内计算模型平均概率，再和真实概率（比如一组内10人有3人发生了结局事件，那这一组的真实概率就是30%）比较，然后把真实概率作为横坐标，预测概率作为纵坐标，就可以画出Calibration curve了，这就是从不同组的角度评价的（这是目前主流做法）。\n除了直接查看图形，校准度还可以用统计检验来评估真实概率和预测概率的差异，比如Hosmer-Lemeshow检验（H-L 检验），若得到的P值小于0.05，那说明模型的预测概率和真实概率之间确实有差异，不是由于随机误差导致的，若P值大于0.05，说明通过了H-L检验，预测概率和实际概率没有明显的差异。但是H-L检验无法量化差异的大小，也不能说明差异的大小在低风险患者和高风险患者之间是否存在差异。\n当样本量很大时，Hosmer-Lemeshow检验也可能具有误导性。在这种情况下，预测风险和真实风险之间的临床微小差异可能导致具有统计学意义的Hosmer-Lemeshow检验结果。\n除了校准曲线和H-L检验外，模型的校准度还可以使用以下指标进行评价：\n\nLog Loss（交叉熵损失）：又叫对数损失、对数似然、逻辑损失，特别适用于概率预测模型，衡量预测概率分布与实际类别之间的差异。越接近0越好。\nBrier-Score：布里尔分数，衡量模型预测的类别的概率与真实值之间的误差，仅用于二分类数据，范围是0到1，越小越好。\n预测概率直方图：评价模型预测概率的分布，并据此判断模型的校准度。\n\n有一些方法可以对预测概率进行校准，使其更加接近真实结果或者可以使模型的校准曲线拟合的更佳贴近理想情况。常见的方法包括：Platt校准（Platt Scaling）、保序回归法（ isotonic regression）、贝叶斯校准（Bayesian Calibration）等。",
    "crumbs": [
      "临床预测模型的评价"
    ]
  },
  {
    "objectID": "临床预测模型评价.html#多个模型的比较",
    "href": "临床预测模型评价.html#多个模型的比较",
    "title": "临床预测模型的评价",
    "section": "多个模型的比较",
    "text": "多个模型的比较\n如果涉及到多个模型进行比较的话，除了区分度和校准度，还可以用净重新分类指数和综合判别改善指数来比较模型的优劣。\n\nNRI\n净重新分类指数（net reclassification index，NRI），是用来比较模型准确度的，这个概念有点难理解，但是非常重要，在临床研究中非常常见，是评价模型的一大利器！\n如果新模型比旧模型更加优秀，那么理想情况下应该是这样的：（1）对于发生终点事件的患者，新模型为其分配了比先前模型更高的风险类别（理想的重新分类），以及（2）对于未发生终点事件的患者，新模型为其分配了较低的风险类别（也是理想的重新分类）。这就是净重分类的基本理念。\n我们可以这样简单的理解，假如有一群受试者，有些是患病的，有些是没病的，你建立了一个模型1，通过计算把受试者分为了有病组和没病组（当然有些是分错的），然后你又建立了模型2，也是把这群受试者分成了有病组和没病组，相当于是重新分类了！2个模型计算的结果是不一样的，有的可能重新分类分对了，有的可能分错了，然后，净重分类=重新分对的-重新分错的，净重分类指数只要再除以总人数就可以了，这样得到的就是绝对净重分类指数（absolute NRI）。\n绝对净重分类指数反应的是模型对整体的分类能力有无改善，但是，对于有病组和没病组，都是有可能出现重新分类分对了/重新分类分错了/重新分类和之前一样，这3种情况的。所以，我们可以把有病组和没病组分开计算净重分类指数，然后再相加，这样得到的就是相加净重分类指数（additive NRI）。\n下面用几个例子说明相加NRI和绝对NRI的计算以及各自的优缺点。\n示例1假设一共有20000名患者，其中发生事件（with events）的患者（以下简称阳性）和未发生事件（without events）的患者（以下简称阴性）人数相等，都是10000人。新旧模型将患者分为低风险、中风险、高风险3组。新旧模型重新分类的结果如下图（example 1）表格所示，其中绿色的表示重新分类正确的，粉色表示重新分类错误的，灰色表示没变化，左侧表格是阳性患者的重新分类表格，右侧是阴性患者的重新分类表格。\n示例2假设一共有11000名患者，但是阳性（with events）的只有1000个，阴性（without events）的有10000个。新旧模型重新分类的结果也是如下图（example 2）表格所示。\n\n\n对于示例1来说：\n\n阳性患者组：新模型重新分类正确的人数是1200+400+600=2200，重新分类错误的人数是300+50+350=700，净重新分类人数是2200-700=1500， 阴性患者组：新模型重新分类正确的人数是100+50+100=250，重新分类错误的人数是300+100+150=550，净重新分类人数是250-550=-300，\n绝对NRI=（2200-700+250-550）/20000=0.06 相加NRI=（2200-700）/10000 +（250-550）/10000=0.12\n\n对于示例2来说：\n\n阳性患者组：新模型重新分类正确的人数是120+40+60=220，重新分类错误的人数是30+5+35=70，净重新分类人数是220-70=150， 阴性患者组：新模型重新分类正确的人数是100+50+100=250，重新分类错误的人数是300+100+150=550，净重新分类人数=250-550=-300，\n绝对NRI=（220-70+250-550）/11000=-0.0136 相加NRI=（220-70）/1000 + （250-550）/10000=0.12\n\n图中在计算时都乘了100，其实没有必要。\n\n相加NRI的主要局限性在于它不考虑人群中事件和非事件的发生比例，比如在上面的示例1和示例2中，虽然示例2的发生事件的患者和不发生事件的患者比例差距很大，但是相加NRI都是0.12。绝对NRI则避免这个问题。以下示例说明了这一优势。\n考虑上图中的示例1，其中发生事件和未发生事件的患者比例相等。在这种情况下，相加NRI将始终是绝对NRI的2倍。绝对NRI表示新模型重新分类更佳的实际比例，如果大于0说明新模型更好，小于0说明新模型更差，等于0说明和原模型相同，在本例中新模型重新分类更佳的比例为0.06。\n在示例2中，发生和不发生事件的患者比例为1：10。阴性组和阳性组重新分类的数量都与示例1是相同的。由于相加NRI不考虑阴性和阳性的比例问题，所以绝对NRI还是0.12，从相加NRI来看是有利于新模型的。虽然新模型在发生事件的患者中表现得更好（净重新分类人数是150），但发生事件的患者比例太小了，新模型在未发生事件的患者中比表现的比较差（净重新分类指数是-300），两者加起来是-150，说明实际上新模型比旧模型还多分错了150个人，新模型是更差的。所以当事件发生率较低时，相加NRI可能会产生误导，而绝对NRI更能反映模型的真实情况。\n但是绝对NRI假设发生事件的影响与不发生事件的影响相同。临床中并不是这样的，比如对于心梗的预测，我们肯定是更关心发生心梗的，因为即使漏诊一个心梗，对于病人本来说也是无法接受的。此时我们可能会更加重视对发生事件的患者能进行更好分类的模型。这就涉及到漏诊和误诊的关系问题了。\n本质上，相加NRI等于（新模型灵敏度与特异度之和）减去（旧模型灵敏度与特异度之和），也就是等于（新模型的约登指数）减去（旧模型的约登指数）。\n所以到底怎么取舍，不能只看数字，一定要结合实际情况，写文章时遇到了不好的结果也要好好讨论！\n\n\nIDI\nNRI、AUC、C-Statistic都是要先设置一个阈值，然后在这个阈值的前提下进行各种比较，它们只是考虑了单独一个点的情况，不能反应模型的整体情况。因此，又来了新的指标-综合判别改善指数（Integrated Discrimination Improvement，IDI）。\nIDI的计算很简单，它反映了两个模型在预测概率上的差别，是基于模型对每个个体的预测概率计算所得。它的计算方法为：\n\nPnew,events：患者组，新模型对每个人预测概率的平均值；\nPold,events ：患者组，旧模型对每个人预测概率的平均值；\n对于患者来说，那肯定是预测概率越高越准确，所以两者相减，值越大，表明新模型的预测能力越好；\nPnew,non-events：非患者组，新模型对每个人预测概率的平均值；\nPold,non-events：非患者组，旧模型对每个人预测概率的平均值；\n对于非患者来说，那肯定是预测概率越小越准确，所以两者相减，值越小，表明新模型的预测能力越好；\n两部分再相减，就是值越大，表明模型预测能力越好，如果IDI为负值，那说明还不如原来的模型好。",
    "crumbs": [
      "临床预测模型的评价"
    ]
  },
  {
    "objectID": "临床预测模型评价.html#临床适用性",
    "href": "临床预测模型评价.html#临床适用性",
    "title": "临床预测模型的评价",
    "section": "临床适用性",
    "text": "临床适用性\n临床都会碰到假阳性和假阴性问题，也就是误诊和漏诊问题，对于不同的疾病，可能我们需要的阈值不同，有时需要更高的假阳性，有时需要更高的假阴性，因此这就是一个实际临床效用问题，到底怎么办，才能使患者获益最大？这就是临床适用性（clinical usefulness）问题。\n\n决策曲线分析\n决策曲线分析（Decision Curve Analysis，DCA）就是为了解决这一问题。\n当患者有症状但尚不能诊断为某种疾病时，临床医生必须决定是(1)经验性治疗，(2)不治疗，或(3)在选择选项1和2之前进行进一步的检查。是否治疗取决于临床医生的经验、疾病治疗的有效性和并发症，以及患者接受治疗风险和负担的意愿。决策曲线分析是一种通过考虑患者风险和获益的可能范围来评估临床决策是否可行的方法。\nDCA中的一个关键概念是概率阈值（probability threshold），即患者选择接受治疗的概率水平。概率阈值表明患者在接受治疗（如果有病）时的相对值，以及如果不存在疾病时避免治疗的值。如果治疗疗效高、成本低、不良反应少，则概率阈值较低；相反，如果治疗效果差或与大量并发症相关（例如，恶性脑肿瘤的放疗），则概率阈值会很高。\n\n结合上面这幅图，横坐标就是概率阈值。此时对于一个病人来说，治疗有可能会利大于弊，也有可能会弊大于利，纵坐标就是利减去弊之后的净获益。\n概率阈值也是概率，取值自然是0-1之间的，所以对于每一个概率，我们都可以计算出一个净获益（计算方法上图中给出了），然后把所有的点连起来，就是决策曲线了（上图中3条虚线，代表3种不同方法的决策曲线）。\n上图中还有2条特殊的线，一条水平的蓝色线，表示所有人都不接受治疗时，此时不管概率阈值是多少，净获益肯定都是0。一条黄色的线，表示所有人都接受治疗时，随着概率阈值的改变，其净获益的改变。这两条线代表了2种极端的情况。\n在给定的概率阈值下，肯定是净获益越大越好，所以一般来说，肯定是曲线距离两条特殊的线越远越好。在写文章时一定要写清楚到底是在哪个概率区间内，你的模型的净获益是正的。\n\n\n临床影响曲线\n临床影响曲线（Clinical Impact Curve，DCA），属于DCA的变种，是Kerr等人对DCA的进一步发展，结合下面这张图来看：\n\n横坐标还是概率阈值，纵坐标是每1000人里面的高风险人数。紫色线表示在不同的概率阈值下，被模型判定为高风险的人数；红色线条表示在不同的概率阈值下，被模型判定为高风险且真的发生结局事件的人数。在最下面还增加了一个损失：获益比，表示在不同的概率阈值下，损失和获益的比例。上图表明在概率阈值大于0.6（大约）以后，模型判定为高风险的人群和实际发生终点事件的人群完全一致。\n\n\n\n\n\n\n注释\n\n\n\n临床影响曲线目前在R语言中只有rmda包可以绘制，而且只适用于二分类模型，不能用于生存分析中，在文献中出现的相对偏少。",
    "crumbs": [
      "临床预测模型的评价"
    ]
  },
  {
    "objectID": "临床预测模型评价.html#回归模型的评价",
    "href": "临床预测模型评价.html#回归模型的评价",
    "title": "临床预测模型的评价",
    "section": "回归模型的评价",
    "text": "回归模型的评价\n以上内容基本基本都是对于分类模型和生存模型的评价，对回归模型来说，也有一些评价指标，常用的回归模型评价指标如下所示：\n\n均方误差（Mean Squared Error, MSE）: 定义为预测值与实际值之差的平方和的均值。\n均方根误差（Root Mean Squared Error, RMSE）: 是MSE的平方根，使得其单位与目标变量相同，便于解释。RMSE对异常值很敏感，极端异常值会让RMSE明显变大。如果只是为了衡量模型整体的误差，则使用RMSE更佳。\n平均绝对误差（Mean Absolute Error, MAE）: 计算预测值与实际值之间绝对差值的平均数。MAE对所有误差给予相等的权重，不被大误差过分影响，比RMSE更适合有极端值的情况。\n平均绝对百分比误差（Mean Absolute Percentage Error, MAPE）: 计算预测误差相对于实际值的百分比的平均值，适用于对预测误差的相对大小更感兴趣的场景。\n中位绝对误差（Median Absolute Error, MAE）：\nR²（决定系数，Coefficient of Determination）: 表示模型解释的变异量占总变异量的比例，值范围从0到1，越接近1表示模型拟合越好。R²衡量了模型解释数据变异的能力。\n解释方差分数（Explained Variance Score）: 类似于R²，但直接作为比例表示模型解释的方差部分，值越大表示模型拟合越好。\n\n凡是叫xxx误差的指标，一般都是越小说明模型越好。\n了解这些基础内容后，我们就可以通过各种各样的工具实现它，后面我们将会详细介绍如果通过R语言计算以上指标。",
    "crumbs": [
      "临床预测模型的评价"
    ]
  },
  {
    "objectID": "临床预测模型评价.html#参考资料",
    "href": "临床预测模型评价.html#参考资料",
    "title": "临床预测模型的评价",
    "section": "参考资料",
    "text": "参考资料\n[1] Alba A C, Agoritsas T, Walsh M, et al. Discrimination and Calibration of Clinical Prediction Models: Users’ Guides to the Medical Literature[J]. JAMA, 2017, 318(14): 1377–1384. DOI:10.1001/jama.2017.12126. [2] Fitzgerald M, Saville B R, Lewis R J. Decision curve analysis[J]. JAMA, 2015, 313(4): 409–410. DOI:10.1001/jama.2015.37.",
    "crumbs": [
      "临床预测模型的评价"
    ]
  },
  {
    "objectID": "多模型比较.html",
    "href": "多模型比较.html",
    "title": "多模型比较",
    "section": "",
    "text": "当我们建立了多个模型后，肯定是要比较不同模型的优劣的。模型比较涉及很多专业的方法和理论。\n当说到模型比较时，我们其实是在比较模型的性能指标，比如，比较AUC值、RMSE、校准曲线、NRI、IDI等。但是此时我们比较的通常是这些指标的大小，比如，A模型的AUC值比B模型高，那么我们就认为A模型更好。\n其实这种方法是很肤浅的。我们需要更加专业的比较方法，比如在前面介绍过的ROC曲线的比较（Delong检验），这种方法更加正式，而且还可以给出p值，在统计学上更加令人信服，是比单纯比较数值大小更好的方法。\n有很多可以用于模型比较的专业方法，比如似然比检验和方差分析法，我们在Chapter 26  C-index的比较C-index的比较中一章中介绍过。\n除此之外，还可以使用贝叶斯方法进行比较，这些方法都是有理论基础的，也有相关的参考文献。而且可以用于多种类型的模型比较，比如，随机森林模型和支持向量机模型进行比较，不必局限于回归模型。\n但是由于这些方法目前在文献中用的很少，所以我会在接下来的章节中简单介绍下。\n接下来的章节会主要介绍几个综合性R包的使用方法，比如caret、tidymodels、mlr3，给大家展示如何使用简洁的代码同时比较多个不同的模型，方便大家快速筛选表现更好的模型。\n\n\n\n\n\n\n注意\n\n\n\n这部分内容主要是几个综合性的机器学习和预测建模R包的介绍，更多的使用方法，可参考机器学习合集。除此之外，在公众号后台回复caret、tidymodels、mlr3，都可以直接获取相关合集。",
    "crumbs": [
      "多模型比较"
    ]
  }
]